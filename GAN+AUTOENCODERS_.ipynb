{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh12987/research_paper/blob/main/GAN%2BAUTOENCODERS_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzjnbaMgHKFd"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-0GQcc7HKCW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx4vurJTHKBN"
      },
      "outputs": [],
      "source": [
        "maled=pd.read_csv(\"male.txt\",sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCzS0MD7HJu5"
      },
      "outputs": [],
      "source": [
        "femaled=pd.read_csv(\"female\",sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlavfIqxHJtu"
      },
      "outputs": [],
      "source": [
        "maled[\"label\"]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDeABss_HJhP"
      },
      "outputs": [],
      "source": [
        "femaled[\"label\"]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "jwAKUZh5HJY1",
        "outputId": "dcecc5fb-253c-4be8-ad01-1cbb4c94f7b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Good Hotel and a very pleasant stay at the Elysees Regencia We stayed at the Elysees Regencia in a (green) deluxe room (47) from Jan 2 til Jan 5, based on TripAdvisor's reviews. To summarize our experience with the Elysees Regencia: it is a very fine hotel.Some pro's:* nice staff, that will help you with booking restaurants* good location (close to the Champs Elysees, subway station nearby (George V))* nice, clean and quite spacious (for Paris!) room. Nice touch: during the day the room is organized (with the green pillows)differently than in the evening (set up for bedtime, with a chocolate and refreshing towel on your pillow). Bathroom (marbled) is ok, with bathrobes slippers and l'Occitane tolietry. The bath itself is a bit on the small side though (no problem for us, though)* a very good feature is the separate toilet from the bath* on arrival, we received a Paris tourist guide and a map (we didn't need it though, since we brought our own and we do know Paris a bitA con* you do hear a bit of street noise (traffic noise from the Avenue Marceau), though it didn't bother us reallySince we woke up quite late, we cannot say how breakfast was (breakfast being served til 1030 am).We would definitely return here.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "maled[\"message\"][536]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JlAwRWnMbNO0",
        "outputId": "521ecaa4-c877-47b5-c434-0fd27f0cb137"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                message  label\n",
              "0     Central location My wife and I stayed at The H...      1\n",
              "1     Central location My wife and I stayed at this ...      1\n",
              "2     fun place for honeymoon we went to honolulu as...      1\n",
              "3     Very Nice Stay We stayed at the Park Hotel Shi...      1\n",
              "4     Very Comfortable Holiday at the L T I Left nov...      1\n",
              "...                                                 ...    ...\n",
              "2796  Got lucky! We booked this hotel on Travelocity...      1\n",
              "2797  Convenient, great staff With some forethought ...      1\n",
              "2798  Completely exceeded expectations We made a dec...      1\n",
              "2799  loved the hotel and friendly staf the hotel ha...      1\n",
              "2800  nice time at le meridien sf we had a rather la...      1\n",
              "\n",
              "[2801 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f65cf19f-58a6-404e-88f6-f2073ef62e86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Central location My wife and I stayed at The H...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Central location My wife and I stayed at this ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fun place for honeymoon we went to honolulu as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very Nice Stay We stayed at the Park Hotel Shi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very Comfortable Holiday at the L T I Left nov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>Got lucky! We booked this hotel on Travelocity...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>Convenient, great staff With some forethought ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>Completely exceeded expectations We made a dec...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>loved the hotel and friendly staf the hotel ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2800</th>\n",
              "      <td>nice time at le meridien sf we had a rather la...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2801 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f65cf19f-58a6-404e-88f6-f2073ef62e86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2a9f9dc4-42e6-4189-8203-6002d33690ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a9f9dc4-42e6-4189-8203-6002d33690ed')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2a9f9dc4-42e6-4189-8203-6002d33690ed button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f65cf19f-58a6-404e-88f6-f2073ef62e86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f65cf19f-58a6-404e-88f6-f2073ef62e86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "maled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "if547G4tbM__",
        "outputId": "e5c04ae4-dd88-4724-ca99-31a30aa21a5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                message  label\n",
              "0     Great Staff in New Orleans The French Quarter ...      0\n",
              "1     Good hotel, Nice Staff This hotel is on the se...      0\n",
              "2     loved it! My mother and I stayed here for a lo...      0\n",
              "3                          Great Location Fron of hotel      0\n",
              "4     Small quiet and friendly Stayed here for 4 nig...      0\n",
              "...                                                 ...    ...\n",
              "2625  Fabulous Location, Chic Hotel! Hotel Granados ...      0\n",
              "2626  Beautiful Resort........food not so good My hu...      0\n",
              "2627  Great Break We went to The Gallery in Barcelon...      0\n",
              "2628  Very Friendly Budget Hotel. We (my mum and I )...      0\n",
              "2629  pretty good for a 3.5 star hotel!! beachgood b...      0\n",
              "\n",
              "[2630 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9d371be8-8cb7-43db-aebd-03530c061f06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Great Staff in New Orleans The French Quarter ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good hotel, Nice Staff This hotel is on the se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>loved it! My mother and I stayed here for a lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Great Location Fron of hotel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small quiet and friendly Stayed here for 4 nig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>Fabulous Location, Chic Hotel! Hotel Granados ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2626</th>\n",
              "      <td>Beautiful Resort........food not so good My hu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2627</th>\n",
              "      <td>Great Break We went to The Gallery in Barcelon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2628</th>\n",
              "      <td>Very Friendly Budget Hotel. We (my mum and I )...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629</th>\n",
              "      <td>pretty good for a 3.5 star hotel!! beachgood b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2630 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d371be8-8cb7-43db-aebd-03530c061f06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e1314ab8-766f-4aa4-a817-bea7118b3ed9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1314ab8-766f-4aa4-a817-bea7118b3ed9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e1314ab8-766f-4aa4-a817-bea7118b3ed9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d371be8-8cb7-43db-aebd-03530c061f06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d371be8-8cb7-43db-aebd-03530c061f06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "femaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHJcebgbtctt"
      },
      "outputs": [],
      "source": [
        "maled=maled[:2630]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqPXN--9k23Y"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([maled,femaled],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "615J7odrk3Ai",
        "outputId": "1b8394d9-1b58-4f91-f894-32ec34c8e67e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Good Hotel But Check Your Bill Stayed two nights in a loft apartment. About average for Sydney prices but well located on a wharf into the harbour and walking distance to the city.Warning. Check your bill; we were charged for breakfast and the use of the bar. After contacting the hotel they did refund the breakfast, but failed to credit the bar which we had not used.As a traveller with a daughter in the area we ate opposite for half the price at Charlies and purchased water there for $3. Be warned, check your account.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data[\"message\"][2002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6Zjt5cUXlCxZ",
        "outputId": "bd06eba6-f672-44ee-d6c1-1001745f3b11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                message  label\n",
              "0     Central location My wife and I stayed at The H...      1\n",
              "1     Central location My wife and I stayed at this ...      1\n",
              "2     fun place for honeymoon we went to honolulu as...      1\n",
              "3     Very Nice Stay We stayed at the Park Hotel Shi...      1\n",
              "4     Very Comfortable Holiday at the L T I Left nov...      1\n",
              "...                                                 ...    ...\n",
              "5255  Fabulous Location, Chic Hotel! Hotel Granados ...      0\n",
              "5256  Beautiful Resort........food not so good My hu...      0\n",
              "5257  Great Break We went to The Gallery in Barcelon...      0\n",
              "5258  Very Friendly Budget Hotel. We (my mum and I )...      0\n",
              "5259  pretty good for a 3.5 star hotel!! beachgood b...      0\n",
              "\n",
              "[5260 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c778dfc3-5d6b-40b4-9c02-ae6062a74e37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Central location My wife and I stayed at The H...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Central location My wife and I stayed at this ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fun place for honeymoon we went to honolulu as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very Nice Stay We stayed at the Park Hotel Shi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very Comfortable Holiday at the L T I Left nov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5255</th>\n",
              "      <td>Fabulous Location, Chic Hotel! Hotel Granados ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5256</th>\n",
              "      <td>Beautiful Resort........food not so good My hu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5257</th>\n",
              "      <td>Great Break We went to The Gallery in Barcelon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5258</th>\n",
              "      <td>Very Friendly Budget Hotel. We (my mum and I )...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5259</th>\n",
              "      <td>pretty good for a 3.5 star hotel!! beachgood b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5260 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c778dfc3-5d6b-40b4-9c02-ae6062a74e37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8ab80bdc-6036-4dd5-bd02-26e762c0e19f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ab80bdc-6036-4dd5-bd02-26e762c0e19f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8ab80bdc-6036-4dd5-bd02-26e762c0e19f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c778dfc3-5d6b-40b4-9c02-ae6062a74e37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c778dfc3-5d6b-40b4-9c02-ae6062a74e37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGVR280moGqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#bert code\n"
      ],
      "metadata": {
        "id": "CILJrpUZoHSI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSImNMC4oGnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xX5EdwtoGkn",
        "outputId": "36e48183-3aa9-4263-ad24-071708b908a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "5_Td1lR_oGiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "bseEnnEvoGeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RTgAroqHs9YA",
        "outputId": "488f1b44-1884-4eeb-e49b-efbf2961292f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.14.0)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow_text)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m532.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow_text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow_text-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow-text"
      ],
      "metadata": {
        "id": "OtN94FhEr3o3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aed0771-b957-48f3-f322-4db113e5b3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.14.0)\n",
            "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "PMIzCnOzrkG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf9f377-e387-4092-9b44-fa457c62df25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_text as text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "xWCJZXcZtEV1",
        "outputId": "d9377dfb-8152-4d88-9152-72122175cb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9495cdc7fbed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_text/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpybinds\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtflite_registrar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/tensorflow_text/core/pybinds/tflite_registrar.so: undefined symbol: _ZN4absl12lts_2023012516raw_log_internal21internal_log_functionB5cxx11E",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "rz57KEQfoGUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuxoMA_xvKSO",
        "outputId": "8ec47818-bae5-42d5-d31d-8ddde07976ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow-text==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_GVhDoEvKPu",
        "outputId": "aef93486-dcea-47c2-a484-8aba8ba111c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.0) (0.14.0)\n",
            "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "-QMgiPacvKMa",
        "outputId": "40d5536e-2176-45cc-bdbc-8ea514e92109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-81ef3d1ab892>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_text/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpybinds\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtflite_registrar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/tensorflow_text/core/pybinds/tflite_registrar.so: undefined symbol: _ZN4absl12lts_2023012516raw_log_internal21internal_log_functionB5cxx11E",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-OJSHOJvKIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Ni9EAfnvKE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "j6fQXNxKoGRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")"
      ],
      "metadata": {
        "id": "dJfMP4GI6OV9",
        "outputId": "0f494f12-ed93-4dd2-ca76-c36c9c98b717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4214\u001b[0m     \u001b[0mdevice_fn_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4215\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceable_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceableStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    965\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n\u001b[0;32m--> 966\u001b[0;31m       saved_model_proto.meta_graphs[0].HasField(\"object_graph_def\")):\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    156\u001b[0m     self._operation_attributes = {\n\u001b[0;32m--> 157\u001b[0;31m         node.name: node.attr for node in meta_graph.graph_def.node}\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0;31m# There is no need to copy all functions into the function def graph. It\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;31m# leads to a O(n^2) increase of memory when importing functions and the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec)\u001b[0m\n\u001b[1;32m     84\u001b[0m       for input_shape, arg_def in zip(raw_input_shapes,\n\u001b[0;32m---> 85\u001b[0;31m                                       fdef.signature.input_arg):\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marg_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_RESOURCE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m    255\u001b[0m       versions_pb2.VersionDef(\n\u001b[0;32m--> 256\u001b[0;31m           \u001b[0mproducer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPH_DEF_VERSION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m           min_consumer=versions.GRAPH_DEF_VERSION_MIN_CONSUMER))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4218\u001b[0m       \u001b[0mcurrent_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4219\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceable_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceableStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on 6206f27163ed. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0919d44dfa99>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_preprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m           \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    118\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    119\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0mwritten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mfail\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpointed\u001b[0m \u001b[0mat\u001b[0m \u001b[0man\u001b[0m \u001b[0mincomplete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mRather\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mchecking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m   \u001b[0;34m\"saved_model_dir/saved_model.pb\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mwritten\u001b[0m \u001b[0matomically\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;31m# tensor_content field contains raw bytes in litle endian format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# which causes problems when loaded on big-endian systems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# requiring byteswap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on 6206f27163ed. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Z5SKHeWfoGOh",
        "outputId": "4c32d931-a5bc-449a-960b-5bab3ded488c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4214\u001b[0m     \u001b[0mdevice_fn_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4215\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceable_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceableStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    965\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n\u001b[0;32m--> 966\u001b[0;31m       saved_model_proto.meta_graphs[0].HasField(\"object_graph_def\")):\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    156\u001b[0m     self._operation_attributes = {\n\u001b[0;32m--> 157\u001b[0;31m         node.name: node.attr for node in meta_graph.graph_def.node}\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0;31m# There is no need to copy all functions into the function def graph. It\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;31m# leads to a O(n^2) increase of memory when importing functions and the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec)\u001b[0m\n\u001b[1;32m     84\u001b[0m       for input_shape, arg_def in zip(raw_input_shapes,\n\u001b[0;32m---> 85\u001b[0;31m                                       fdef.signature.input_arg):\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marg_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_RESOURCE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m    255\u001b[0m       versions_pb2.VersionDef(\n\u001b[0;32m--> 256\u001b[0;31m           \u001b[0mproducer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPH_DEF_VERSION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m           min_consumer=versions.GRAPH_DEF_VERSION_MIN_CONSUMER))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4218\u001b[0m       \u001b[0mcurrent_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4219\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceable_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceableStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on 6206f27163ed. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0919d44dfa99>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_preprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m           \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    118\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    119\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0mwritten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mfail\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpointed\u001b[0m \u001b[0mat\u001b[0m \u001b[0man\u001b[0m \u001b[0mincomplete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mRather\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mchecking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m   \u001b[0;34m\"saved_model_dir/saved_model.pb\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mwritten\u001b[0m \u001b[0matomically\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;31m# tensor_content field contains raw bytes in litle endian format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# which causes problems when loaded on big-endian systems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# requiring byteswap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on 6206f27163ed. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyahYuh3oGLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOTay8i6u1Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8sp68Sru1Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHj4LCm-u1Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53fw2Gtbu1Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDxGaGuBu09M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzllWp6qu05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpNrwPTBu03H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# end of bert"
      ],
      "metadata": {
        "id": "6gLTcxzWoKeQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_C-TRV9k2r4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# normal vectorization"
      ],
      "metadata": {
        "id": "WwC5oFxWoN88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFw-Bw3UHJIw",
        "outputId": "ed6ab971-8472-41ce-95da-f7fe214a585f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOncnSWLmt0Y"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EkE4h4BmtxP",
        "outputId": "5e5f7806-0507-4310-a513-ac9d1f147704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExGbPhD2bIW6"
      },
      "outputs": [],
      "source": [
        "male_word_vectors1 = []\n",
        "for i in range(0, len(maled)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', (maled[\"message\"][i]))\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "\n",
        "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    male_word_vectors1.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkjkTEaXnbc3"
      },
      "outputs": [],
      "source": [
        "female_word_vectors1 = []\n",
        "for i in range(0, len(femaled)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', (femaled[\"message\"][i]))\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "\n",
        "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    female_word_vectors1.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_dPxZtYbIL9"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for i in range(0, len(data)):\n",
        "  review = []\n",
        "  review = re.sub('[^a-zA-Z]', ' ', (data[\"message\"][i]))\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhK6pXpAmvk2",
        "outputId": "17613205-3b43-45c4-8911-565344c78f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2630"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(male_word_vectors1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_word_vectors1"
      ],
      "metadata": {
        "id": "t2nUITqv6LgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXnuka1H6547"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "V9XhpKza6of7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb4wHVWskVb3",
        "outputId": "33a3b351-3b6e-4b3c-e13a-76f0a0885c39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2630"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(female_word_vectors1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9GP7kd9mtrv",
        "outputId": "ac2a0e8f-d76d-432b-a8eb-8acf2124a2f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5260"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKmReDTmmxm-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nlcy-BX7FyUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tokenising\n"
      ],
      "metadata": {
        "id": "RfUKjPPIFy05"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2J241ld6FyRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifqlZolOoI_X",
        "outputId": "97636420-ef9d-44c4-dad1-e7054d07ebec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g8UhvSwHJCj"
      },
      "outputs": [],
      "source": [
        "from gensim.models import keyedvectors\n",
        "from gensim.utils import simple_preprocess\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPFsJsOuHI_8"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "for sent in corpus:\n",
        "    sent_token=sent_tokenize(sent)\n",
        "    for sent in sent_token:\n",
        "        words.append(simple_preprocess(sent))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ya7lLsMy_-U",
        "outputId": "7e9ec02e-740f-4724-8ae1-99c1c1aa2dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5260"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1KQZdxH4DE4"
      },
      "outputs": [],
      "source": [
        "male_word_2=[]\n",
        "for sent in male_word_vectors1:\n",
        "    sent_token=sent_tokenize(str(sent))\n",
        "    for sent in sent_token:\n",
        "        male_word_2.append(simple_preprocess(sent))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(male_word_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K51xQbE4y-MV",
        "outputId": "15fd9962-9fa9-4bf4-d821-9fd64ced171c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2630"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlKoCfHt4DBn"
      },
      "outputs": [],
      "source": [
        "female_word_2=[]\n",
        "for sent in female_word_vectors1:\n",
        "    sent_token=sent_tokenize(sent)\n",
        "    for sent in sent_token:\n",
        "        female_word_2.append(simple_preprocess(sent))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(female_word_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XaekhqAzF7l",
        "outputId": "ccf90dc3-684e-4ba0-c788-8b7716b091b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2630"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#end of tokenising\n"
      ],
      "metadata": {
        "id": "0KfYC041FqxM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqgiEaEnlAco"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1I-IL7uyFrjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV8jRpXY4C-J",
        "outputId": "3f7a79ec-d9db-4d46-8e78-dba115eb2888"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-883fc5453957>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  vectors_array = np.array(words)\n"
          ]
        }
      ],
      "source": [
        "# #for downloading the vectors into the device\n",
        "\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# # Assuming 'vectors_list' is your list of vectors\n",
        "# vectors_array = np.array(words)\n",
        "\n",
        "# # Save the NumPy array to a file\n",
        "# vectors_filename = 'vectors(words)_list.npy'  # You can choose any filename you like, ending with '.npy'\n",
        "# np.save(vectors_filename, vectors_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjWJmQ-44C7r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMZ9pC9iHI-O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#vectorising for all the words"
      ],
      "metadata": {
        "id": "FptvHzbrB6nS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHX-d0ZyHI6c",
        "outputId": "624a3816-bf8c-4ed8-f8dc-09145ccd6b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21563911, 27480450)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "model = gensim.models.Word2Vec(words,min_count=5)\n",
        "\n",
        "model.train(words,total_examples=model.corpus_count,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYpbw4CPHIxk"
      },
      "outputs": [],
      "source": [
        "x1 = model.wv.vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = data[\"label\"]"
      ],
      "metadata": {
        "id": "RIzUvSzoibYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iTSttC-DV7B",
        "outputId": "4781c849-391a-46d6-8e12-7082af5fa8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6278"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kft7mG__ihRH",
        "outputId": "d1a7bcc6-fede-47f7-d677-26cccf722e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5260"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PszS8p1VRT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633f9cca-54b8-4ea4-f0c2-9c28cad8a092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6278, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x903nWMYDSZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Nvkdq_rDSXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#vectorising for only male words"
      ],
      "metadata": {
        "id": "RK4CAswBB-uy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMRikro2VRQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8ba898-7437-43f0-8640-15caefc42a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10250123, 12302100)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "male_model=gensim.models.Word2Vec(male_word_2,min_count=5)\n",
        "\n",
        "male_model.train(male_word_2,total_examples=male_model.corpus_count,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QWcSnchVQ2s"
      },
      "outputs": [],
      "source": [
        "male_word_vectors=male_model.wv.vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_word_vectors=male_word_vectors[:4000]"
      ],
      "metadata": {
        "id": "DEKlsDXqDt3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(male_word_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pwwuBzzCv_p",
        "outputId": "72234db0-5866-4fdd-8289-d016545fecc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_word_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV3DzikvCv6K",
        "outputId": "c7d0c011-eed3-4e97-e4ac-957cca8f743a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#vectorising for only female words"
      ],
      "metadata": {
        "id": "02Nchx6qCCWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEByue8hVRNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8169e8b-86c4-4884-b08c-9e5694d10134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10798113, 15178350)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "female_model=gensim.models.Word2Vec(female_word_2,min_count=5)\n",
        "\n",
        "female_model.train(female_word_2,total_examples=female_model.corpus_count,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a0ze8xNVQ5l"
      },
      "outputs": [],
      "source": [
        "female_word_vectors=female_model.wv.vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akBe3SWIVRK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a5916e-c4aa-4142-daf6-d978c86ddc44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(female_word_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "female_word_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVCywjTLCKL5",
        "outputId": "ccca02ae-ed09-4b58-cd3f-02c975cfc080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "female_word_vectors=female_word_vectors[:4000]"
      ],
      "metadata": {
        "id": "AvAd8Au0CKJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOLQ8N9rFd5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# end of vectorising"
      ],
      "metadata": {
        "id": "TG4wP2ZPFfAz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZRmKo_UFd1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rl1F8WDEFdy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l7ggPDgVRIN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0XttIDgxQpG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeT2Yl0QxQl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "62430278-86a2-469e-884b-d1529a0f3056"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c354add4404d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(x, y,test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBcgHhYCxQjQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEZIPCU9VUdo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM5MqErUVUb9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrJ_QehzfwU9"
      },
      "source": [
        "#GAN's\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zizb9BM6VUXF"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "NOISE_DIM = 100  # Dimension of the random noise for the generator\n",
        "INPUT_DIM = 100  # Dimension of each word vector\n",
        "HIDDEN_UNITS = 64\n",
        "LEARNING_RATE = 0.0002\n",
        "EPOCHS = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqp-5moXVUVB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNSYfeZsVUSn"
      },
      "outputs": [],
      "source": [
        "# Generator Model\n",
        "generator = Sequential([\n",
        "    Dense(HIDDEN_UNITS, input_dim=NOISE_DIM),\n",
        "    LeakyReLU(alpha=0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(INPUT_DIM)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efmUZYLZVUQA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjXPZ0ejVUOL"
      },
      "outputs": [],
      "source": [
        "# Discriminator Model\n",
        "discriminator = Sequential([\n",
        "    Dense(HIDDEN_UNITS, input_dim=INPUT_DIM),\n",
        "    LeakyReLU(alpha=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYprs36AVUKo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL1TLIirVUH2"
      },
      "outputs": [],
      "source": [
        "# GAN Model\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWCbHcuVUEq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szvpkmFHVUCB"
      },
      "outputs": [],
      "source": [
        "gan = build_gan(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AfQUXLxgTrw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSAeTR3hgTp_",
        "outputId": "5ee41b88-9a80-4dca-ffba-195ee8713fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# Compile models\n",
        "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE), run_eagerly=True)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE))\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRzcc3qJgToH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWZ8nbCgTmH",
        "outputId": "c31be5f7-1f1f-4eb0-e0ce-db7d97adac4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7500/10000 | D Loss: 7.616598129272461 | G Loss: 1.5992936823749915e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7501/10000 | D Loss: 7.678493022918701 | G Loss: 1.5596483535773586e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7502/10000 | D Loss: 7.728957176208496 | G Loss: 1.1298852768959478e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7503/10000 | D Loss: 7.631331443786621 | G Loss: 9.94594529402093e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7504/10000 | D Loss: 7.886969566345215 | G Loss: 1.4094562175159808e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7505/10000 | D Loss: 7.5008440017700195 | G Loss: 1.1735205589502584e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7506/10000 | D Loss: 7.547931671142578 | G Loss: 1.474842520110542e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7507/10000 | D Loss: 7.588517189025879 | G Loss: 1.288589942305407e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7508/10000 | D Loss: 7.637767791748047 | G Loss: 1.206768729389296e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7509/10000 | D Loss: 7.542298316955566 | G Loss: 1.719767169561237e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7510/10000 | D Loss: 7.755776882171631 | G Loss: 1.7706510107018403e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7511/10000 | D Loss: 7.563196659088135 | G Loss: 1.30120201902173e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7512/10000 | D Loss: 7.625560283660889 | G Loss: 1.327939116890775e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7513/10000 | D Loss: 7.653672695159912 | G Loss: 1.2751140729960753e-06\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 7514/10000 | D Loss: 7.481222152709961 | G Loss: 1.3017645414947765e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7515/10000 | D Loss: 7.638670921325684 | G Loss: 9.87020257525728e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7516/10000 | D Loss: 7.456908226013184 | G Loss: 1.045440512825735e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7517/10000 | D Loss: 7.588099956512451 | G Loss: 2.009774334510439e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7518/10000 | D Loss: 7.538311958312988 | G Loss: 1.6499477624165593e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7519/10000 | D Loss: 7.748525142669678 | G Loss: 1.2263744793017395e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7520/10000 | D Loss: 7.7238359451293945 | G Loss: 1.135367256210884e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7521/10000 | D Loss: 7.681268692016602 | G Loss: 1.1652931561911828e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7522/10000 | D Loss: 7.648542404174805 | G Loss: 1.5616162727383198e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7523/10000 | D Loss: 7.578153610229492 | G Loss: 1.6029969174269354e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7524/10000 | D Loss: 7.794878005981445 | G Loss: 1.3916358057031175e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7525/10000 | D Loss: 7.478667259216309 | G Loss: 1.1504301937748096e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7526/10000 | D Loss: 7.564247131347656 | G Loss: 8.809392397779447e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7527/10000 | D Loss: 7.538701057434082 | G Loss: 1.3779606433672598e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7528/10000 | D Loss: 7.543868541717529 | G Loss: 1.1695277635226375e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7529/10000 | D Loss: 7.527999401092529 | G Loss: 9.471820021644817e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7530/10000 | D Loss: 7.5998077392578125 | G Loss: 1.2103082553949207e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7531/10000 | D Loss: 7.60603141784668 | G Loss: 1.4049970786800259e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7532/10000 | D Loss: 7.5500617027282715 | G Loss: 1.1644772257568548e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7533/10000 | D Loss: 7.88137674331665 | G Loss: 1.0790558917506132e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7534/10000 | D Loss: 7.623857498168945 | G Loss: 1.2367133876978187e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7535/10000 | D Loss: 7.596096992492676 | G Loss: 1.0172802831220906e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7536/10000 | D Loss: 7.528263092041016 | G Loss: 1.2824473287764704e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7537/10000 | D Loss: 7.532837867736816 | G Loss: 1.5704753195677768e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7538/10000 | D Loss: 7.637120723724365 | G Loss: 1.1301196991553297e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7539/10000 | D Loss: 7.582375526428223 | G Loss: 1.4085203474678565e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7540/10000 | D Loss: 7.607487678527832 | G Loss: 9.901382327370811e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7541/10000 | D Loss: 7.526464939117432 | G Loss: 1.2881224620286957e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7542/10000 | D Loss: 7.773497581481934 | G Loss: 1.6953745216596872e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7543/10000 | D Loss: 7.683879852294922 | G Loss: 1.5556388461845927e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7544/10000 | D Loss: 7.667872905731201 | G Loss: 1.5691625776526053e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7545/10000 | D Loss: 7.6216325759887695 | G Loss: 1.2375542155496078e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7546/10000 | D Loss: 7.65046501159668 | G Loss: 1.347706870546972e-06\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 7547/10000 | D Loss: 7.646688461303711 | G Loss: 1.690450744717964e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7548/10000 | D Loss: 7.7885541915893555 | G Loss: 1.4884850543239736e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7549/10000 | D Loss: 7.538524627685547 | G Loss: 1.90924924936553e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7550/10000 | D Loss: 7.571717262268066 | G Loss: 1.2395187241054373e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7551/10000 | D Loss: 7.737462043762207 | G Loss: 1.2733086123262183e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7552/10000 | D Loss: 7.895421504974365 | G Loss: 1.0567139270278858e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7553/10000 | D Loss: 7.626780986785889 | G Loss: 9.542836778564379e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7554/10000 | D Loss: 7.6563262939453125 | G Loss: 1.4722573951075901e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7555/10000 | D Loss: 7.595118045806885 | G Loss: 1.4131134093986475e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7556/10000 | D Loss: 7.680671215057373 | G Loss: 1.5468051515199477e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7557/10000 | D Loss: 7.652386665344238 | G Loss: 1.2780565157299861e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7558/10000 | D Loss: 7.687989234924316 | G Loss: 1.1562838153622579e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7559/10000 | D Loss: 7.556668281555176 | G Loss: 1.4249612831918057e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7560/10000 | D Loss: 7.732056617736816 | G Loss: 1.4440515769820195e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7561/10000 | D Loss: 7.589437484741211 | G Loss: 1.3809238907924737e-06\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 7562/10000 | D Loss: 7.704377174377441 | G Loss: 3.915343313565245e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7563/10000 | D Loss: 7.640475749969482 | G Loss: 1.122386038332479e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7564/10000 | D Loss: 7.604226112365723 | G Loss: 1.5723675232948153e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7565/10000 | D Loss: 7.745917797088623 | G Loss: 1.474746909480018e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7566/10000 | D Loss: 7.595475196838379 | G Loss: 1.7082106751331594e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7567/10000 | D Loss: 7.697461128234863 | G Loss: 1.6223223155975575e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7568/10000 | D Loss: 7.5382490158081055 | G Loss: 1.2343436992523493e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7569/10000 | D Loss: 7.754024982452393 | G Loss: 8.324208238263964e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7570/10000 | D Loss: 7.775347709655762 | G Loss: 1.7507157963336795e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7571/10000 | D Loss: 7.6952009201049805 | G Loss: 1.1696727142407326e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7572/10000 | D Loss: 7.711572647094727 | G Loss: 1.5601852965119178e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7573/10000 | D Loss: 7.696074485778809 | G Loss: 1.0714247764553875e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7574/10000 | D Loss: 7.552765846252441 | G Loss: 1.5744892607472138e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7575/10000 | D Loss: 7.56032657623291 | G Loss: 1.32644890982192e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7576/10000 | D Loss: 7.778748512268066 | G Loss: 9.468789130551158e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7577/10000 | D Loss: 7.566615104675293 | G Loss: 1.2874329513579141e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7578/10000 | D Loss: 7.660367012023926 | G Loss: 8.994883273771848e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7579/10000 | D Loss: 7.5129899978637695 | G Loss: 1.3138678696122952e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7580/10000 | D Loss: 7.606739044189453 | G Loss: 9.42348663102166e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7581/10000 | D Loss: 7.822425842285156 | G Loss: 1.5107798390090466e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7582/10000 | D Loss: 7.5456132888793945 | G Loss: 1.03883326119103e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7583/10000 | D Loss: 7.550574779510498 | G Loss: 1.2465106919989921e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7584/10000 | D Loss: 7.70436429977417 | G Loss: 1.0719429610617226e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7585/10000 | D Loss: 7.644731521606445 | G Loss: 1.1953446801271639e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7586/10000 | D Loss: 7.573015213012695 | G Loss: 1.9270537450211123e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7587/10000 | D Loss: 7.708195686340332 | G Loss: 1.9536714717105497e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7588/10000 | D Loss: 7.686991214752197 | G Loss: 1.5119755971682025e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7589/10000 | D Loss: 7.675500869750977 | G Loss: 8.46907880713843e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7590/10000 | D Loss: 7.837521553039551 | G Loss: 1.569597998241079e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7591/10000 | D Loss: 7.7712907791137695 | G Loss: 9.339026973975706e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7592/10000 | D Loss: 7.510492324829102 | G Loss: 1.1425983075241675e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7593/10000 | D Loss: 7.642940521240234 | G Loss: 1.3795827271678718e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7594/10000 | D Loss: 7.6559038162231445 | G Loss: 8.716347679182945e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7595/10000 | D Loss: 7.484743118286133 | G Loss: 1.4899703728588065e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7596/10000 | D Loss: 7.550138473510742 | G Loss: 1.2195022236483055e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7597/10000 | D Loss: 7.546069145202637 | G Loss: 9.408030905433407e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7598/10000 | D Loss: 7.601711750030518 | G Loss: 1.276116336157429e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7599/10000 | D Loss: 7.626283645629883 | G Loss: 9.075614570974722e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7600/10000 | D Loss: 7.671411037445068 | G Loss: 1.1815742482212954e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7601/10000 | D Loss: 7.531499862670898 | G Loss: 1.610490471648518e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7602/10000 | D Loss: 7.780599594116211 | G Loss: 1.2404667586451978e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7603/10000 | D Loss: 7.6623759269714355 | G Loss: 1.3267651866044616e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7604/10000 | D Loss: 7.595880508422852 | G Loss: 1.2747671007673489e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7605/10000 | D Loss: 7.604040145874023 | G Loss: 8.444825425613089e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7606/10000 | D Loss: 7.684811592102051 | G Loss: 1.5069044820847921e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7607/10000 | D Loss: 7.900022983551025 | G Loss: 9.309627557740896e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7608/10000 | D Loss: 7.809693813323975 | G Loss: 1.7938225482794223e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7609/10000 | D Loss: 7.669676303863525 | G Loss: 2.249005092380685e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7610/10000 | D Loss: 7.660131931304932 | G Loss: 1.1894265981027274e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7611/10000 | D Loss: 7.56756067276001 | G Loss: 2.0205961845931597e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7612/10000 | D Loss: 7.45134162902832 | G Loss: 3.0744085961487144e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7613/10000 | D Loss: 7.495598316192627 | G Loss: 1.5870487004576717e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7614/10000 | D Loss: 7.487085342407227 | G Loss: 2.00705585484684e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7615/10000 | D Loss: 7.593114852905273 | G Loss: 1.373593704556697e-06\n",
            "2/2 [==============================] - 0s 31ms/step\n",
            "Epoch 7616/10000 | D Loss: 7.679594993591309 | G Loss: 1.6180282500499743e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7617/10000 | D Loss: 7.625856399536133 | G Loss: 1.7394866063114023e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7618/10000 | D Loss: 7.649769306182861 | G Loss: 1.157564838649705e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7619/10000 | D Loss: 7.694608688354492 | G Loss: 9.159841738437535e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7620/10000 | D Loss: 7.738724708557129 | G Loss: 2.032426891673822e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7621/10000 | D Loss: 7.572119235992432 | G Loss: 1.6419643316112342e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7622/10000 | D Loss: 7.6600341796875 | G Loss: 1.197569531541376e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7623/10000 | D Loss: 7.670358657836914 | G Loss: 1.7555763633936294e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7624/10000 | D Loss: 7.454921722412109 | G Loss: 1.2587440778588643e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7625/10000 | D Loss: 7.633756160736084 | G Loss: 1.3598195209851838e-06\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 7626/10000 | D Loss: 7.553445816040039 | G Loss: 1.419699174221023e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7627/10000 | D Loss: 7.736044883728027 | G Loss: 1.3887870409234893e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7628/10000 | D Loss: 7.577852725982666 | G Loss: 1.1897564036189578e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7629/10000 | D Loss: 7.611269950866699 | G Loss: 1.3521241726266453e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7630/10000 | D Loss: 7.534969329833984 | G Loss: 1.1868310139107052e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7631/10000 | D Loss: 7.656062126159668 | G Loss: 1.2229468211444328e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7632/10000 | D Loss: 7.64958381652832 | G Loss: 1.3477501852321438e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7633/10000 | D Loss: 7.680548667907715 | G Loss: 1.1407055353629403e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7634/10000 | D Loss: 7.66682767868042 | G Loss: 1.1482253512440366e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7635/10000 | D Loss: 7.578512191772461 | G Loss: 1.4343131624627858e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7636/10000 | D Loss: 7.599178791046143 | G Loss: 1.266629283236398e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7637/10000 | D Loss: 7.614609241485596 | G Loss: 1.2934287951793522e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7638/10000 | D Loss: 7.696386814117432 | G Loss: 1.0258763722958975e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7639/10000 | D Loss: 7.587497234344482 | G Loss: 2.1858727450307924e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7640/10000 | D Loss: 7.417858600616455 | G Loss: 1.6570231764490018e-06\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7641/10000 | D Loss: 7.752505302429199 | G Loss: 2.4407277123827953e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7642/10000 | D Loss: 7.415704727172852 | G Loss: 1.4554384506482165e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7643/10000 | D Loss: 7.850785255432129 | G Loss: 1.7342449609714095e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7644/10000 | D Loss: 7.5172224044799805 | G Loss: 1.1839767921628663e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7645/10000 | D Loss: 7.763824939727783 | G Loss: 1.9803646864602342e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7646/10000 | D Loss: 7.880544662475586 | G Loss: 1.3666825680047623e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7647/10000 | D Loss: 7.704888343811035 | G Loss: 1.0840495860975352e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7648/10000 | D Loss: 7.626409530639648 | G Loss: 1.4616034604841843e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7649/10000 | D Loss: 7.6842522621154785 | G Loss: 1.4677733588541741e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7650/10000 | D Loss: 7.574860572814941 | G Loss: 1.3580938684754074e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7651/10000 | D Loss: 7.569280624389648 | G Loss: 9.622730203773244e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7652/10000 | D Loss: 7.602786064147949 | G Loss: 1.1788690699177096e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7653/10000 | D Loss: 7.728111267089844 | G Loss: 1.53033170136041e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7654/10000 | D Loss: 7.590872764587402 | G Loss: 1.2357266996332328e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7655/10000 | D Loss: 7.665919780731201 | G Loss: 1.0999560799973551e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7656/10000 | D Loss: 7.5576395988464355 | G Loss: 1.0205988019151846e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7657/10000 | D Loss: 7.743391513824463 | G Loss: 8.991685263026739e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7658/10000 | D Loss: 7.53399133682251 | G Loss: 1.13525618417043e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7659/10000 | D Loss: 7.791359901428223 | G Loss: 1.1345556458763895e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7660/10000 | D Loss: 7.464753150939941 | G Loss: 2.1289088181219995e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7661/10000 | D Loss: 7.697700023651123 | G Loss: 1.020366653392557e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7662/10000 | D Loss: 7.694064140319824 | G Loss: 1.1685083336487878e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7663/10000 | D Loss: 7.640534400939941 | G Loss: 1.4369670680025592e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7664/10000 | D Loss: 7.546720504760742 | G Loss: 2.12016516343283e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7665/10000 | D Loss: 7.66774845123291 | G Loss: 1.2499808690336067e-06\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 7666/10000 | D Loss: 7.656496047973633 | G Loss: 1.2261709798622178e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7667/10000 | D Loss: 7.7504377365112305 | G Loss: 8.912631983548636e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7668/10000 | D Loss: 7.587856769561768 | G Loss: 1.656150743656326e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7669/10000 | D Loss: 7.629902362823486 | G Loss: 7.958722676448815e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7670/10000 | D Loss: 7.5444865226745605 | G Loss: 1.2395277053656173e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7671/10000 | D Loss: 7.801641941070557 | G Loss: 1.1417309906391893e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7672/10000 | D Loss: 7.604217052459717 | G Loss: 1.3572630450653378e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7673/10000 | D Loss: 7.680505275726318 | G Loss: 1.581036372044764e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7674/10000 | D Loss: 7.596429824829102 | G Loss: 1.2199931234135875e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7675/10000 | D Loss: 7.513227462768555 | G Loss: 1.506502712800284e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7676/10000 | D Loss: 7.577695846557617 | G Loss: 1.475443241361063e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7677/10000 | D Loss: 7.511532783508301 | G Loss: 1.6660812889313092e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7678/10000 | D Loss: 7.650630950927734 | G Loss: 9.060649404091237e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7679/10000 | D Loss: 7.638979911804199 | G Loss: 8.95450966709177e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7680/10000 | D Loss: 7.632951736450195 | G Loss: 2.0135403246968053e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7681/10000 | D Loss: 7.687928199768066 | G Loss: 2.0890670384687837e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7682/10000 | D Loss: 7.68144416809082 | G Loss: 1.9560511645977385e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7683/10000 | D Loss: 7.735838890075684 | G Loss: 1.0896035291807493e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7684/10000 | D Loss: 7.784198760986328 | G Loss: 1.3736338360104128e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7685/10000 | D Loss: 7.694531440734863 | G Loss: 1.0291637408954557e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7686/10000 | D Loss: 7.722966194152832 | G Loss: 8.804761364444857e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7687/10000 | D Loss: 7.6838178634643555 | G Loss: 1.214017856909777e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7688/10000 | D Loss: 7.687505722045898 | G Loss: 8.022109341254691e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7689/10000 | D Loss: 7.770045757293701 | G Loss: 1.3298359817781602e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7690/10000 | D Loss: 7.510337829589844 | G Loss: 1.4872420024403255e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7691/10000 | D Loss: 7.582803249359131 | G Loss: 1.3569577959060553e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7692/10000 | D Loss: 7.5882086753845215 | G Loss: 1.2967614111403236e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7693/10000 | D Loss: 7.649890899658203 | G Loss: 1.3356083172766375e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7694/10000 | D Loss: 7.768487930297852 | G Loss: 1.7189570371556329e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7695/10000 | D Loss: 7.616647243499756 | G Loss: 1.251862954632088e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7696/10000 | D Loss: 7.625556945800781 | G Loss: 1.4486381587630603e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7697/10000 | D Loss: 7.9098100662231445 | G Loss: 1.6828473690111423e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7698/10000 | D Loss: 7.432181358337402 | G Loss: 1.063965100911446e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7699/10000 | D Loss: 7.629241466522217 | G Loss: 1.4663210095022805e-06\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 7700/10000 | D Loss: 7.619198799133301 | G Loss: 8.732563969715557e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7701/10000 | D Loss: 7.715366363525391 | G Loss: 1.983457423193613e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7702/10000 | D Loss: 7.8261919021606445 | G Loss: 1.3457720342557877e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7703/10000 | D Loss: 7.67572021484375 | G Loss: 1.718455905574956e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7704/10000 | D Loss: 7.761443138122559 | G Loss: 1.1169377103215083e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7705/10000 | D Loss: 7.670799255371094 | G Loss: 1.0216431292064954e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7706/10000 | D Loss: 7.824085235595703 | G Loss: 1.0826024663401768e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7707/10000 | D Loss: 7.7730560302734375 | G Loss: 9.065133212970977e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7708/10000 | D Loss: 7.71044921875 | G Loss: 1.2223304111103062e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7709/10000 | D Loss: 7.735019683837891 | G Loss: 9.326283247901301e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7710/10000 | D Loss: 7.825064659118652 | G Loss: 1.369520532534807e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7711/10000 | D Loss: 7.585209369659424 | G Loss: 1.4501584928439115e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7712/10000 | D Loss: 7.722206115722656 | G Loss: 9.305799153480621e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7713/10000 | D Loss: 7.8026323318481445 | G Loss: 1.1276581517449813e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7714/10000 | D Loss: 7.613134384155273 | G Loss: 1.741368578223046e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7715/10000 | D Loss: 7.652569770812988 | G Loss: 1.4260724583436968e-06\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 7716/10000 | D Loss: 7.623713493347168 | G Loss: 1.2217933544889092e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7717/10000 | D Loss: 7.763449192047119 | G Loss: 1.6298148466376006e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7718/10000 | D Loss: 7.722586631774902 | G Loss: 9.211991027768818e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7719/10000 | D Loss: 7.786787986755371 | G Loss: 1.08065478343633e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7720/10000 | D Loss: 7.750761985778809 | G Loss: 9.40261429605016e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7721/10000 | D Loss: 7.575018405914307 | G Loss: 1.3397656175584416e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7722/10000 | D Loss: 7.696267127990723 | G Loss: 9.173771786663565e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7723/10000 | D Loss: 7.560405731201172 | G Loss: 1.289418150918209e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7724/10000 | D Loss: 7.762691497802734 | G Loss: 1.0615885912557133e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7725/10000 | D Loss: 7.514521598815918 | G Loss: 8.962090305431047e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7726/10000 | D Loss: 7.555543899536133 | G Loss: 7.749582096039376e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7727/10000 | D Loss: 7.829084396362305 | G Loss: 1.5146908936003456e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7728/10000 | D Loss: 7.749088287353516 | G Loss: 1.1199102800674154e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7729/10000 | D Loss: 7.775087356567383 | G Loss: 1.0748722161224578e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7730/10000 | D Loss: 7.627707481384277 | G Loss: 1.9020969830307877e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7731/10000 | D Loss: 7.728906631469727 | G Loss: 9.043929480867519e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7732/10000 | D Loss: 7.625759124755859 | G Loss: 1.5508646811213112e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7733/10000 | D Loss: 7.6384382247924805 | G Loss: 9.946687669071252e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7734/10000 | D Loss: 7.708243370056152 | G Loss: 1.062621890923765e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7735/10000 | D Loss: 7.620489120483398 | G Loss: 1.0744599876488792e-06\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 7736/10000 | D Loss: 7.804932594299316 | G Loss: 1.3243810599306016e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7737/10000 | D Loss: 7.776512145996094 | G Loss: 1.2044024515489582e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7738/10000 | D Loss: 7.700984954833984 | G Loss: 1.2720204267679946e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7739/10000 | D Loss: 7.714910507202148 | G Loss: 1.3623264294437831e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7740/10000 | D Loss: 7.597499847412109 | G Loss: 1.2640189197554719e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7741/10000 | D Loss: 7.766298294067383 | G Loss: 1.404887143507949e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7742/10000 | D Loss: 7.640789985656738 | G Loss: 1.3240248790680198e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7743/10000 | D Loss: 7.811939239501953 | G Loss: 8.515269200870534e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7744/10000 | D Loss: 7.742532730102539 | G Loss: 8.242839157901471e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7745/10000 | D Loss: 7.827254295349121 | G Loss: 1.47893774737895e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7746/10000 | D Loss: 7.751770973205566 | G Loss: 1.2400255400280003e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7747/10000 | D Loss: 7.6160888671875 | G Loss: 9.082384622161044e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7748/10000 | D Loss: 7.620086193084717 | G Loss: 1.104690454667434e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7749/10000 | D Loss: 7.557862758636475 | G Loss: 1.135645788963302e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7750/10000 | D Loss: 7.84666633605957 | G Loss: 1.1775737220887095e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7751/10000 | D Loss: 7.647432327270508 | G Loss: 1.5726598121545976e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7752/10000 | D Loss: 7.718596458435059 | G Loss: 1.5553164303128142e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7753/10000 | D Loss: 7.469473361968994 | G Loss: 1.2852917734562652e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7754/10000 | D Loss: 7.665121555328369 | G Loss: 9.77273430180503e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7755/10000 | D Loss: 7.821924209594727 | G Loss: 1.0484548056410858e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7756/10000 | D Loss: 7.6632866859436035 | G Loss: 1.3438072983262828e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7757/10000 | D Loss: 7.763993263244629 | G Loss: 1.2218362144267303e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7758/10000 | D Loss: 7.821290969848633 | G Loss: 1.6088649772427743e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7759/10000 | D Loss: 7.615791320800781 | G Loss: 1.052065272233449e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7760/10000 | D Loss: 7.786047458648682 | G Loss: 1.062201249624195e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7761/10000 | D Loss: 7.631678581237793 | G Loss: 1.6561791653657565e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7762/10000 | D Loss: 7.699763298034668 | G Loss: 1.0155623613172793e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7763/10000 | D Loss: 7.743577003479004 | G Loss: 8.546123808628181e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7764/10000 | D Loss: 7.6091718673706055 | G Loss: 9.752433243193082e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7765/10000 | D Loss: 7.684205532073975 | G Loss: 1.0871744962059893e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7766/10000 | D Loss: 7.808656692504883 | G Loss: 1.3409610346570844e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7767/10000 | D Loss: 7.5930495262146 | G Loss: 1.3286232842801837e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7768/10000 | D Loss: 7.796374320983887 | G Loss: 1.4579006801795913e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7769/10000 | D Loss: 7.886319160461426 | G Loss: 1.822247213567607e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7770/10000 | D Loss: 7.665190696716309 | G Loss: 1.339598838967504e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7771/10000 | D Loss: 7.604372024536133 | G Loss: 1.3127486226949259e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7772/10000 | D Loss: 7.632983207702637 | G Loss: 1.0549276794336038e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7773/10000 | D Loss: 7.550867080688477 | G Loss: 9.980498134609661e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7774/10000 | D Loss: 7.832582950592041 | G Loss: 8.510687621310353e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7775/10000 | D Loss: 7.900425910949707 | G Loss: 1.2077424571543816e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7776/10000 | D Loss: 7.8046183586120605 | G Loss: 1.435369995306246e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7777/10000 | D Loss: 7.713474273681641 | G Loss: 1.0104319017045782e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7778/10000 | D Loss: 7.806768417358398 | G Loss: 1.5392170098493807e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7779/10000 | D Loss: 7.700992107391357 | G Loss: 1.4557655276803416e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7780/10000 | D Loss: 7.6264543533325195 | G Loss: 1.5447213854713482e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 7781/10000 | D Loss: 7.571778297424316 | G Loss: 1.261150828213431e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7782/10000 | D Loss: 7.836477279663086 | G Loss: 9.995953860197915e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7783/10000 | D Loss: 7.700070858001709 | G Loss: 1.140206222771667e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7784/10000 | D Loss: 7.631913185119629 | G Loss: 9.419775892638427e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7785/10000 | D Loss: 7.5983428955078125 | G Loss: 5.451831839309307e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7786/10000 | D Loss: 7.698381423950195 | G Loss: 8.207548489735927e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7787/10000 | D Loss: 7.617427825927734 | G Loss: 1.5375910606962861e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7788/10000 | D Loss: 7.654969215393066 | G Loss: 2.151337412215071e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7789/10000 | D Loss: 7.715178966522217 | G Loss: 8.465640917165729e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7790/10000 | D Loss: 7.764160633087158 | G Loss: 1.1377273949619848e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7791/10000 | D Loss: 7.763698577880859 | G Loss: 1.6603229369138717e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7792/10000 | D Loss: 7.5673828125 | G Loss: 9.22759454624611e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7793/10000 | D Loss: 7.587383270263672 | G Loss: 9.83516770247661e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7794/10000 | D Loss: 7.7764739990234375 | G Loss: 1.3013254829274956e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7795/10000 | D Loss: 7.6226091384887695 | G Loss: 3.5515868148650043e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7796/10000 | D Loss: 7.789247989654541 | G Loss: 1.2276907455088804e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7797/10000 | D Loss: 7.749547004699707 | G Loss: 2.0250540728738997e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7798/10000 | D Loss: 7.73377799987793 | G Loss: 1.0336910918340436e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7799/10000 | D Loss: 7.769838333129883 | G Loss: 1.2468403838283848e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7800/10000 | D Loss: 7.716647148132324 | G Loss: 8.153477324412961e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7801/10000 | D Loss: 7.800436973571777 | G Loss: 8.438111080977251e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7802/10000 | D Loss: 7.851016044616699 | G Loss: 7.897155569480674e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7803/10000 | D Loss: 7.6988444328308105 | G Loss: 1.030725229611562e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7804/10000 | D Loss: 7.653678894042969 | G Loss: 1.2938933195982827e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7805/10000 | D Loss: 7.403002738952637 | G Loss: 8.6185099235081e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7806/10000 | D Loss: 7.67115592956543 | G Loss: 1.149550371337682e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7807/10000 | D Loss: 7.72364616394043 | G Loss: 2.8629665393964387e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7808/10000 | D Loss: 7.7575578689575195 | G Loss: 1.7077568372769747e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7809/10000 | D Loss: 7.77964448928833 | G Loss: 8.864215601533942e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7810/10000 | D Loss: 7.806981563568115 | G Loss: 1.3708192909689387e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7811/10000 | D Loss: 7.807757377624512 | G Loss: 1.1577526493056212e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7812/10000 | D Loss: 7.806358337402344 | G Loss: 1.4108788946032291e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7813/10000 | D Loss: 7.796229362487793 | G Loss: 9.041472139870166e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7814/10000 | D Loss: 7.571771144866943 | G Loss: 1.0771365168693592e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7815/10000 | D Loss: 7.630890846252441 | G Loss: 8.173414016710012e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7816/10000 | D Loss: 7.641412734985352 | G Loss: 1.1078029729105765e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7817/10000 | D Loss: 7.772321701049805 | G Loss: 8.324458349306951e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7818/10000 | D Loss: 7.683871269226074 | G Loss: 9.407694960827939e-07\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7819/10000 | D Loss: 7.738680839538574 | G Loss: 1.508142304373905e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7820/10000 | D Loss: 7.633509635925293 | G Loss: 8.052389830481843e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7821/10000 | D Loss: 7.679934501647949 | G Loss: 1.2169532510597492e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7822/10000 | D Loss: 7.6263508796691895 | G Loss: 1.0970882158289896e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7823/10000 | D Loss: 7.5197649002075195 | G Loss: 1.9271769815532025e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7824/10000 | D Loss: 7.878811359405518 | G Loss: 1.4932688827684615e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7825/10000 | D Loss: 7.627791881561279 | G Loss: 1.046557372319512e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7826/10000 | D Loss: 7.668416976928711 | G Loss: 1.185365817946149e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7827/10000 | D Loss: 7.939208030700684 | G Loss: 1.0815974746947177e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7828/10000 | D Loss: 7.591048240661621 | G Loss: 1.0659599638529471e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7829/10000 | D Loss: 7.715843200683594 | G Loss: 1.1044787697755964e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7830/10000 | D Loss: 7.714879512786865 | G Loss: 1.396630068484228e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7831/10000 | D Loss: 7.699804306030273 | G Loss: 1.560602186145843e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7832/10000 | D Loss: 7.718371391296387 | G Loss: 1.0750668479886372e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7833/10000 | D Loss: 7.792117118835449 | G Loss: 1.1894321687577758e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7834/10000 | D Loss: 7.757052898406982 | G Loss: 9.15056943995296e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7835/10000 | D Loss: 7.667339324951172 | G Loss: 1.1770165428970358e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7836/10000 | D Loss: 7.800517559051514 | G Loss: 1.6253013654932147e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7837/10000 | D Loss: 7.759012222290039 | G Loss: 9.332195531897014e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7838/10000 | D Loss: 7.823871612548828 | G Loss: 1.0855555956368335e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7839/10000 | D Loss: 7.8245158195495605 | G Loss: 1.1687041023833444e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7840/10000 | D Loss: 7.78455924987793 | G Loss: 8.323424935952062e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7841/10000 | D Loss: 7.676080703735352 | G Loss: 1.1073864243371645e-06\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7842/10000 | D Loss: 7.850249290466309 | G Loss: 9.895741186483065e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7843/10000 | D Loss: 7.718242645263672 | G Loss: 6.640892138420895e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7844/10000 | D Loss: 7.8980512619018555 | G Loss: 1.1527774859132478e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7845/10000 | D Loss: 7.772284507751465 | G Loss: 8.588797300035367e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7846/10000 | D Loss: 7.757670879364014 | G Loss: 1.37749907480611e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7847/10000 | D Loss: 7.738959789276123 | G Loss: 1.3754480505667743e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7848/10000 | D Loss: 7.639131546020508 | G Loss: 1.1431384336901829e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7849/10000 | D Loss: 7.78074836730957 | G Loss: 8.301861385007214e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7850/10000 | D Loss: 7.708288192749023 | G Loss: 1.0479033107912983e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7851/10000 | D Loss: 7.717066287994385 | G Loss: 1.1641584478638833e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7852/10000 | D Loss: 7.799839019775391 | G Loss: 1.3359629065234913e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7853/10000 | D Loss: 7.724886894226074 | G Loss: 1.2944728950969875e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7854/10000 | D Loss: 7.554680824279785 | G Loss: 1.1545623692654772e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7855/10000 | D Loss: 7.709626197814941 | G Loss: 1.0990202099492308e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7856/10000 | D Loss: 7.670412540435791 | G Loss: 1.249891738552833e-06\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7857/10000 | D Loss: 7.653136730194092 | G Loss: 9.112301881941676e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7858/10000 | D Loss: 7.6588544845581055 | G Loss: 1.3558772025135113e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7859/10000 | D Loss: 7.806620121002197 | G Loss: 1.7795887288230006e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7860/10000 | D Loss: 7.660122871398926 | G Loss: 1.3391544371188502e-06\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "Epoch 7861/10000 | D Loss: 7.730184555053711 | G Loss: 8.610365966887912e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7862/10000 | D Loss: 7.827639579772949 | G Loss: 1.156707298832771e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7863/10000 | D Loss: 7.750426292419434 | G Loss: 1.7337233657599427e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7864/10000 | D Loss: 7.63346004486084 | G Loss: 1.0578064575383905e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7865/10000 | D Loss: 7.71155309677124 | G Loss: 1.3354180055102916e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7866/10000 | D Loss: 7.75471830368042 | G Loss: 1.3247458809928503e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7867/10000 | D Loss: 7.774056911468506 | G Loss: 1.1736252645278e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7868/10000 | D Loss: 7.868546485900879 | G Loss: 1.029034137900453e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7869/10000 | D Loss: 7.635326385498047 | G Loss: 1.111237679651822e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7870/10000 | D Loss: 7.753195762634277 | G Loss: 1.1470107210698188e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7871/10000 | D Loss: 7.7142133712768555 | G Loss: 6.49299067845277e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7872/10000 | D Loss: 7.748369216918945 | G Loss: 1.9772926407313207e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7873/10000 | D Loss: 7.861087799072266 | G Loss: 1.3882959137845319e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7874/10000 | D Loss: 7.560572147369385 | G Loss: 6.854994580862694e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7875/10000 | D Loss: 7.77534294128418 | G Loss: 1.1735214684449602e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7876/10000 | D Loss: 7.671774864196777 | G Loss: 1.5737601870569051e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7877/10000 | D Loss: 7.8057661056518555 | G Loss: 1.1449729981904966e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7878/10000 | D Loss: 7.825357437133789 | G Loss: 1.044000100591802e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7879/10000 | D Loss: 7.892989158630371 | G Loss: 1.1907806083399919e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7880/10000 | D Loss: 7.7334370613098145 | G Loss: 9.133252660831204e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7881/10000 | D Loss: 7.815254211425781 | G Loss: 1.0213834684691392e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7882/10000 | D Loss: 7.726510047912598 | G Loss: 1.5838605804674444e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7883/10000 | D Loss: 7.589628219604492 | G Loss: 9.81851826509228e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7884/10000 | D Loss: 7.763981342315674 | G Loss: 1.541642632219009e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7885/10000 | D Loss: 7.720663070678711 | G Loss: 9.360157946503023e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7886/10000 | D Loss: 7.69849967956543 | G Loss: 6.981445039855316e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7887/10000 | D Loss: 7.878753662109375 | G Loss: 8.657485182084201e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7888/10000 | D Loss: 7.779014587402344 | G Loss: 1.1583726973185549e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7889/10000 | D Loss: 7.878259658813477 | G Loss: 9.036945129992091e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7890/10000 | D Loss: 7.687169075012207 | G Loss: 8.290905384455982e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7891/10000 | D Loss: 7.719080924987793 | G Loss: 1.351471723864961e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7892/10000 | D Loss: 7.669308662414551 | G Loss: 1.0754234835985699e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7893/10000 | D Loss: 7.62635612487793 | G Loss: 9.657151167630218e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7894/10000 | D Loss: 7.800981044769287 | G Loss: 1.2228333616803866e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7895/10000 | D Loss: 7.768454551696777 | G Loss: 8.904893320504925e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7896/10000 | D Loss: 7.701746940612793 | G Loss: 2.5883739454002352e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7897/10000 | D Loss: 7.70423698425293 | G Loss: 1.1925234275622643e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7898/10000 | D Loss: 7.626465797424316 | G Loss: 8.078586688498035e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7899/10000 | D Loss: 7.794970989227295 | G Loss: 1.125477069763292e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7900/10000 | D Loss: 7.752408027648926 | G Loss: 1.0930298230960034e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7901/10000 | D Loss: 7.715577125549316 | G Loss: 1.2298414731048979e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7902/10000 | D Loss: 7.897165298461914 | G Loss: 1.6471808521600906e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7903/10000 | D Loss: 7.735043525695801 | G Loss: 1.3457322438625852e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7904/10000 | D Loss: 7.753435134887695 | G Loss: 9.862028491625097e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7905/10000 | D Loss: 7.572865962982178 | G Loss: 1.1847577070511761e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7906/10000 | D Loss: 7.642951011657715 | G Loss: 8.915257581065816e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7907/10000 | D Loss: 7.770897388458252 | G Loss: 1.1904504617632483e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7908/10000 | D Loss: 7.696953296661377 | G Loss: 1.23045560940227e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7909/10000 | D Loss: 7.790525436401367 | G Loss: 1.088315229935688e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7910/10000 | D Loss: 7.757569313049316 | G Loss: 1.2576610970427282e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7911/10000 | D Loss: 7.736786842346191 | G Loss: 2.332577423658222e-06\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 7912/10000 | D Loss: 7.722994804382324 | G Loss: 1.6293873841277673e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7913/10000 | D Loss: 7.68193244934082 | G Loss: 1.0430121619720012e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7914/10000 | D Loss: 7.8420820236206055 | G Loss: 1.5700569520049612e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7915/10000 | D Loss: 7.800718307495117 | G Loss: 6.214713721419685e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7916/10000 | D Loss: 7.867194175720215 | G Loss: 1.1039621767849894e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7917/10000 | D Loss: 7.720884323120117 | G Loss: 1.1149911642860388e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7918/10000 | D Loss: 7.794063568115234 | G Loss: 1.523197738606541e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7919/10000 | D Loss: 7.829344749450684 | G Loss: 1.4676777482236503e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7920/10000 | D Loss: 7.791158199310303 | G Loss: 1.0164208106289152e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7921/10000 | D Loss: 7.678234577178955 | G Loss: 8.293022801808547e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7922/10000 | D Loss: 7.866404056549072 | G Loss: 1.163976889984042e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7923/10000 | D Loss: 7.891947269439697 | G Loss: 1.2502007393777603e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7924/10000 | D Loss: 7.632401466369629 | G Loss: 1.2053886848661932e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7925/10000 | D Loss: 7.844141960144043 | G Loss: 1.4581239611288765e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7926/10000 | D Loss: 7.616440773010254 | G Loss: 1.1821192629213328e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7927/10000 | D Loss: 7.755146026611328 | G Loss: 1.0786508255478111e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7928/10000 | D Loss: 7.610002517700195 | G Loss: 1.1444074061728315e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7929/10000 | D Loss: 7.64463472366333 | G Loss: 5.816333441543975e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7930/10000 | D Loss: 7.669508457183838 | G Loss: 1.5522456351391156e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7931/10000 | D Loss: 7.729331970214844 | G Loss: 8.553384418519272e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7932/10000 | D Loss: 7.740265369415283 | G Loss: 1.1460782616268261e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7933/10000 | D Loss: 7.632584571838379 | G Loss: 9.670350209489698e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7934/10000 | D Loss: 7.616464138031006 | G Loss: 8.151409929268993e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7935/10000 | D Loss: 7.730962753295898 | G Loss: 9.805544323171489e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7936/10000 | D Loss: 7.792743682861328 | G Loss: 1.196209950649063e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7937/10000 | D Loss: 7.917644023895264 | G Loss: 1.6727191223253612e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7938/10000 | D Loss: 7.723240852355957 | G Loss: 8.754313398640079e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7939/10000 | D Loss: 7.690582275390625 | G Loss: 1.1316594736854313e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7940/10000 | D Loss: 7.576210975646973 | G Loss: 1.1539966635609744e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7941/10000 | D Loss: 7.77032470703125 | G Loss: 9.044997000273725e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7942/10000 | D Loss: 7.7672648429870605 | G Loss: 8.37317884361255e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7943/10000 | D Loss: 7.831798553466797 | G Loss: 8.512354270351352e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7944/10000 | D Loss: 7.869756698608398 | G Loss: 1.0709331945690792e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7945/10000 | D Loss: 7.696475982666016 | G Loss: 1.178679781332903e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7946/10000 | D Loss: 7.752312183380127 | G Loss: 8.0450769246454e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 7947/10000 | D Loss: 7.7490339279174805 | G Loss: 8.306567451654701e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7948/10000 | D Loss: 7.738622665405273 | G Loss: 8.368357953258965e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7949/10000 | D Loss: 7.687145233154297 | G Loss: 8.836501024234167e-07\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 7950/10000 | D Loss: 7.981998443603516 | G Loss: 8.790221386334451e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7951/10000 | D Loss: 7.826352596282959 | G Loss: 1.699711219771416e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7952/10000 | D Loss: 7.861710548400879 | G Loss: 7.354927902269992e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7953/10000 | D Loss: 7.743553638458252 | G Loss: 1.1037078593290062e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7954/10000 | D Loss: 7.658170223236084 | G Loss: 1.6899531374292565e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7955/10000 | D Loss: 7.731252670288086 | G Loss: 1.0597548225632636e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7956/10000 | D Loss: 7.773292064666748 | G Loss: 9.501266617917281e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7957/10000 | D Loss: 7.848567008972168 | G Loss: 1.080743800230266e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7958/10000 | D Loss: 7.8545989990234375 | G Loss: 8.421810662184726e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7959/10000 | D Loss: 7.758871078491211 | G Loss: 8.691014272699249e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7960/10000 | D Loss: 7.7531914710998535 | G Loss: 1.0526630376261892e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7961/10000 | D Loss: 7.684759140014648 | G Loss: 7.538426416431321e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7962/10000 | D Loss: 7.609777927398682 | G Loss: 1.7610993836569833e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7963/10000 | D Loss: 7.834527015686035 | G Loss: 9.941425105353119e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7964/10000 | D Loss: 7.830813407897949 | G Loss: 8.347354309989896e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7965/10000 | D Loss: 7.85368537902832 | G Loss: 8.353738394362153e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7966/10000 | D Loss: 7.956040382385254 | G Loss: 1.2820210031350143e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7967/10000 | D Loss: 7.682887077331543 | G Loss: 1.1395807177905226e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7968/10000 | D Loss: 7.904777526855469 | G Loss: 8.260560093731328e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7969/10000 | D Loss: 7.8403520584106445 | G Loss: 1.180157369162771e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7970/10000 | D Loss: 7.692729949951172 | G Loss: 9.865169658951345e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7971/10000 | D Loss: 7.783071041107178 | G Loss: 9.692603271105327e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7972/10000 | D Loss: 7.725976467132568 | G Loss: 9.732152648211922e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7973/10000 | D Loss: 7.814617156982422 | G Loss: 9.742350357555551e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7974/10000 | D Loss: 7.904568195343018 | G Loss: 9.039349038175715e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7975/10000 | D Loss: 7.880873203277588 | G Loss: 1.105782075683237e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7976/10000 | D Loss: 7.665122985839844 | G Loss: 1.0975037412208621e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7977/10000 | D Loss: 7.832086086273193 | G Loss: 1.469181142965681e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7978/10000 | D Loss: 7.858509063720703 | G Loss: 1.7151850215668674e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7979/10000 | D Loss: 7.759248733520508 | G Loss: 8.598516956226376e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7980/10000 | D Loss: 7.857491493225098 | G Loss: 1.0584921028566896e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7981/10000 | D Loss: 7.6219682693481445 | G Loss: 9.874493116512895e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7982/10000 | D Loss: 7.627378940582275 | G Loss: 1.0286177030138788e-06\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 7983/10000 | D Loss: 7.68414306640625 | G Loss: 1.140405515798193e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7984/10000 | D Loss: 7.711618423461914 | G Loss: 9.577255468684598e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7985/10000 | D Loss: 7.7511396408081055 | G Loss: 9.420127184966987e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7986/10000 | D Loss: 7.818399906158447 | G Loss: 8.623932785667421e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7987/10000 | D Loss: 7.744061470031738 | G Loss: 1.167800974144484e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7988/10000 | D Loss: 7.844412326812744 | G Loss: 1.4345126828629873e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7989/10000 | D Loss: 7.737863063812256 | G Loss: 9.078892162506236e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7990/10000 | D Loss: 7.729555130004883 | G Loss: 1.1621593785093864e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7991/10000 | D Loss: 7.789107322692871 | G Loss: 9.591639127393137e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 7992/10000 | D Loss: 7.805036544799805 | G Loss: 1.2254013199708425e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7993/10000 | D Loss: 7.762939929962158 | G Loss: 8.358786658391182e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7994/10000 | D Loss: 7.621063709259033 | G Loss: 1.3721992218052037e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7995/10000 | D Loss: 7.724206924438477 | G Loss: 8.058056550908077e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7996/10000 | D Loss: 7.750313758850098 | G Loss: 1.091002332032076e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7997/10000 | D Loss: 7.7388811111450195 | G Loss: 9.979909236790263e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7998/10000 | D Loss: 7.637280464172363 | G Loss: 8.46361899675685e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7999/10000 | D Loss: 7.822013854980469 | G Loss: 6.528546805384394e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8000/10000 | D Loss: 7.6766557693481445 | G Loss: 1.6645761888867128e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8001/10000 | D Loss: 7.889005184173584 | G Loss: 1.0884596122195944e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8002/10000 | D Loss: 7.751154899597168 | G Loss: 1.3135454537405167e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8003/10000 | D Loss: 7.666405200958252 | G Loss: 1.082303015209618e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8004/10000 | D Loss: 7.667744159698486 | G Loss: 8.537745088688098e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8005/10000 | D Loss: 7.6493353843688965 | G Loss: 8.723943096811126e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8006/10000 | D Loss: 7.722211837768555 | G Loss: 8.129116508825973e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8007/10000 | D Loss: 7.763134002685547 | G Loss: 1.0374149042036152e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8008/10000 | D Loss: 7.733198165893555 | G Loss: 7.047342478472274e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8009/10000 | D Loss: 7.71502685546875 | G Loss: 8.512356544088107e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8010/10000 | D Loss: 7.660819053649902 | G Loss: 1.1994738997600507e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8011/10000 | D Loss: 7.7568745613098145 | G Loss: 1.1326949334033998e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8012/10000 | D Loss: 7.764555931091309 | G Loss: 8.899996259970067e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8013/10000 | D Loss: 7.792117595672607 | G Loss: 1.2496318504418014e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8014/10000 | D Loss: 7.9057841300964355 | G Loss: 1.537103116788785e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8015/10000 | D Loss: 7.799932479858398 | G Loss: 1.1978638667642372e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8016/10000 | D Loss: 7.726526260375977 | G Loss: 6.160298084978422e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8017/10000 | D Loss: 7.70908260345459 | G Loss: 8.293786208923848e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8018/10000 | D Loss: 7.825423240661621 | G Loss: 2.084400421153987e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8019/10000 | D Loss: 7.748439311981201 | G Loss: 1.1593840554269264e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8020/10000 | D Loss: 7.721983909606934 | G Loss: 1.1208467185497284e-06\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "Epoch 8021/10000 | D Loss: 7.788208484649658 | G Loss: 1.151498395302042e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8022/10000 | D Loss: 7.713292121887207 | G Loss: 9.93854996522714e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8023/10000 | D Loss: 8.04559326171875 | G Loss: 1.0655635378498118e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8024/10000 | D Loss: 7.903885841369629 | G Loss: 1.117830151997623e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8025/10000 | D Loss: 7.890756130218506 | G Loss: 7.45376098620909e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8026/10000 | D Loss: 7.978912353515625 | G Loss: 1.1562941608644906e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8027/10000 | D Loss: 7.83542537689209 | G Loss: 9.358037118545326e-07\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "Epoch 8028/10000 | D Loss: 7.624068737030029 | G Loss: 9.399747114002821e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8029/10000 | D Loss: 7.738103866577148 | G Loss: 1.358604890810966e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8030/10000 | D Loss: 8.063131332397461 | G Loss: 1.097396761906566e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8031/10000 | D Loss: 7.691166877746582 | G Loss: 1.1772285688493866e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8032/10000 | D Loss: 7.635732650756836 | G Loss: 7.810491524651297e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8033/10000 | D Loss: 7.665350437164307 | G Loss: 1.0728574579843553e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8034/10000 | D Loss: 7.763064384460449 | G Loss: 1.1742532706193742e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8035/10000 | D Loss: 7.701786041259766 | G Loss: 9.78022853814764e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8036/10000 | D Loss: 7.9600725173950195 | G Loss: 7.818350127308804e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8037/10000 | D Loss: 7.707762718200684 | G Loss: 5.658114332618425e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8038/10000 | D Loss: 7.699278354644775 | G Loss: 8.486375691063586e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8039/10000 | D Loss: 7.865447521209717 | G Loss: 9.013422186399112e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8040/10000 | D Loss: 7.7138471603393555 | G Loss: 1.3215307035352453e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8041/10000 | D Loss: 7.773561477661133 | G Loss: 8.387717684854579e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8042/10000 | D Loss: 7.81758451461792 | G Loss: 1.145995383922127e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8043/10000 | D Loss: 7.581831932067871 | G Loss: 8.267899147540447e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 8044/10000 | D Loss: 7.808047294616699 | G Loss: 1.590644387761131e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8045/10000 | D Loss: 7.730793476104736 | G Loss: 9.968800895876484e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8046/10000 | D Loss: 7.878050804138184 | G Loss: 1.1905178780580172e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8047/10000 | D Loss: 7.829686641693115 | G Loss: 8.138446219163598e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8048/10000 | D Loss: 7.74050760269165 | G Loss: 6.203104589985742e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8049/10000 | D Loss: 7.735538482666016 | G Loss: 9.737595974002033e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8050/10000 | D Loss: 7.72674560546875 | G Loss: 7.758632136756205e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8051/10000 | D Loss: 7.686318874359131 | G Loss: 9.735349522088654e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8052/10000 | D Loss: 7.8050360679626465 | G Loss: 5.763700414718187e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8053/10000 | D Loss: 7.660330772399902 | G Loss: 8.965664619609015e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8054/10000 | D Loss: 7.820265769958496 | G Loss: 7.478445809283585e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8055/10000 | D Loss: 7.911481857299805 | G Loss: 1.00807312719553e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8056/10000 | D Loss: 7.685193061828613 | G Loss: 1.162182456937444e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8057/10000 | D Loss: 7.871591091156006 | G Loss: 7.416955440930906e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8058/10000 | D Loss: 7.811491966247559 | G Loss: 5.425343942988547e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8059/10000 | D Loss: 7.700759410858154 | G Loss: 1.4525371625495609e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8060/10000 | D Loss: 8.01840877532959 | G Loss: 1.1818993925771792e-06\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8061/10000 | D Loss: 7.725123882293701 | G Loss: 8.262646815637709e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8062/10000 | D Loss: 7.798013210296631 | G Loss: 9.639497875468805e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8063/10000 | D Loss: 7.640460014343262 | G Loss: 9.912762379826745e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8064/10000 | D Loss: 7.8526201248168945 | G Loss: 1.2649617247006972e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8065/10000 | D Loss: 7.871124267578125 | G Loss: 1.143503027378756e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8066/10000 | D Loss: 7.813848495483398 | G Loss: 1.1517329312482616e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8067/10000 | D Loss: 7.711345195770264 | G Loss: 8.489354286211892e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8068/10000 | D Loss: 7.856799125671387 | G Loss: 1.282032940252975e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8069/10000 | D Loss: 7.876001358032227 | G Loss: 7.813351885488373e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8070/10000 | D Loss: 7.926029205322266 | G Loss: 9.192717698169872e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8071/10000 | D Loss: 7.5782575607299805 | G Loss: 9.519455943518551e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8072/10000 | D Loss: 7.784341335296631 | G Loss: 1.0740534435171867e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8073/10000 | D Loss: 7.849209785461426 | G Loss: 1.0722676506702555e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8074/10000 | D Loss: 7.908273696899414 | G Loss: 7.01223939358897e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8075/10000 | D Loss: 7.86245584487915 | G Loss: 1.1500594609969994e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8076/10000 | D Loss: 7.732133388519287 | G Loss: 1.0524126992095262e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8077/10000 | D Loss: 7.717144966125488 | G Loss: 6.787926736251393e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8078/10000 | D Loss: 7.7650675773620605 | G Loss: 1.2210737168061314e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8079/10000 | D Loss: 7.838162899017334 | G Loss: 2.09750646718021e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8080/10000 | D Loss: 7.774693012237549 | G Loss: 7.325804745050846e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8081/10000 | D Loss: 7.699152946472168 | G Loss: 6.476489033957478e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8082/10000 | D Loss: 7.691868782043457 | G Loss: 9.100720035348786e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8083/10000 | D Loss: 7.683843612670898 | G Loss: 1.0815358564286726e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8084/10000 | D Loss: 7.887975692749023 | G Loss: 1.153455286839744e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8085/10000 | D Loss: 7.7899885177612305 | G Loss: 8.794807513368141e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8086/10000 | D Loss: 7.793512344360352 | G Loss: 1.4982530274210148e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8087/10000 | D Loss: 7.713922023773193 | G Loss: 9.85302222034079e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8088/10000 | D Loss: 7.518787384033203 | G Loss: 8.521664085492375e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8089/10000 | D Loss: 7.959536552429199 | G Loss: 8.301869911520043e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8090/10000 | D Loss: 7.847872734069824 | G Loss: 7.708704288234003e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8091/10000 | D Loss: 7.865077972412109 | G Loss: 1.55759448716708e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8092/10000 | D Loss: 7.9365234375 | G Loss: 1.0827486676134868e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8093/10000 | D Loss: 7.743435859680176 | G Loss: 1.0177005833611474e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8094/10000 | D Loss: 7.7843852043151855 | G Loss: 1.0659892950570793e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8095/10000 | D Loss: 7.794270992279053 | G Loss: 7.738944987067953e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8096/10000 | D Loss: 7.6873698234558105 | G Loss: 8.273033813566144e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8097/10000 | D Loss: 7.8414812088012695 | G Loss: 9.631020247979905e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8098/10000 | D Loss: 7.814924240112305 | G Loss: 7.443303502441267e-07\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch 8099/10000 | D Loss: 7.805852890014648 | G Loss: 1.60087552103505e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8100/10000 | D Loss: 7.816816329956055 | G Loss: 6.429056043089076e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8101/10000 | D Loss: 7.86994743347168 | G Loss: 1.0335298838981544e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8102/10000 | D Loss: 7.930468559265137 | G Loss: 8.949435255090066e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8103/10000 | D Loss: 7.877601146697998 | G Loss: 1.3204173683334375e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8104/10000 | D Loss: 7.843380928039551 | G Loss: 1.2881585007562535e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8105/10000 | D Loss: 7.68643856048584 | G Loss: 9.356392638437683e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8106/10000 | D Loss: 7.777150630950928 | G Loss: 1.232498789249803e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8107/10000 | D Loss: 7.7862677574157715 | G Loss: 1.413829068042105e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8108/10000 | D Loss: 8.024953842163086 | G Loss: 1.0833769010787364e-06\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "Epoch 8109/10000 | D Loss: 7.714745998382568 | G Loss: 7.063437692522712e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8110/10000 | D Loss: 7.755329608917236 | G Loss: 7.734251994406804e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8111/10000 | D Loss: 7.974165916442871 | G Loss: 8.393211601287476e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8112/10000 | D Loss: 7.955394268035889 | G Loss: 1.1811569038400194e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8113/10000 | D Loss: 7.78530216217041 | G Loss: 1.3144435797585174e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8114/10000 | D Loss: 7.81585693359375 | G Loss: 1.1489951248222496e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8115/10000 | D Loss: 7.808896064758301 | G Loss: 1.0622710533425561e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8116/10000 | D Loss: 7.783440589904785 | G Loss: 6.027850076861796e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8117/10000 | D Loss: 7.756669044494629 | G Loss: 1.287588588638755e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8118/10000 | D Loss: 7.867354393005371 | G Loss: 8.111942406685557e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8119/10000 | D Loss: 7.819424152374268 | G Loss: 7.405749897770875e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8120/10000 | D Loss: 7.955629825592041 | G Loss: 8.627964689367218e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8121/10000 | D Loss: 7.723922252655029 | G Loss: 1.606138312126859e-06\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8122/10000 | D Loss: 7.834009170532227 | G Loss: 9.701482213131385e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8123/10000 | D Loss: 7.7756781578063965 | G Loss: 1.170891550827946e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8124/10000 | D Loss: 7.940581321716309 | G Loss: 1.1673345170493121e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8125/10000 | D Loss: 7.634674072265625 | G Loss: 1.7883919554151362e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8126/10000 | D Loss: 7.8081746101379395 | G Loss: 1.5929813343973365e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8127/10000 | D Loss: 7.835692405700684 | G Loss: 8.767517556407256e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8128/10000 | D Loss: 7.703091621398926 | G Loss: 9.90386979538016e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8129/10000 | D Loss: 7.772322654724121 | G Loss: 8.323536917487218e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8130/10000 | D Loss: 7.63136100769043 | G Loss: 9.804753062780946e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8131/10000 | D Loss: 7.705472469329834 | G Loss: 1.0079777439386817e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8132/10000 | D Loss: 7.815527439117432 | G Loss: 7.961245955812046e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8133/10000 | D Loss: 7.95651912689209 | G Loss: 9.799869076232426e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8134/10000 | D Loss: 7.877677917480469 | G Loss: 8.399389912483457e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8135/10000 | D Loss: 7.759069442749023 | G Loss: 1.6443771073682e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8136/10000 | D Loss: 7.79435920715332 | G Loss: 7.325843398575671e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8137/10000 | D Loss: 7.872651100158691 | G Loss: 9.078108860194334e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8138/10000 | D Loss: 7.6712727546691895 | G Loss: 7.046629661999759e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8139/10000 | D Loss: 7.823345184326172 | G Loss: 8.329001843776496e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8140/10000 | D Loss: 7.909128189086914 | G Loss: 1.083118604583433e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8141/10000 | D Loss: 7.818662643432617 | G Loss: 1.4457948509516427e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8142/10000 | D Loss: 7.910245418548584 | G Loss: 9.70607061390183e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8143/10000 | D Loss: 7.778254508972168 | G Loss: 1.5845424741200986e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8144/10000 | D Loss: 7.909501075744629 | G Loss: 1.6203840687012416e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8145/10000 | D Loss: 7.841557502746582 | G Loss: 8.851097277329245e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8146/10000 | D Loss: 7.829176902770996 | G Loss: 8.965579354480724e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8147/10000 | D Loss: 7.895596981048584 | G Loss: 8.238548616645858e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8148/10000 | D Loss: 7.788618087768555 | G Loss: 9.334448236586468e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8149/10000 | D Loss: 7.8247151374816895 | G Loss: 1.103699332816177e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8150/10000 | D Loss: 7.638387680053711 | G Loss: 1.035400828186539e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8151/10000 | D Loss: 7.710560321807861 | G Loss: 7.490267535104067e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8152/10000 | D Loss: 7.848691940307617 | G Loss: 8.338749353242747e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8153/10000 | D Loss: 7.952345848083496 | G Loss: 1.4842464679531986e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8154/10000 | D Loss: 7.765863418579102 | G Loss: 8.983608950074995e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8155/10000 | D Loss: 7.901642322540283 | G Loss: 1.1126696790597634e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8156/10000 | D Loss: 7.681608200073242 | G Loss: 1.3538041230276576e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8157/10000 | D Loss: 7.832883834838867 | G Loss: 1.2251334737811703e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8158/10000 | D Loss: 7.6331257820129395 | G Loss: 9.867824246612145e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8159/10000 | D Loss: 7.80399227142334 | G Loss: 8.742846944187477e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8160/10000 | D Loss: 7.663130283355713 | G Loss: 9.140507586380409e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8161/10000 | D Loss: 7.8190131187438965 | G Loss: 7.237067620735615e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8162/10000 | D Loss: 7.70528507232666 | G Loss: 1.097781932912767e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8163/10000 | D Loss: 7.720639705657959 | G Loss: 7.016219569777604e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8164/10000 | D Loss: 7.904799461364746 | G Loss: 7.048913062135398e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8165/10000 | D Loss: 7.773171424865723 | G Loss: 9.745465376909124e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8166/10000 | D Loss: 7.873539924621582 | G Loss: 6.183124696690356e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8167/10000 | D Loss: 7.750905990600586 | G Loss: 5.725551091018133e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8168/10000 | D Loss: 8.001411437988281 | G Loss: 6.305105557657953e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8169/10000 | D Loss: 7.938947677612305 | G Loss: 6.938529395483783e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8170/10000 | D Loss: 7.817217826843262 | G Loss: 8.499509931425564e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8171/10000 | D Loss: 7.8881988525390625 | G Loss: 1.0407156878500246e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8172/10000 | D Loss: 7.844237327575684 | G Loss: 9.226649808624643e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8173/10000 | D Loss: 7.801145553588867 | G Loss: 5.862331136086141e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8174/10000 | D Loss: 7.846473693847656 | G Loss: 8.263489803539414e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8175/10000 | D Loss: 7.668719291687012 | G Loss: 1.038642949424684e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8176/10000 | D Loss: 7.869778156280518 | G Loss: 7.092859846125066e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8177/10000 | D Loss: 7.775722503662109 | G Loss: 8.032523624024179e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8178/10000 | D Loss: 7.859348773956299 | G Loss: 6.874698783576605e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8179/10000 | D Loss: 7.837281703948975 | G Loss: 1.129544557443296e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8180/10000 | D Loss: 7.9090375900268555 | G Loss: 1.2652637906285236e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8181/10000 | D Loss: 7.855701446533203 | G Loss: 1.5257741097229882e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8182/10000 | D Loss: 7.817677021026611 | G Loss: 8.543406124772446e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8183/10000 | D Loss: 7.904868125915527 | G Loss: 9.377770311402855e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8184/10000 | D Loss: 7.803470611572266 | G Loss: 6.650577688560588e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8185/10000 | D Loss: 7.810202598571777 | G Loss: 1.1469614946690854e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8186/10000 | D Loss: 7.781804084777832 | G Loss: 1.7174028243971406e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8187/10000 | D Loss: 7.840342998504639 | G Loss: 1.0877288332267199e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8188/10000 | D Loss: 7.874969005584717 | G Loss: 7.635138103978534e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8189/10000 | D Loss: 7.826016426086426 | G Loss: 8.664461574880988e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8190/10000 | D Loss: 7.887979507446289 | G Loss: 9.818278385864687e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8191/10000 | D Loss: 7.750103950500488 | G Loss: 7.6632323953163e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8192/10000 | D Loss: 7.739054203033447 | G Loss: 9.614550435799174e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8193/10000 | D Loss: 8.068889617919922 | G Loss: 1.2894718111056136e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8194/10000 | D Loss: 7.874300003051758 | G Loss: 9.634247817302821e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 8195/10000 | D Loss: 7.820720672607422 | G Loss: 6.884491767777945e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8196/10000 | D Loss: 7.99127197265625 | G Loss: 5.758691372648173e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8197/10000 | D Loss: 7.940715789794922 | G Loss: 7.430103323713411e-07\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 8198/10000 | D Loss: 7.795334339141846 | G Loss: 4.798984605258738e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8199/10000 | D Loss: 7.866262912750244 | G Loss: 1.321787294727983e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8200/10000 | D Loss: 7.897904396057129 | G Loss: 7.139885838114424e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8201/10000 | D Loss: 7.7159223556518555 | G Loss: 7.892045914559276e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8202/10000 | D Loss: 7.890055179595947 | G Loss: 9.058211389856297e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8203/10000 | D Loss: 7.708666801452637 | G Loss: 7.2556554187031e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8204/10000 | D Loss: 8.039047241210938 | G Loss: 1.0387281008661375e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8205/10000 | D Loss: 7.895807266235352 | G Loss: 6.017289706505835e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8206/10000 | D Loss: 7.938573837280273 | G Loss: 9.706716355140088e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8207/10000 | D Loss: 7.935368061065674 | G Loss: 9.940176823874936e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8208/10000 | D Loss: 7.763424873352051 | G Loss: 8.607693189333077e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8209/10000 | D Loss: 8.04702091217041 | G Loss: 6.94366008247016e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8210/10000 | D Loss: 7.908469200134277 | G Loss: 8.067456747085089e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8211/10000 | D Loss: 7.683908462524414 | G Loss: 8.83382085703488e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8212/10000 | D Loss: 7.849978446960449 | G Loss: 8.88953195499198e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8213/10000 | D Loss: 7.729646682739258 | G Loss: 6.761188160453457e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8214/10000 | D Loss: 7.939591884613037 | G Loss: 8.796130259725032e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8215/10000 | D Loss: 7.725446701049805 | G Loss: 9.764535207068548e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8216/10000 | D Loss: 7.7900238037109375 | G Loss: 9.351527410217386e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8217/10000 | D Loss: 7.824515342712402 | G Loss: 9.140526913142821e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8218/10000 | D Loss: 7.931975364685059 | G Loss: 1.0612916412355844e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8219/10000 | D Loss: 7.730478286743164 | G Loss: 7.968180284478876e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8220/10000 | D Loss: 7.8725504875183105 | G Loss: 7.769636454213469e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8221/10000 | D Loss: 7.769468307495117 | G Loss: 9.92938112176489e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8222/10000 | D Loss: 7.727170944213867 | G Loss: 7.157748314057244e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8223/10000 | D Loss: 8.078546524047852 | G Loss: 8.898236956156325e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8224/10000 | D Loss: 7.8373026847839355 | G Loss: 9.370144198328489e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8225/10000 | D Loss: 7.714487075805664 | G Loss: 1.2365384236545651e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8226/10000 | D Loss: 7.686768531799316 | G Loss: 1.0836383808054961e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8227/10000 | D Loss: 7.856087684631348 | G Loss: 9.712778137327405e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8228/10000 | D Loss: 7.7502288818359375 | G Loss: 7.189540838226094e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8229/10000 | D Loss: 7.840978622436523 | G Loss: 7.365755436694599e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8230/10000 | D Loss: 7.653007507324219 | G Loss: 7.222222393465927e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8231/10000 | D Loss: 7.878800868988037 | G Loss: 1.0297529797753668e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8232/10000 | D Loss: 7.7974443435668945 | G Loss: 8.996437372843502e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8233/10000 | D Loss: 7.814784526824951 | G Loss: 9.0068112967856e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8234/10000 | D Loss: 7.805362701416016 | G Loss: 6.01845158598735e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8235/10000 | D Loss: 7.677510738372803 | G Loss: 8.374984190595569e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8236/10000 | D Loss: 8.025379180908203 | G Loss: 8.823180905892514e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8237/10000 | D Loss: 7.816330432891846 | G Loss: 1.9599292500060983e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8238/10000 | D Loss: 7.884730339050293 | G Loss: 8.362228527403204e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8239/10000 | D Loss: 7.905519008636475 | G Loss: 1.4878745560054085e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8240/10000 | D Loss: 7.894336700439453 | G Loss: 9.020129709824687e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8241/10000 | D Loss: 7.806460380554199 | G Loss: 6.9233146859915e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8242/10000 | D Loss: 8.07794189453125 | G Loss: 1.503170324212988e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8243/10000 | D Loss: 7.794428825378418 | G Loss: 9.99706685433921e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8244/10000 | D Loss: 7.806775093078613 | G Loss: 1.0615980272632441e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8245/10000 | D Loss: 7.721691131591797 | G Loss: 1.3979476989334216e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8246/10000 | D Loss: 7.964620113372803 | G Loss: 6.313936182777979e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8247/10000 | D Loss: 7.79637336730957 | G Loss: 7.520156373175269e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8248/10000 | D Loss: 7.832686424255371 | G Loss: 1.2158334357081912e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8249/10000 | D Loss: 7.960896968841553 | G Loss: 8.072792070379364e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8250/10000 | D Loss: 7.996932506561279 | G Loss: 1.1069448646594537e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8251/10000 | D Loss: 7.877978801727295 | G Loss: 6.31624743618886e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8252/10000 | D Loss: 7.913599967956543 | G Loss: 7.899099045971525e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8253/10000 | D Loss: 7.77670955657959 | G Loss: 5.916081704526732e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8254/10000 | D Loss: 7.973925590515137 | G Loss: 7.241746970976237e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8255/10000 | D Loss: 7.725070476531982 | G Loss: 1.3080904182061204e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8256/10000 | D Loss: 7.742907524108887 | G Loss: 9.097569204641331e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8257/10000 | D Loss: 7.879331111907959 | G Loss: 7.364119483099785e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8258/10000 | D Loss: 7.93531608581543 | G Loss: 5.981473805150017e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8259/10000 | D Loss: 8.031147003173828 | G Loss: 9.970945029635914e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8260/10000 | D Loss: 7.821717739105225 | G Loss: 7.417150982291787e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8261/10000 | D Loss: 7.774658203125 | G Loss: 6.698893457723898e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8262/10000 | D Loss: 7.872185707092285 | G Loss: 9.052748737303773e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8263/10000 | D Loss: 7.702461242675781 | G Loss: 8.717111086298246e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8264/10000 | D Loss: 8.077855110168457 | G Loss: 1.049280854203971e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8265/10000 | D Loss: 7.795628547668457 | G Loss: 1.0876156011363491e-06\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 8266/10000 | D Loss: 7.88527250289917 | G Loss: 1.078742343452177e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8267/10000 | D Loss: 7.60821533203125 | G Loss: 1.016690816868504e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8268/10000 | D Loss: 7.9126410484313965 | G Loss: 9.79521587396448e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8269/10000 | D Loss: 7.766358375549316 | G Loss: 9.276893138121522e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8270/10000 | D Loss: 7.809154510498047 | G Loss: 6.721191994074616e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8271/10000 | D Loss: 7.906484127044678 | G Loss: 8.814184297989414e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8272/10000 | D Loss: 7.9415459632873535 | G Loss: 2.1441001081257127e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8273/10000 | D Loss: 7.827386856079102 | G Loss: 6.713323159601714e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8274/10000 | D Loss: 7.884376525878906 | G Loss: 9.370053817292501e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8275/10000 | D Loss: 7.855401992797852 | G Loss: 6.407640285033267e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8276/10000 | D Loss: 7.855346202850342 | G Loss: 6.320821626104589e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8277/10000 | D Loss: 7.784786701202393 | G Loss: 9.709420965009485e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8278/10000 | D Loss: 7.938596248626709 | G Loss: 1.1537422324181534e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8279/10000 | D Loss: 7.944531440734863 | G Loss: 1.3365529412112664e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8280/10000 | D Loss: 7.799869537353516 | G Loss: 2.277739895362174e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8281/10000 | D Loss: 7.724757194519043 | G Loss: 7.26602820577682e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8282/10000 | D Loss: 7.913523197174072 | G Loss: 8.329859610967105e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8283/10000 | D Loss: 7.762485504150391 | G Loss: 1.1198069387319265e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8284/10000 | D Loss: 7.7779436111450195 | G Loss: 5.947713930254395e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8285/10000 | D Loss: 7.979161262512207 | G Loss: 6.229575433280843e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8286/10000 | D Loss: 7.995784282684326 | G Loss: 1.524126787444402e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8287/10000 | D Loss: 7.903883934020996 | G Loss: 8.423030521953478e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8288/10000 | D Loss: 7.93408727645874 | G Loss: 9.99243980004394e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8289/10000 | D Loss: 7.897640705108643 | G Loss: 6.477678766714234e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8290/10000 | D Loss: 7.764208793640137 | G Loss: 1.1067219247706817e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8291/10000 | D Loss: 7.787448883056641 | G Loss: 9.681855317467125e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8292/10000 | D Loss: 7.827624797821045 | G Loss: 8.816520562504593e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8293/10000 | D Loss: 7.9852824211120605 | G Loss: 5.507040441443678e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8294/10000 | D Loss: 7.726860523223877 | G Loss: 9.015143405122217e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8295/10000 | D Loss: 7.853128910064697 | G Loss: 8.304143648274476e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8296/10000 | D Loss: 7.784509658813477 | G Loss: 5.833945806443808e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8297/10000 | D Loss: 7.8357086181640625 | G Loss: 9.615532690077089e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8298/10000 | D Loss: 7.776175022125244 | G Loss: 6.472489531006431e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8299/10000 | D Loss: 7.826587200164795 | G Loss: 8.738167593946855e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8300/10000 | D Loss: 7.810387134552002 | G Loss: 1.2427481124177575e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8301/10000 | D Loss: 7.844824314117432 | G Loss: 5.590719069914485e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8302/10000 | D Loss: 7.857144355773926 | G Loss: 6.756398533980246e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8303/10000 | D Loss: 7.943934917449951 | G Loss: 8.382080523006152e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8304/10000 | D Loss: 7.955440521240234 | G Loss: 1.02209696706268e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8305/10000 | D Loss: 7.7488813400268555 | G Loss: 6.482546268671285e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8306/10000 | D Loss: 7.947955131530762 | G Loss: 9.669277005741606e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8307/10000 | D Loss: 8.039237976074219 | G Loss: 8.489263336741715e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8308/10000 | D Loss: 7.7515788078308105 | G Loss: 1.1467315061963745e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8309/10000 | D Loss: 7.930720329284668 | G Loss: 7.998193609637383e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8310/10000 | D Loss: 7.805536270141602 | G Loss: 8.827125839161454e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8311/10000 | D Loss: 7.846447944641113 | G Loss: 5.393637820816366e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8312/10000 | D Loss: 7.854891777038574 | G Loss: 1.4514936310661142e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8313/10000 | D Loss: 7.802924633026123 | G Loss: 6.520392616948811e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8314/10000 | D Loss: 7.832187652587891 | G Loss: 6.214367544998822e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8315/10000 | D Loss: 7.6926679611206055 | G Loss: 8.196057024179026e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8316/10000 | D Loss: 7.794621467590332 | G Loss: 6.674550832030945e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8317/10000 | D Loss: 7.813484191894531 | G Loss: 1.5006002058726153e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8318/10000 | D Loss: 8.119024276733398 | G Loss: 1.0035847708422807e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8319/10000 | D Loss: 7.755453109741211 | G Loss: 8.865158633852843e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8320/10000 | D Loss: 7.818347930908203 | G Loss: 1.0558228495938238e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8321/10000 | D Loss: 7.878889083862305 | G Loss: 6.35209516985924e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8322/10000 | D Loss: 7.77396821975708 | G Loss: 9.391099524691526e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8323/10000 | D Loss: 7.931239128112793 | G Loss: 7.712706064921804e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8324/10000 | D Loss: 7.887351036071777 | G Loss: 7.056646609271411e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8325/10000 | D Loss: 8.046802520751953 | G Loss: 2.0595941805368057e-06\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8326/10000 | D Loss: 7.8944878578186035 | G Loss: 1.5565540252282517e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8327/10000 | D Loss: 7.995656967163086 | G Loss: 8.959223123383708e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8328/10000 | D Loss: 7.9427266120910645 | G Loss: 9.64056198426988e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8329/10000 | D Loss: 7.786357879638672 | G Loss: 5.712290658266284e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8330/10000 | D Loss: 7.753521919250488 | G Loss: 8.468833243568952e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8331/10000 | D Loss: 7.932652473449707 | G Loss: 7.578466920676874e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8332/10000 | D Loss: 7.723237037658691 | G Loss: 1.426519133929105e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8333/10000 | D Loss: 7.878055572509766 | G Loss: 8.698567626197473e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8334/10000 | D Loss: 7.870031356811523 | G Loss: 6.54839197977708e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8335/10000 | D Loss: 7.720236778259277 | G Loss: 7.863226301196846e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8336/10000 | D Loss: 8.113880157470703 | G Loss: 1.8515022475185106e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8337/10000 | D Loss: 7.821374416351318 | G Loss: 9.004438652482349e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8338/10000 | D Loss: 7.769252777099609 | G Loss: 9.371040619043924e-07\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch 8339/10000 | D Loss: 7.895447254180908 | G Loss: 6.119812496763188e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8340/10000 | D Loss: 7.993711948394775 | G Loss: 1.0251176263409434e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8341/10000 | D Loss: 7.874266624450684 | G Loss: 8.95257414867956e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8342/10000 | D Loss: 7.8403730392456055 | G Loss: 9.539044185657986e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8343/10000 | D Loss: 7.893155574798584 | G Loss: 1.1128538517368725e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8344/10000 | D Loss: 7.969205856323242 | G Loss: 1.5836958482395858e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8345/10000 | D Loss: 7.966673851013184 | G Loss: 1.0031535566668026e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8346/10000 | D Loss: 7.8728251457214355 | G Loss: 8.91094373400847e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8347/10000 | D Loss: 7.755985260009766 | G Loss: 6.560146630363306e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8348/10000 | D Loss: 7.703714370727539 | G Loss: 7.699876505284919e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8349/10000 | D Loss: 7.846172332763672 | G Loss: 1.0528488019190263e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8350/10000 | D Loss: 7.949209690093994 | G Loss: 7.263334396157006e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8351/10000 | D Loss: 7.894599914550781 | G Loss: 5.456415692606242e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8352/10000 | D Loss: 7.848522186279297 | G Loss: 7.495906402255059e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8353/10000 | D Loss: 7.840818881988525 | G Loss: 9.113551868722425e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8354/10000 | D Loss: 7.742476463317871 | G Loss: 8.260868753495743e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8355/10000 | D Loss: 8.030056953430176 | G Loss: 9.027967280417215e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8356/10000 | D Loss: 7.763660907745361 | G Loss: 7.223245575005421e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8357/10000 | D Loss: 7.718611717224121 | G Loss: 7.156390324780659e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8358/10000 | D Loss: 7.884239673614502 | G Loss: 9.796830227060127e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8359/10000 | D Loss: 7.935196876525879 | G Loss: 7.950629878905602e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8360/10000 | D Loss: 7.64286470413208 | G Loss: 8.642675766168395e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8361/10000 | D Loss: 7.920988082885742 | G Loss: 6.067029971745797e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8362/10000 | D Loss: 7.984905242919922 | G Loss: 6.852417300251545e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8363/10000 | D Loss: 7.92813777923584 | G Loss: 7.615151389472885e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8364/10000 | D Loss: 7.938011169433594 | G Loss: 8.43269219785725e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8365/10000 | D Loss: 7.873538970947266 | G Loss: 5.85723910262459e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8366/10000 | D Loss: 7.941821098327637 | G Loss: 6.470405651270994e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8367/10000 | D Loss: 7.774897575378418 | G Loss: 8.177190693459124e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8368/10000 | D Loss: 8.179927825927734 | G Loss: 8.813848353383946e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8369/10000 | D Loss: 7.823486804962158 | G Loss: 7.648810083082935e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8370/10000 | D Loss: 8.003554344177246 | G Loss: 9.175658419735555e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8371/10000 | D Loss: 7.865983009338379 | G Loss: 7.622662678841152e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8372/10000 | D Loss: 7.875045299530029 | G Loss: 6.36857748759212e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8373/10000 | D Loss: 7.891978740692139 | G Loss: 8.211114845835255e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8374/10000 | D Loss: 7.979021072387695 | G Loss: 7.509395345550729e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8375/10000 | D Loss: 7.974213600158691 | G Loss: 1.2587553328557988e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8376/10000 | D Loss: 7.832157135009766 | G Loss: 8.488235607728711e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8377/10000 | D Loss: 7.892725944519043 | G Loss: 7.052480555103102e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8378/10000 | D Loss: 7.68170166015625 | G Loss: 8.115940772768226e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8379/10000 | D Loss: 7.826729774475098 | G Loss: 1.0306483773092623e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8380/10000 | D Loss: 7.6874003410339355 | G Loss: 9.7907889085036e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8381/10000 | D Loss: 7.799095153808594 | G Loss: 9.56294115894707e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8382/10000 | D Loss: 7.945059299468994 | G Loss: 7.586746164633951e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8383/10000 | D Loss: 7.834466934204102 | G Loss: 8.337530061908183e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8384/10000 | D Loss: 7.77255916595459 | G Loss: 6.700374797219411e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8385/10000 | D Loss: 8.022071838378906 | G Loss: 7.794418479534215e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8386/10000 | D Loss: 7.618454933166504 | G Loss: 1.137780373028363e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8387/10000 | D Loss: 7.8969316482543945 | G Loss: 5.928344535277574e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8388/10000 | D Loss: 7.937367916107178 | G Loss: 6.929518576725968e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8389/10000 | D Loss: 7.827826976776123 | G Loss: 6.332775228656828e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8390/10000 | D Loss: 7.914682865142822 | G Loss: 8.310900057040271e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8391/10000 | D Loss: 7.743248462677002 | G Loss: 1.0530536656006007e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8392/10000 | D Loss: 8.044835090637207 | G Loss: 1.052547986546415e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8393/10000 | D Loss: 7.980999946594238 | G Loss: 1.1390950476197759e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8394/10000 | D Loss: 7.772307395935059 | G Loss: 7.19962145012687e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8395/10000 | D Loss: 7.969682693481445 | G Loss: 7.287581524906273e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8396/10000 | D Loss: 7.818891525268555 | G Loss: 6.593763828277588e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8397/10000 | D Loss: 7.787325859069824 | G Loss: 7.619133270964085e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8398/10000 | D Loss: 8.044321060180664 | G Loss: 6.162376848806161e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8399/10000 | D Loss: 7.8565778732299805 | G Loss: 6.256486813072115e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8400/10000 | D Loss: 7.85931396484375 | G Loss: 8.949036214289663e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8401/10000 | D Loss: 8.099679946899414 | G Loss: 8.995787652565923e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8402/10000 | D Loss: 7.979593276977539 | G Loss: 9.819121942200582e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8403/10000 | D Loss: 7.810512542724609 | G Loss: 9.579364359524334e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8404/10000 | D Loss: 7.928974151611328 | G Loss: 5.382823928812286e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8405/10000 | D Loss: 7.933738708496094 | G Loss: 5.729262397835555e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8406/10000 | D Loss: 7.719951629638672 | G Loss: 7.400890353892464e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8407/10000 | D Loss: 8.053512573242188 | G Loss: 8.964203175310104e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8408/10000 | D Loss: 7.922290325164795 | G Loss: 8.497989938405226e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8409/10000 | D Loss: 7.82935094833374 | G Loss: 4.435321443452267e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8410/10000 | D Loss: 7.86652135848999 | G Loss: 1.3735115089730243e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8411/10000 | D Loss: 8.053067207336426 | G Loss: 7.020242378530384e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8412/10000 | D Loss: 7.816312789916992 | G Loss: 1.5344189705501776e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8413/10000 | D Loss: 7.92421817779541 | G Loss: 9.264602454095439e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8414/10000 | D Loss: 7.854447841644287 | G Loss: 1.0739522622316144e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8415/10000 | D Loss: 7.871843338012695 | G Loss: 1.3169527619538712e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8416/10000 | D Loss: 7.879273414611816 | G Loss: 6.295405796663545e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8417/10000 | D Loss: 7.739710330963135 | G Loss: 7.225326044135727e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8418/10000 | D Loss: 7.852941513061523 | G Loss: 7.920906455183285e-07\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 8419/10000 | D Loss: 7.810931205749512 | G Loss: 8.541605893697124e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8420/10000 | D Loss: 7.989068984985352 | G Loss: 9.625400707591325e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8421/10000 | D Loss: 7.813683986663818 | G Loss: 6.928432298991538e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8422/10000 | D Loss: 7.893113136291504 | G Loss: 8.027591320569627e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8423/10000 | D Loss: 8.025033950805664 | G Loss: 5.240116820459662e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8424/10000 | D Loss: 7.937403678894043 | G Loss: 7.809222779542324e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8425/10000 | D Loss: 7.765948295593262 | G Loss: 5.657124688696058e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8426/10000 | D Loss: 7.956158638000488 | G Loss: 7.193268629634986e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8427/10000 | D Loss: 8.073770523071289 | G Loss: 7.636498366991873e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8428/10000 | D Loss: 7.949894905090332 | G Loss: 8.457392937089026e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8429/10000 | D Loss: 7.990687847137451 | G Loss: 7.173067615440232e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8430/10000 | D Loss: 7.87369441986084 | G Loss: 7.075276471368852e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8431/10000 | D Loss: 7.84157133102417 | G Loss: 8.636544635010068e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8432/10000 | D Loss: 7.781087398529053 | G Loss: 7.575539484605542e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8433/10000 | D Loss: 8.017071723937988 | G Loss: 6.315098062259494e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8434/10000 | D Loss: 7.94901704788208 | G Loss: 1.2412629075697623e-06\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 8435/10000 | D Loss: 7.801779747009277 | G Loss: 6.267692924666335e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8436/10000 | D Loss: 7.8256120681762695 | G Loss: 1.0617304724291898e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8437/10000 | D Loss: 7.827585220336914 | G Loss: 9.070349733519834e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8438/10000 | D Loss: 8.065788269042969 | G Loss: 8.595246754339314e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8439/10000 | D Loss: 7.869771957397461 | G Loss: 7.429169954775716e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8440/10000 | D Loss: 7.927300453186035 | G Loss: 8.976446110864345e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8441/10000 | D Loss: 7.97957706451416 | G Loss: 5.988299562886823e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8442/10000 | D Loss: 8.040590286254883 | G Loss: 7.213609478640137e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8443/10000 | D Loss: 7.950534343719482 | G Loss: 6.952229796297615e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8444/10000 | D Loss: 7.727187633514404 | G Loss: 9.403008789377054e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8445/10000 | D Loss: 7.818922996520996 | G Loss: 7.981924454725231e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8446/10000 | D Loss: 7.844738483428955 | G Loss: 8.85800091054989e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8447/10000 | D Loss: 7.830662727355957 | G Loss: 7.760470452922164e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8448/10000 | D Loss: 7.872446060180664 | G Loss: 4.916304305879748e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8449/10000 | D Loss: 7.922670364379883 | G Loss: 1.2400332707329653e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8450/10000 | D Loss: 7.883315086364746 | G Loss: 5.270480869512539e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8451/10000 | D Loss: 7.936625003814697 | G Loss: 1.169551296698046e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8452/10000 | D Loss: 7.826974391937256 | G Loss: 4.951118626195239e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8453/10000 | D Loss: 7.748285293579102 | G Loss: 8.686437809046765e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8454/10000 | D Loss: 8.110392570495605 | G Loss: 5.343886186892632e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8455/10000 | D Loss: 7.828505039215088 | G Loss: 4.814735348190879e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8456/10000 | D Loss: 7.94279146194458 | G Loss: 6.587092684640083e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8457/10000 | D Loss: 8.05040168762207 | G Loss: 9.62548483585124e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8458/10000 | D Loss: 7.798130035400391 | G Loss: 5.55738495222613e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8459/10000 | D Loss: 7.835954666137695 | G Loss: 6.18884882896964e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8460/10000 | D Loss: 7.740653038024902 | G Loss: 7.895545195424347e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8461/10000 | D Loss: 7.916572570800781 | G Loss: 8.255811962953885e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8462/10000 | D Loss: 7.9518280029296875 | G Loss: 9.303439583163708e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8463/10000 | D Loss: 7.978332042694092 | G Loss: 7.844457741157385e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8464/10000 | D Loss: 7.858966827392578 | G Loss: 5.857564246980473e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8465/10000 | D Loss: 7.981288433074951 | G Loss: 7.126465106921387e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8466/10000 | D Loss: 7.982104778289795 | G Loss: 9.346182423541904e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8467/10000 | D Loss: 7.818270683288574 | G Loss: 9.545623242956935e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8468/10000 | D Loss: 7.904264450073242 | G Loss: 6.617325425395393e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8469/10000 | D Loss: 7.879537582397461 | G Loss: 8.863515859047766e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8470/10000 | D Loss: 8.043466567993164 | G Loss: 9.706350283522625e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8471/10000 | D Loss: 7.969598293304443 | G Loss: 5.533487410502858e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8472/10000 | D Loss: 7.930563926696777 | G Loss: 7.404509005937143e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8473/10000 | D Loss: 7.891058444976807 | G Loss: 1.588847453604103e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8474/10000 | D Loss: 7.898919105529785 | G Loss: 4.89977651341178e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8475/10000 | D Loss: 8.022014617919922 | G Loss: 8.971505280896963e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8476/10000 | D Loss: 7.941182613372803 | G Loss: 6.390037015080452e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8477/10000 | D Loss: 8.075517654418945 | G Loss: 6.7264420522406e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8478/10000 | D Loss: 7.950798034667969 | G Loss: 7.342317189795722e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8479/10000 | D Loss: 7.88923454284668 | G Loss: 5.649211516356445e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8480/10000 | D Loss: 7.823823928833008 | G Loss: 9.13385463263694e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8481/10000 | D Loss: 7.874114036560059 | G Loss: 1.0398377980891382e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8482/10000 | D Loss: 7.74190616607666 | G Loss: 6.352865966618992e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8483/10000 | D Loss: 7.82996940612793 | G Loss: 7.302644462470198e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8484/10000 | D Loss: 7.952239990234375 | G Loss: 8.177934205377824e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8485/10000 | D Loss: 8.014531135559082 | G Loss: 8.747095421313134e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8486/10000 | D Loss: 7.958945274353027 | G Loss: 6.276285944295523e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8487/10000 | D Loss: 7.926769256591797 | G Loss: 8.316972071042983e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8488/10000 | D Loss: 7.927441596984863 | G Loss: 1.6354731542378431e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8489/10000 | D Loss: 8.010880470275879 | G Loss: 5.534036517929053e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8490/10000 | D Loss: 7.705729961395264 | G Loss: 8.289100605907151e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8491/10000 | D Loss: 7.806452751159668 | G Loss: 7.615126378368586e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8492/10000 | D Loss: 8.083850860595703 | G Loss: 5.085470888843702e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8493/10000 | D Loss: 7.967604637145996 | G Loss: 8.211836188820598e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8494/10000 | D Loss: 7.911149978637695 | G Loss: 8.320686788465537e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8495/10000 | D Loss: 7.962027549743652 | G Loss: 9.473731097386917e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8496/10000 | D Loss: 7.89015007019043 | G Loss: 4.609831307789136e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8497/10000 | D Loss: 7.791914939880371 | G Loss: 5.447831767924072e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8498/10000 | D Loss: 7.849220275878906 | G Loss: 1.0153351013286738e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8499/10000 | D Loss: 7.730618476867676 | G Loss: 6.267104026846937e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8500/10000 | D Loss: 7.873169898986816 | G Loss: 7.535064696639893e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8501/10000 | D Loss: 8.088122367858887 | G Loss: 9.314188105236099e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8502/10000 | D Loss: 7.858338356018066 | G Loss: 8.872615353539004e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8503/10000 | D Loss: 7.9909162521362305 | G Loss: 7.563588724224246e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8504/10000 | D Loss: 7.949621200561523 | G Loss: 7.504794439228135e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8505/10000 | D Loss: 7.986734390258789 | G Loss: 6.94575078341586e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8506/10000 | D Loss: 7.860708236694336 | G Loss: 8.097352974800742e-07\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 8507/10000 | D Loss: 8.041136741638184 | G Loss: 1.8835152104657027e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8508/10000 | D Loss: 7.797228813171387 | G Loss: 7.09581911451096e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8509/10000 | D Loss: 8.012873649597168 | G Loss: 1.206448132506921e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8510/10000 | D Loss: 8.106039047241211 | G Loss: 9.502846864961612e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8511/10000 | D Loss: 7.823775768280029 | G Loss: 8.451203257209272e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8512/10000 | D Loss: 8.005731582641602 | G Loss: 6.19392494627391e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8513/10000 | D Loss: 7.895988941192627 | G Loss: 6.867353476991411e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8514/10000 | D Loss: 7.956362724304199 | G Loss: 5.704852696908347e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8515/10000 | D Loss: 7.943007946014404 | G Loss: 5.657032033923315e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8516/10000 | D Loss: 7.965089321136475 | G Loss: 6.947374231458525e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8517/10000 | D Loss: 7.899349212646484 | G Loss: 5.735017793995212e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8518/10000 | D Loss: 7.894361972808838 | G Loss: 7.753769750706851e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8519/10000 | D Loss: 7.969455718994141 | G Loss: 6.046200837772631e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8520/10000 | D Loss: 8.064157485961914 | G Loss: 5.637553499582282e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8521/10000 | D Loss: 7.861486911773682 | G Loss: 7.498582021980837e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8522/10000 | D Loss: 7.881501197814941 | G Loss: 8.897085876924393e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8523/10000 | D Loss: 8.068174362182617 | G Loss: 7.097278285073116e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8524/10000 | D Loss: 7.82984733581543 | G Loss: 7.793801160005387e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8525/10000 | D Loss: 8.088143348693848 | G Loss: 8.104981361611863e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8526/10000 | D Loss: 7.795962333679199 | G Loss: 6.823049147897109e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8527/10000 | D Loss: 7.941117763519287 | G Loss: 1.1612780781433685e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8528/10000 | D Loss: 7.896193981170654 | G Loss: 7.873554750403855e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8529/10000 | D Loss: 7.949365139007568 | G Loss: 5.275201715448929e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8530/10000 | D Loss: 7.892978191375732 | G Loss: 6.32335741101997e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8531/10000 | D Loss: 7.883637428283691 | G Loss: 6.749419867446704e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8532/10000 | D Loss: 8.060028076171875 | G Loss: 1.038336677083862e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8533/10000 | D Loss: 8.02800178527832 | G Loss: 8.060311529334285e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8534/10000 | D Loss: 7.908824443817139 | G Loss: 9.977613899536664e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8535/10000 | D Loss: 7.9323835372924805 | G Loss: 5.061829142505303e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8536/10000 | D Loss: 7.850696563720703 | G Loss: 4.98611257171433e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8537/10000 | D Loss: 8.034427642822266 | G Loss: 1.0377889338997193e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8538/10000 | D Loss: 7.9192376136779785 | G Loss: 6.113942845331621e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8539/10000 | D Loss: 8.0672607421875 | G Loss: 7.317507311199734e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8540/10000 | D Loss: 7.937397003173828 | G Loss: 1.4894399100739975e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8541/10000 | D Loss: 8.023674011230469 | G Loss: 1.0554183518252103e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8542/10000 | D Loss: 8.184746742248535 | G Loss: 5.448468982649501e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8543/10000 | D Loss: 7.972421646118164 | G Loss: 6.785219284211053e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8544/10000 | D Loss: 7.921079635620117 | G Loss: 7.908990369287494e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8545/10000 | D Loss: 7.741318702697754 | G Loss: 9.570943575454294e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8546/10000 | D Loss: 8.069191932678223 | G Loss: 5.906279625378374e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8547/10000 | D Loss: 7.971887588500977 | G Loss: 8.737672487768577e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8548/10000 | D Loss: 7.924161911010742 | G Loss: 7.616886819050706e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8549/10000 | D Loss: 7.986688613891602 | G Loss: 6.121468913988792e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8550/10000 | D Loss: 7.866847038269043 | G Loss: 6.36606159787334e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8551/10000 | D Loss: 8.13546085357666 | G Loss: 6.570190862476011e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8552/10000 | D Loss: 7.826075553894043 | G Loss: 7.400996651085734e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8553/10000 | D Loss: 8.008012771606445 | G Loss: 6.801276981605042e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8554/10000 | D Loss: 7.882663249969482 | G Loss: 6.176877036523365e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8555/10000 | D Loss: 7.916293144226074 | G Loss: 5.618453542410862e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8556/10000 | D Loss: 8.091739654541016 | G Loss: 6.267890171329782e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8557/10000 | D Loss: 7.8985090255737305 | G Loss: 7.340809702327533e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8558/10000 | D Loss: 7.930340766906738 | G Loss: 6.479734224740241e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8559/10000 | D Loss: 8.074556350708008 | G Loss: 8.097075010482513e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8560/10000 | D Loss: 8.063203811645508 | G Loss: 5.118196213516057e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8561/10000 | D Loss: 8.112476348876953 | G Loss: 8.667691417940659e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8562/10000 | D Loss: 7.975824356079102 | G Loss: 8.705119967089558e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8563/10000 | D Loss: 7.8986029624938965 | G Loss: 4.2522802345956734e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8564/10000 | D Loss: 7.937652111053467 | G Loss: 5.890398711017042e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8565/10000 | D Loss: 8.111377716064453 | G Loss: 8.261029620371119e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8566/10000 | D Loss: 8.049705505371094 | G Loss: 5.124672952661058e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8567/10000 | D Loss: 7.90717887878418 | G Loss: 6.252809043871821e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8568/10000 | D Loss: 7.788376331329346 | G Loss: 6.444714699682663e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8569/10000 | D Loss: 7.908257961273193 | G Loss: 8.635298058834451e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8570/10000 | D Loss: 7.902921676635742 | G Loss: 8.399114790336171e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8571/10000 | D Loss: 8.000785827636719 | G Loss: 6.614849894504005e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8572/10000 | D Loss: 8.06801986694336 | G Loss: 7.531037908847793e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8573/10000 | D Loss: 7.892194747924805 | G Loss: 6.434510169128771e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8574/10000 | D Loss: 8.011180877685547 | G Loss: 5.965721925349499e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8575/10000 | D Loss: 7.77246618270874 | G Loss: 8.424030966125429e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8576/10000 | D Loss: 7.889341354370117 | G Loss: 5.29683347849641e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8577/10000 | D Loss: 7.808213233947754 | G Loss: 5.550448349822545e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8578/10000 | D Loss: 7.941336154937744 | G Loss: 6.213176675373688e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8579/10000 | D Loss: 8.148176193237305 | G Loss: 8.960066679719603e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 8580/10000 | D Loss: 7.923870086669922 | G Loss: 5.318477178661851e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8581/10000 | D Loss: 8.090288162231445 | G Loss: 6.383522190844815e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8582/10000 | D Loss: 7.918129920959473 | G Loss: 7.193385727077839e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8583/10000 | D Loss: 7.953015327453613 | G Loss: 6.588271617147257e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8584/10000 | D Loss: 7.986795902252197 | G Loss: 1.1456097581685754e-06\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 8585/10000 | D Loss: 8.033415794372559 | G Loss: 6.519906605717551e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8586/10000 | D Loss: 7.997872352600098 | G Loss: 8.28110501061019e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8587/10000 | D Loss: 8.217174530029297 | G Loss: 7.395589136649505e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8588/10000 | D Loss: 7.937734603881836 | G Loss: 9.105450544666382e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8589/10000 | D Loss: 7.946865081787109 | G Loss: 8.698673354956554e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8590/10000 | D Loss: 7.976829528808594 | G Loss: 9.367065558762988e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8591/10000 | D Loss: 8.107563972473145 | G Loss: 9.641655651648762e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8592/10000 | D Loss: 7.999660015106201 | G Loss: 6.313929361567716e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8593/10000 | D Loss: 7.970697402954102 | G Loss: 8.889506375453493e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8594/10000 | D Loss: 8.07671070098877 | G Loss: 9.026554153024335e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8595/10000 | D Loss: 7.826035499572754 | G Loss: 9.970390237867832e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8596/10000 | D Loss: 8.018919944763184 | G Loss: 8.409997462877072e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8597/10000 | D Loss: 7.956609725952148 | G Loss: 6.470090738730505e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8598/10000 | D Loss: 7.986540794372559 | G Loss: 5.783832079941931e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8599/10000 | D Loss: 7.8184943199157715 | G Loss: 6.371741392285912e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8600/10000 | D Loss: 7.98499870300293 | G Loss: 1.0762876172520919e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8601/10000 | D Loss: 7.912241458892822 | G Loss: 6.649563601968111e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8602/10000 | D Loss: 8.141195297241211 | G Loss: 6.484086725322413e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8603/10000 | D Loss: 7.912418842315674 | G Loss: 7.20460775482934e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8604/10000 | D Loss: 8.205339431762695 | G Loss: 7.820481187081896e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8605/10000 | D Loss: 8.11434268951416 | G Loss: 1.0798901257658144e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8606/10000 | D Loss: 7.808916091918945 | G Loss: 6.70976362471265e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8607/10000 | D Loss: 7.979345321655273 | G Loss: 5.659895805365522e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8608/10000 | D Loss: 7.798266410827637 | G Loss: 6.853688319097273e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8609/10000 | D Loss: 8.096155166625977 | G Loss: 7.639694104000228e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8610/10000 | D Loss: 7.924012184143066 | G Loss: 5.255636779111228e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8611/10000 | D Loss: 7.9184064865112305 | G Loss: 5.032576950725343e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8612/10000 | D Loss: 7.850346565246582 | G Loss: 8.83430686826614e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8613/10000 | D Loss: 7.919846534729004 | G Loss: 4.431751676747808e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8614/10000 | D Loss: 8.042219161987305 | G Loss: 8.618809488325496e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8615/10000 | D Loss: 7.930922508239746 | G Loss: 6.786982567064115e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8616/10000 | D Loss: 7.981845855712891 | G Loss: 6.103620080466499e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8617/10000 | D Loss: 7.906276702880859 | G Loss: 1.0489306987437885e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8618/10000 | D Loss: 7.935143947601318 | G Loss: 7.423330430356145e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8619/10000 | D Loss: 8.035279273986816 | G Loss: 5.880625622012303e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8620/10000 | D Loss: 7.989852428436279 | G Loss: 7.287127345989575e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8621/10000 | D Loss: 7.897764682769775 | G Loss: 6.056316124158911e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8622/10000 | D Loss: 7.833998203277588 | G Loss: 8.8125034380937e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8623/10000 | D Loss: 7.953866004943848 | G Loss: 5.387487931329815e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8624/10000 | D Loss: 7.948809623718262 | G Loss: 1.0114763426827267e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8625/10000 | D Loss: 8.036436080932617 | G Loss: 6.410313062588102e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8626/10000 | D Loss: 8.147361755371094 | G Loss: 5.734622163799941e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8627/10000 | D Loss: 7.975140571594238 | G Loss: 7.641934871571721e-07\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 8628/10000 | D Loss: 7.862879753112793 | G Loss: 5.578224318014691e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8629/10000 | D Loss: 7.976467609405518 | G Loss: 6.158990686344623e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8630/10000 | D Loss: 8.013446807861328 | G Loss: 7.874189122958342e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8631/10000 | D Loss: 8.065496444702148 | G Loss: 7.003744713074411e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8632/10000 | D Loss: 8.046297073364258 | G Loss: 6.73799092965055e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8633/10000 | D Loss: 8.078222274780273 | G Loss: 1.277353362638678e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8634/10000 | D Loss: 7.979001998901367 | G Loss: 1.0177565172853065e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8635/10000 | D Loss: 8.004542350769043 | G Loss: 6.762957127648406e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8636/10000 | D Loss: 7.949255466461182 | G Loss: 6.081218089093454e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8637/10000 | D Loss: 7.885469436645508 | G Loss: 6.475357849922148e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8638/10000 | D Loss: 7.922276496887207 | G Loss: 4.3167730723325803e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8639/10000 | D Loss: 7.935256481170654 | G Loss: 5.823480933031533e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8640/10000 | D Loss: 7.814100742340088 | G Loss: 8.142930596477527e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8641/10000 | D Loss: 8.051986694335938 | G Loss: 1.1250739362367312e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8642/10000 | D Loss: 8.027528762817383 | G Loss: 5.544802093027101e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8643/10000 | D Loss: 8.004451751708984 | G Loss: 9.001700504995824e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8644/10000 | D Loss: 8.060054779052734 | G Loss: 7.514693152188556e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8645/10000 | D Loss: 7.972373962402344 | G Loss: 5.885413543182949e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8646/10000 | D Loss: 8.033111572265625 | G Loss: 4.0686842339709983e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8647/10000 | D Loss: 7.886994361877441 | G Loss: 7.149504313019861e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8648/10000 | D Loss: 7.993799686431885 | G Loss: 8.489427614222222e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8649/10000 | D Loss: 7.999801158905029 | G Loss: 5.16578779752308e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8650/10000 | D Loss: 7.880951881408691 | G Loss: 6.220460591066512e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8651/10000 | D Loss: 7.899853706359863 | G Loss: 6.331421786853753e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8652/10000 | D Loss: 7.962239742279053 | G Loss: 1.1042860705856583e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8653/10000 | D Loss: 7.845001220703125 | G Loss: 7.454088972735917e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8654/10000 | D Loss: 7.8103837966918945 | G Loss: 6.324354444586788e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8655/10000 | D Loss: 8.153862953186035 | G Loss: 5.68910024867364e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8656/10000 | D Loss: 7.97254753112793 | G Loss: 5.017670900997473e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8657/10000 | D Loss: 8.082408905029297 | G Loss: 7.405750466205063e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8658/10000 | D Loss: 8.122112274169922 | G Loss: 5.281013955027447e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8659/10000 | D Loss: 7.962721347808838 | G Loss: 8.000048410394811e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8660/10000 | D Loss: 8.065597534179688 | G Loss: 6.496495643659728e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8661/10000 | D Loss: 7.839321136474609 | G Loss: 9.207627726937062e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8662/10000 | D Loss: 8.098434448242188 | G Loss: 6.605737326026428e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8663/10000 | D Loss: 8.00474739074707 | G Loss: 5.837402454744733e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8664/10000 | D Loss: 8.003140449523926 | G Loss: 6.234001830307534e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8665/10000 | D Loss: 8.026848793029785 | G Loss: 7.011823299762909e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8666/10000 | D Loss: 7.949461936950684 | G Loss: 5.605845672107534e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8667/10000 | D Loss: 7.899242401123047 | G Loss: 5.223467383075331e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8668/10000 | D Loss: 7.999885559082031 | G Loss: 6.548004307660449e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8669/10000 | D Loss: 7.98321533203125 | G Loss: 1.5744877828183235e-06\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8670/10000 | D Loss: 8.005067825317383 | G Loss: 7.019353915893589e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8671/10000 | D Loss: 7.944262504577637 | G Loss: 6.644056611548876e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8672/10000 | D Loss: 8.061149597167969 | G Loss: 8.046729362831684e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8673/10000 | D Loss: 7.954235553741455 | G Loss: 7.591775101900566e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8674/10000 | D Loss: 8.05743408203125 | G Loss: 6.423101694963407e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8675/10000 | D Loss: 8.04344367980957 | G Loss: 5.678365369021776e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8676/10000 | D Loss: 7.949489593505859 | G Loss: 7.595037914143177e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8677/10000 | D Loss: 7.914006233215332 | G Loss: 7.140661182347685e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8678/10000 | D Loss: 7.889423370361328 | G Loss: 1.0703137149903341e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8679/10000 | D Loss: 7.965914726257324 | G Loss: 6.906096245984372e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8680/10000 | D Loss: 8.000482559204102 | G Loss: 8.568129032937577e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8681/10000 | D Loss: 8.078502655029297 | G Loss: 8.600379715062445e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8682/10000 | D Loss: 7.810953140258789 | G Loss: 5.476950946103898e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8683/10000 | D Loss: 8.015787124633789 | G Loss: 6.367328069245559e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8684/10000 | D Loss: 7.985989570617676 | G Loss: 9.676757599663688e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8685/10000 | D Loss: 7.972956657409668 | G Loss: 5.943035148447962e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8686/10000 | D Loss: 8.010075569152832 | G Loss: 9.792229320737533e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8687/10000 | D Loss: 7.906205177307129 | G Loss: 9.165416372525215e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8688/10000 | D Loss: 8.13337230682373 | G Loss: 6.259640485950513e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8689/10000 | D Loss: 7.860068321228027 | G Loss: 7.903946652731975e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8690/10000 | D Loss: 7.934530258178711 | G Loss: 8.479327107124845e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8691/10000 | D Loss: 8.288750648498535 | G Loss: 7.684348588554712e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8692/10000 | D Loss: 7.972064018249512 | G Loss: 5.829884344166203e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8693/10000 | D Loss: 8.022622108459473 | G Loss: 5.82580980790226e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8694/10000 | D Loss: 8.01301383972168 | G Loss: 5.774952001047495e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8695/10000 | D Loss: 8.09572696685791 | G Loss: 6.469317668233998e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8696/10000 | D Loss: 7.983266830444336 | G Loss: 4.766010306411772e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8697/10000 | D Loss: 7.809200286865234 | G Loss: 7.0272722041409e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8698/10000 | D Loss: 7.997555255889893 | G Loss: 1.2825078101741383e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8699/10000 | D Loss: 8.033790588378906 | G Loss: 9.81854668680171e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8700/10000 | D Loss: 7.915620803833008 | G Loss: 7.084329922690813e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8701/10000 | D Loss: 8.061111450195312 | G Loss: 7.081637249939376e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8702/10000 | D Loss: 7.9227681159973145 | G Loss: 6.026205028319964e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8703/10000 | D Loss: 7.879330635070801 | G Loss: 5.264164428808726e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8704/10000 | D Loss: 7.951438903808594 | G Loss: 8.143973673213623e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8705/10000 | D Loss: 7.947010517120361 | G Loss: 5.17003513778036e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8706/10000 | D Loss: 7.951458930969238 | G Loss: 9.57118572841864e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8707/10000 | D Loss: 7.901477336883545 | G Loss: 6.270877292990917e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8708/10000 | D Loss: 7.857982635498047 | G Loss: 7.763094345136778e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8709/10000 | D Loss: 7.7864885330200195 | G Loss: 5.606440822703007e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8710/10000 | D Loss: 8.036373138427734 | G Loss: 4.520729817159008e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8711/10000 | D Loss: 8.110212326049805 | G Loss: 9.128463034357992e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8712/10000 | D Loss: 8.002167701721191 | G Loss: 1.308209448325215e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8713/10000 | D Loss: 8.080521583557129 | G Loss: 9.334383435088967e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8714/10000 | D Loss: 7.986224174499512 | G Loss: 6.542628625538782e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8715/10000 | D Loss: 8.114828109741211 | G Loss: 8.246410629908496e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8716/10000 | D Loss: 8.138325691223145 | G Loss: 1.0111461961059831e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8717/10000 | D Loss: 7.9666428565979 | G Loss: 7.22982917977788e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8718/10000 | D Loss: 7.965393543243408 | G Loss: 5.388685622165212e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 8719/10000 | D Loss: 7.970848083496094 | G Loss: 8.359536423085956e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8720/10000 | D Loss: 8.145956039428711 | G Loss: 4.990132538296166e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8721/10000 | D Loss: 7.997145652770996 | G Loss: 6.800789833505405e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8722/10000 | D Loss: 7.983110427856445 | G Loss: 5.839086725245579e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8723/10000 | D Loss: 8.037227630615234 | G Loss: 7.234365284602973e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8724/10000 | D Loss: 7.9763617515563965 | G Loss: 7.234770009745262e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8725/10000 | D Loss: 8.123416900634766 | G Loss: 4.373457045403484e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8726/10000 | D Loss: 8.174107551574707 | G Loss: 6.317070528893964e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8727/10000 | D Loss: 8.021059036254883 | G Loss: 1.5096552488103043e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8728/10000 | D Loss: 7.9239501953125 | G Loss: 5.239784854893514e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8729/10000 | D Loss: 8.135374069213867 | G Loss: 9.184961413666315e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8730/10000 | D Loss: 8.06109619140625 | G Loss: 7.00006580700574e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8731/10000 | D Loss: 8.163141250610352 | G Loss: 5.595873631136783e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8732/10000 | D Loss: 8.064762115478516 | G Loss: 8.588740456616506e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8733/10000 | D Loss: 7.993442535400391 | G Loss: 7.800316552675213e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8734/10000 | D Loss: 7.975340366363525 | G Loss: 6.731921189384593e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8735/10000 | D Loss: 8.079201698303223 | G Loss: 7.793250915710814e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8736/10000 | D Loss: 7.8400492668151855 | G Loss: 3.882922214870632e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8737/10000 | D Loss: 7.885640621185303 | G Loss: 5.533359512810421e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8738/10000 | D Loss: 8.005501747131348 | G Loss: 8.051389386309893e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8739/10000 | D Loss: 7.886509418487549 | G Loss: 5.335906507752952e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8740/10000 | D Loss: 7.914062976837158 | G Loss: 8.410229384026024e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8741/10000 | D Loss: 7.938999176025391 | G Loss: 7.128458037186647e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8742/10000 | D Loss: 7.893647193908691 | G Loss: 7.350029136432568e-07\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "Epoch 8743/10000 | D Loss: 7.937945365905762 | G Loss: 7.333305802603718e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8744/10000 | D Loss: 8.137163162231445 | G Loss: 6.466775630542543e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8745/10000 | D Loss: 7.893355369567871 | G Loss: 7.664932581974426e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8746/10000 | D Loss: 7.902239799499512 | G Loss: 7.222276963148033e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8747/10000 | D Loss: 7.951376914978027 | G Loss: 5.295798928273143e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8748/10000 | D Loss: 7.924835205078125 | G Loss: 7.190284350144793e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8749/10000 | D Loss: 7.9576287269592285 | G Loss: 9.73824285210867e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8750/10000 | D Loss: 8.056800842285156 | G Loss: 3.617471406869299e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8751/10000 | D Loss: 7.784438610076904 | G Loss: 6.363766260619741e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8752/10000 | D Loss: 7.983641147613525 | G Loss: 4.769077577293501e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8753/10000 | D Loss: 8.129260063171387 | G Loss: 2.9989323024892656e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8754/10000 | D Loss: 7.959648132324219 | G Loss: 5.909705578233115e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8755/10000 | D Loss: 7.926818370819092 | G Loss: 6.830899792475975e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8756/10000 | D Loss: 8.137956619262695 | G Loss: 7.174712095547875e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8757/10000 | D Loss: 8.06267261505127 | G Loss: 1.1886722859344445e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8758/10000 | D Loss: 7.904932022094727 | G Loss: 7.25090160358377e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8759/10000 | D Loss: 7.999205589294434 | G Loss: 7.541748345829546e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8760/10000 | D Loss: 7.948622226715088 | G Loss: 4.6941963205426873e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8761/10000 | D Loss: 7.983121871948242 | G Loss: 1.0651167485775659e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8762/10000 | D Loss: 8.057835578918457 | G Loss: 7.227670266729547e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8763/10000 | D Loss: 8.020696640014648 | G Loss: 6.299760570982471e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8764/10000 | D Loss: 7.966251373291016 | G Loss: 6.59721365536825e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8765/10000 | D Loss: 8.116945266723633 | G Loss: 7.272404900504625e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8766/10000 | D Loss: 8.024886131286621 | G Loss: 6.817347184551181e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8767/10000 | D Loss: 7.852565765380859 | G Loss: 7.305645794986049e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8768/10000 | D Loss: 8.047836303710938 | G Loss: 5.95674123360368e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8769/10000 | D Loss: 8.065998077392578 | G Loss: 8.724707072360616e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8770/10000 | D Loss: 8.008905410766602 | G Loss: 5.11719463247573e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8771/10000 | D Loss: 7.808312892913818 | G Loss: 7.533992629760178e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8772/10000 | D Loss: 8.067909240722656 | G Loss: 3.8237936905716197e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8773/10000 | D Loss: 7.9233503341674805 | G Loss: 6.384213975252351e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8774/10000 | D Loss: 8.174760818481445 | G Loss: 1.1137904039060231e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8775/10000 | D Loss: 8.122604370117188 | G Loss: 8.941899523051688e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8776/10000 | D Loss: 8.133031845092773 | G Loss: 1.043585598381469e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8777/10000 | D Loss: 7.996339797973633 | G Loss: 7.054042043819209e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8778/10000 | D Loss: 8.065502166748047 | G Loss: 6.917189239175059e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8779/10000 | D Loss: 7.912761688232422 | G Loss: 4.4755455519407406e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8780/10000 | D Loss: 7.893364906311035 | G Loss: 8.420554422627902e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8781/10000 | D Loss: 8.058488845825195 | G Loss: 4.5866960363127873e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8782/10000 | D Loss: 7.9938859939575195 | G Loss: 6.931828124834283e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8783/10000 | D Loss: 8.127216339111328 | G Loss: 3.8449050521194295e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8784/10000 | D Loss: 8.0625 | G Loss: 6.679243824692094e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8785/10000 | D Loss: 8.011086463928223 | G Loss: 7.30491819922463e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8786/10000 | D Loss: 7.987398624420166 | G Loss: 6.661225029347406e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8787/10000 | D Loss: 8.070924758911133 | G Loss: 6.349638397296076e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8788/10000 | D Loss: 8.120308876037598 | G Loss: 8.467884526908165e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8789/10000 | D Loss: 7.995665550231934 | G Loss: 4.822190931008663e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8790/10000 | D Loss: 7.878822326660156 | G Loss: 5.264315632302896e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8791/10000 | D Loss: 7.9623517990112305 | G Loss: 6.441482582886238e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8792/10000 | D Loss: 7.898403167724609 | G Loss: 3.8383473111025523e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8793/10000 | D Loss: 7.942695140838623 | G Loss: 6.202303666213993e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8794/10000 | D Loss: 8.01293659210205 | G Loss: 4.937395488013863e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8795/10000 | D Loss: 7.9549479484558105 | G Loss: 7.451321835105773e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8796/10000 | D Loss: 7.925863265991211 | G Loss: 1.1110982995887753e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8797/10000 | D Loss: 8.073575019836426 | G Loss: 5.542445933315321e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8798/10000 | D Loss: 8.02554702758789 | G Loss: 6.225897664080549e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8799/10000 | D Loss: 7.950381278991699 | G Loss: 7.926244620648504e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8800/10000 | D Loss: 7.897812843322754 | G Loss: 4.859835485149233e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8801/10000 | D Loss: 8.102958679199219 | G Loss: 5.36870061296213e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8802/10000 | D Loss: 7.888187408447266 | G Loss: 6.312444611467072e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8803/10000 | D Loss: 7.910146236419678 | G Loss: 6.520337478832516e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8804/10000 | D Loss: 8.13424301147461 | G Loss: 8.509358622177388e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8805/10000 | D Loss: 7.826852798461914 | G Loss: 5.372889972932171e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8806/10000 | D Loss: 7.945554733276367 | G Loss: 4.581847861118149e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8807/10000 | D Loss: 8.179535865783691 | G Loss: 6.546931672346545e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8808/10000 | D Loss: 7.915899276733398 | G Loss: 6.2088349750411e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8809/10000 | D Loss: 8.091717720031738 | G Loss: 6.859564791739103e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8810/10000 | D Loss: 7.863147258758545 | G Loss: 7.62695549383352e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8811/10000 | D Loss: 7.7844672203063965 | G Loss: 5.610075390904967e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8812/10000 | D Loss: 7.956809043884277 | G Loss: 6.441810000978876e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8813/10000 | D Loss: 8.01518440246582 | G Loss: 6.586218432858004e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8814/10000 | D Loss: 7.920708656311035 | G Loss: 6.146451028143929e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8815/10000 | D Loss: 8.039200782775879 | G Loss: 8.873005299392389e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8816/10000 | D Loss: 8.063132286071777 | G Loss: 8.758479452808388e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 8817/10000 | D Loss: 8.0255765914917 | G Loss: 8.180861641449155e-07\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "Epoch 8818/10000 | D Loss: 8.071372985839844 | G Loss: 1.0738090168160852e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8819/10000 | D Loss: 8.170999526977539 | G Loss: 5.98227700265852e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8820/10000 | D Loss: 8.096726417541504 | G Loss: 8.420240078521601e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8821/10000 | D Loss: 7.90668249130249 | G Loss: 5.897596224713197e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8822/10000 | D Loss: 8.039654731750488 | G Loss: 6.002998702570039e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8823/10000 | D Loss: 8.028257369995117 | G Loss: 6.940690582268871e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8824/10000 | D Loss: 7.911036491394043 | G Loss: 6.51082075364684e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8825/10000 | D Loss: 8.201545715332031 | G Loss: 7.625230296071095e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8826/10000 | D Loss: 8.011594772338867 | G Loss: 7.737731380075275e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 8827/10000 | D Loss: 8.133092880249023 | G Loss: 7.606601002407842e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8828/10000 | D Loss: 8.160163879394531 | G Loss: 6.106955652285251e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8829/10000 | D Loss: 8.049549102783203 | G Loss: 6.430648795685556e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8830/10000 | D Loss: 8.014543533325195 | G Loss: 6.145947963887011e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8831/10000 | D Loss: 8.04985523223877 | G Loss: 5.983630444461596e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8832/10000 | D Loss: 7.947129249572754 | G Loss: 5.018509909859858e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8833/10000 | D Loss: 8.015985488891602 | G Loss: 5.534042202270939e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8834/10000 | D Loss: 7.912529945373535 | G Loss: 7.797173680046399e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8835/10000 | D Loss: 7.879390716552734 | G Loss: 7.18416004019673e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8836/10000 | D Loss: 8.031599044799805 | G Loss: 7.500474339394714e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8837/10000 | D Loss: 8.140357971191406 | G Loss: 5.925747927904013e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8838/10000 | D Loss: 7.840470314025879 | G Loss: 6.29889939318673e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8839/10000 | D Loss: 7.934880256652832 | G Loss: 5.41055953817704e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8840/10000 | D Loss: 7.989227771759033 | G Loss: 7.334678002735018e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8841/10000 | D Loss: 8.070735931396484 | G Loss: 5.20344087817648e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8842/10000 | D Loss: 8.175286293029785 | G Loss: 5.595034053840209e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 8843/10000 | D Loss: 7.981359004974365 | G Loss: 6.586492418136913e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8844/10000 | D Loss: 8.043403625488281 | G Loss: 5.676582759406301e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8845/10000 | D Loss: 7.881023406982422 | G Loss: 5.483232712322206e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8846/10000 | D Loss: 8.04291820526123 | G Loss: 8.579548307352525e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8847/10000 | D Loss: 8.005681991577148 | G Loss: 1.0347019951950642e-06\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8848/10000 | D Loss: 7.937281131744385 | G Loss: 6.175708335831587e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8849/10000 | D Loss: 8.110085487365723 | G Loss: 4.6405128273363516e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8850/10000 | D Loss: 8.029019355773926 | G Loss: 6.351112347147136e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8851/10000 | D Loss: 8.085892677307129 | G Loss: 6.670815082543413e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8852/10000 | D Loss: 8.010784149169922 | G Loss: 5.220108505454846e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8853/10000 | D Loss: 8.05221939086914 | G Loss: 6.041840379111818e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8854/10000 | D Loss: 7.958320140838623 | G Loss: 4.7276745362978545e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8855/10000 | D Loss: 8.073171615600586 | G Loss: 5.0186275757369e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8856/10000 | D Loss: 8.035771369934082 | G Loss: 9.684882797955652e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8857/10000 | D Loss: 7.882061004638672 | G Loss: 7.961889423313551e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8858/10000 | D Loss: 7.9730000495910645 | G Loss: 5.103119065097417e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8859/10000 | D Loss: 8.17500114440918 | G Loss: 4.793889161192055e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8860/10000 | D Loss: 8.011953353881836 | G Loss: 6.668829541922605e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8861/10000 | D Loss: 8.012201309204102 | G Loss: 5.208599986872287e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8862/10000 | D Loss: 8.196576118469238 | G Loss: 5.655876975652063e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8863/10000 | D Loss: 8.059444427490234 | G Loss: 4.926211545352999e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8864/10000 | D Loss: 8.202484130859375 | G Loss: 1.1119275313831167e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8865/10000 | D Loss: 7.946974754333496 | G Loss: 6.544294137711404e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8866/10000 | D Loss: 8.008684158325195 | G Loss: 4.969004407939792e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8867/10000 | D Loss: 8.16635799407959 | G Loss: 7.438441116391914e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8868/10000 | D Loss: 8.19603157043457 | G Loss: 4.2265554611731204e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8869/10000 | D Loss: 8.03611946105957 | G Loss: 4.33936691024428e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8870/10000 | D Loss: 8.077085494995117 | G Loss: 7.52978962736961e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8871/10000 | D Loss: 7.954122543334961 | G Loss: 1.4879462924000109e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8872/10000 | D Loss: 7.860787868499756 | G Loss: 7.975079938660201e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8873/10000 | D Loss: 8.13266372680664 | G Loss: 1.152413915406214e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8874/10000 | D Loss: 8.015178680419922 | G Loss: 6.636311127294903e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8875/10000 | D Loss: 8.127828598022461 | G Loss: 4.3490780399224604e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8876/10000 | D Loss: 8.223701477050781 | G Loss: 5.462293870550639e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8877/10000 | D Loss: 7.8967180252075195 | G Loss: 5.25516611560306e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8878/10000 | D Loss: 8.075724601745605 | G Loss: 1.124995606005541e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8879/10000 | D Loss: 8.170402526855469 | G Loss: 3.4779020552377915e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8880/10000 | D Loss: 7.860644817352295 | G Loss: 8.048417043937661e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8881/10000 | D Loss: 7.953713893890381 | G Loss: 6.369101583914016e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8882/10000 | D Loss: 8.197566986083984 | G Loss: 6.55555481898773e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8883/10000 | D Loss: 7.9070048332214355 | G Loss: 6.847511713203858e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8884/10000 | D Loss: 8.0639009475708 | G Loss: 9.073795581571176e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8885/10000 | D Loss: 8.056034088134766 | G Loss: 6.691471980957431e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8886/10000 | D Loss: 7.923312187194824 | G Loss: 5.225714971857087e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8887/10000 | D Loss: 8.09329891204834 | G Loss: 6.81397864354949e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8888/10000 | D Loss: 8.05372428894043 | G Loss: 6.213578558345034e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8889/10000 | D Loss: 8.055427551269531 | G Loss: 5.869771371180832e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8890/10000 | D Loss: 8.162738800048828 | G Loss: 6.72427347581106e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8891/10000 | D Loss: 8.191333770751953 | G Loss: 2.727761057030875e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8892/10000 | D Loss: 8.066192626953125 | G Loss: 4.618722755367344e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8893/10000 | D Loss: 8.122739791870117 | G Loss: 4.93456241201784e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8894/10000 | D Loss: 8.160451889038086 | G Loss: 4.733278160529153e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8895/10000 | D Loss: 8.154410362243652 | G Loss: 6.772692131562508e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8896/10000 | D Loss: 8.023580551147461 | G Loss: 6.521667046399671e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8897/10000 | D Loss: 8.11631965637207 | G Loss: 4.685652186253719e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8898/10000 | D Loss: 7.886703014373779 | G Loss: 8.71095494403562e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8899/10000 | D Loss: 8.107423782348633 | G Loss: 1.4860200963084935e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8900/10000 | D Loss: 8.15377426147461 | G Loss: 5.999171435178141e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8901/10000 | D Loss: 8.136210441589355 | G Loss: 4.866009817305894e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8902/10000 | D Loss: 8.038122177124023 | G Loss: 4.034584151213494e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8903/10000 | D Loss: 7.996887683868408 | G Loss: 8.827763622321072e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8904/10000 | D Loss: 7.877544403076172 | G Loss: 7.076414476614445e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8905/10000 | D Loss: 8.162496566772461 | G Loss: 5.973634529254923e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8906/10000 | D Loss: 8.00539779663086 | G Loss: 4.521859011674678e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8907/10000 | D Loss: 8.136857986450195 | G Loss: 4.258874071183527e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8908/10000 | D Loss: 7.970968246459961 | G Loss: 1.3398656619756366e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8909/10000 | D Loss: 7.958600044250488 | G Loss: 4.953236611981993e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8910/10000 | D Loss: 8.08608627319336 | G Loss: 7.440904710165341e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8911/10000 | D Loss: 8.086835861206055 | G Loss: 4.4367448026605416e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8912/10000 | D Loss: 7.9376020431518555 | G Loss: 6.416336759684782e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 8913/10000 | D Loss: 8.031615257263184 | G Loss: 9.85332462732913e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8914/10000 | D Loss: 8.077156066894531 | G Loss: 6.735862143614213e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8915/10000 | D Loss: 8.183307647705078 | G Loss: 1.1864378848258639e-06\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8916/10000 | D Loss: 7.9809393882751465 | G Loss: 5.099074087411282e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8917/10000 | D Loss: 8.261918067932129 | G Loss: 8.130117521432112e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8918/10000 | D Loss: 8.221817970275879 | G Loss: 7.785107527524815e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8919/10000 | D Loss: 7.992646217346191 | G Loss: 6.343361746985465e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8920/10000 | D Loss: 7.980140209197998 | G Loss: 6.352983064061846e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8921/10000 | D Loss: 7.980311393737793 | G Loss: 6.058002099962323e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8922/10000 | D Loss: 8.04227066040039 | G Loss: 9.599668828741414e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8923/10000 | D Loss: 8.193225860595703 | G Loss: 8.083165425887273e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8924/10000 | D Loss: 8.006834030151367 | G Loss: 4.7101855216169497e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8925/10000 | D Loss: 7.953505992889404 | G Loss: 6.024891376910091e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8926/10000 | D Loss: 8.095970153808594 | G Loss: 5.937078526585537e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8927/10000 | D Loss: 7.951388359069824 | G Loss: 5.722406513086753e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8928/10000 | D Loss: 8.038597106933594 | G Loss: 5.570578878177912e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8929/10000 | D Loss: 7.9429473876953125 | G Loss: 5.303851366988965e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8930/10000 | D Loss: 7.935441970825195 | G Loss: 4.941254587720323e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8931/10000 | D Loss: 7.989107131958008 | G Loss: 8.688822958902165e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8932/10000 | D Loss: 8.017961502075195 | G Loss: 4.1903095393536205e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8933/10000 | D Loss: 8.100555419921875 | G Loss: 5.151768505129439e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8934/10000 | D Loss: 8.18210506439209 | G Loss: 4.709847303274728e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8935/10000 | D Loss: 7.986103057861328 | G Loss: 8.067509043030441e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8936/10000 | D Loss: 7.922534942626953 | G Loss: 6.0393813328119e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8937/10000 | D Loss: 7.950003623962402 | G Loss: 4.536179858405376e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8938/10000 | D Loss: 8.154254913330078 | G Loss: 3.8824674675197457e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8939/10000 | D Loss: 7.9944844245910645 | G Loss: 4.7289142912632087e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8940/10000 | D Loss: 7.956474304199219 | G Loss: 4.69514276346672e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8941/10000 | D Loss: 7.969283580780029 | G Loss: 6.395887339749606e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8942/10000 | D Loss: 8.050941467285156 | G Loss: 5.302190402289852e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8943/10000 | D Loss: 8.019792556762695 | G Loss: 6.280359912125277e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 8944/10000 | D Loss: 8.060173034667969 | G Loss: 5.233525257608562e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8945/10000 | D Loss: 8.091325759887695 | G Loss: 6.803437031521753e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8946/10000 | D Loss: 8.140729904174805 | G Loss: 5.215536589275871e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8947/10000 | D Loss: 8.019617080688477 | G Loss: 7.392138172690466e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8948/10000 | D Loss: 8.016844749450684 | G Loss: 4.4027177636962733e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8949/10000 | D Loss: 8.062784194946289 | G Loss: 7.450834118571947e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8950/10000 | D Loss: 7.992815971374512 | G Loss: 6.226232471817639e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8951/10000 | D Loss: 8.097620010375977 | G Loss: 6.917051678101416e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8952/10000 | D Loss: 7.966062545776367 | G Loss: 3.4598687648212945e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8953/10000 | D Loss: 8.094461441040039 | G Loss: 5.195853418626939e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8954/10000 | D Loss: 8.088191986083984 | G Loss: 3.815272293650196e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8955/10000 | D Loss: 8.019479751586914 | G Loss: 5.684112238668604e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8956/10000 | D Loss: 8.047464370727539 | G Loss: 5.949253250037145e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8957/10000 | D Loss: 8.13826847076416 | G Loss: 4.266831012955663e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8958/10000 | D Loss: 8.193048477172852 | G Loss: 6.734182420586876e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8959/10000 | D Loss: 8.034758567810059 | G Loss: 4.784379825650831e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8960/10000 | D Loss: 8.094840049743652 | G Loss: 5.323345249053091e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8961/10000 | D Loss: 7.9601311683654785 | G Loss: 7.004403528299008e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8962/10000 | D Loss: 8.11967658996582 | G Loss: 4.4549562971951673e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8963/10000 | D Loss: 8.176360130310059 | G Loss: 7.214363222374232e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8964/10000 | D Loss: 8.022648811340332 | G Loss: 4.897885901300469e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8965/10000 | D Loss: 7.930510520935059 | G Loss: 5.136402023708797e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8966/10000 | D Loss: 7.982645511627197 | G Loss: 9.66397010415676e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8967/10000 | D Loss: 8.217061996459961 | G Loss: 4.976972149961512e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8968/10000 | D Loss: 7.975282669067383 | G Loss: 8.609266046732955e-07\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 8969/10000 | D Loss: 8.052605628967285 | G Loss: 5.595773018285399e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8970/10000 | D Loss: 8.161064147949219 | G Loss: 6.375506131917064e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8971/10000 | D Loss: 8.127490997314453 | G Loss: 4.833233901990752e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 8972/10000 | D Loss: 8.091389656066895 | G Loss: 6.140874120319495e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8973/10000 | D Loss: 8.071895599365234 | G Loss: 5.556734663514362e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8974/10000 | D Loss: 7.977709770202637 | G Loss: 6.081343713049137e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8975/10000 | D Loss: 8.240291595458984 | G Loss: 7.633858558619977e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8976/10000 | D Loss: 8.033224105834961 | G Loss: 5.383915322454413e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8977/10000 | D Loss: 8.076004981994629 | G Loss: 3.65550562264616e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8978/10000 | D Loss: 8.153292655944824 | G Loss: 6.187649432831677e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8979/10000 | D Loss: 8.000894546508789 | G Loss: 4.977463845534658e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8980/10000 | D Loss: 8.015277862548828 | G Loss: 6.112833261795458e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8981/10000 | D Loss: 8.182313919067383 | G Loss: 6.988664154050639e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8982/10000 | D Loss: 7.998467445373535 | G Loss: 7.115352218534099e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8983/10000 | D Loss: 7.985079288482666 | G Loss: 5.509190827979182e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8984/10000 | D Loss: 8.04130744934082 | G Loss: 6.046440148566035e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8985/10000 | D Loss: 7.948652744293213 | G Loss: 4.693815753853414e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8986/10000 | D Loss: 8.021565437316895 | G Loss: 6.581382194781327e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8987/10000 | D Loss: 8.235675811767578 | G Loss: 5.210356448515086e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8988/10000 | D Loss: 7.956308841705322 | G Loss: 8.391997425860609e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8989/10000 | D Loss: 8.026731491088867 | G Loss: 6.970790877858235e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8990/10000 | D Loss: 8.171327590942383 | G Loss: 3.9885679825601983e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8991/10000 | D Loss: 8.008137702941895 | G Loss: 4.671491637964209e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8992/10000 | D Loss: 8.078667640686035 | G Loss: 5.644732254950213e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8993/10000 | D Loss: 8.13306999206543 | G Loss: 6.947195174689114e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8994/10000 | D Loss: 7.94865608215332 | G Loss: 4.3021913143093116e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8995/10000 | D Loss: 8.10836410522461 | G Loss: 5.80937239647028e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8996/10000 | D Loss: 8.044256210327148 | G Loss: 3.089020310653723e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8997/10000 | D Loss: 8.165904998779297 | G Loss: 5.91698096741311e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8998/10000 | D Loss: 8.258916854858398 | G Loss: 6.949568387426552e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8999/10000 | D Loss: 8.031179428100586 | G Loss: 5.021260562898533e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9000/10000 | D Loss: 7.996986389160156 | G Loss: 6.227939479686029e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9001/10000 | D Loss: 8.147911071777344 | G Loss: 7.193660280790937e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9002/10000 | D Loss: 7.954131126403809 | G Loss: 6.452377760979289e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9003/10000 | D Loss: 8.072822570800781 | G Loss: 7.768882710479375e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9004/10000 | D Loss: 8.068811416625977 | G Loss: 5.181931896913738e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9005/10000 | D Loss: 7.989729881286621 | G Loss: 6.637125125052989e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9006/10000 | D Loss: 7.984748840332031 | G Loss: 5.753847744927043e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9007/10000 | D Loss: 8.112222671508789 | G Loss: 5.160757154953899e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9008/10000 | D Loss: 8.004405975341797 | G Loss: 7.705320399509219e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9009/10000 | D Loss: 8.169904708862305 | G Loss: 4.891552976005187e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9010/10000 | D Loss: 8.046441078186035 | G Loss: 4.101513297882775e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9011/10000 | D Loss: 8.051401138305664 | G Loss: 5.439860046863032e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9012/10000 | D Loss: 8.15646743774414 | G Loss: 5.515740326700325e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9013/10000 | D Loss: 8.013923645019531 | G Loss: 4.89155183913681e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9014/10000 | D Loss: 8.101373672485352 | G Loss: 3.8046545114411856e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9015/10000 | D Loss: 8.040263175964355 | G Loss: 4.591522895225353e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9016/10000 | D Loss: 8.045940399169922 | G Loss: 4.540594886748295e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9017/10000 | D Loss: 7.91508674621582 | G Loss: 7.09794676367892e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9018/10000 | D Loss: 8.033334732055664 | G Loss: 1.0819589988386724e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9019/10000 | D Loss: 8.175619125366211 | G Loss: 5.888232408324257e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9020/10000 | D Loss: 8.148484230041504 | G Loss: 7.717662811046466e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9021/10000 | D Loss: 8.044677734375 | G Loss: 4.319043398481881e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9022/10000 | D Loss: 8.028922080993652 | G Loss: 6.054394248167227e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9023/10000 | D Loss: 8.131754875183105 | G Loss: 6.477001761595602e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9024/10000 | D Loss: 8.196514129638672 | G Loss: 7.512243200835655e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9025/10000 | D Loss: 7.788578987121582 | G Loss: 5.615979148387851e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9026/10000 | D Loss: 7.982607841491699 | G Loss: 3.0849440690872143e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9027/10000 | D Loss: 8.323192596435547 | G Loss: 5.860650844624615e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9028/10000 | D Loss: 8.045446395874023 | G Loss: 3.576433300622739e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9029/10000 | D Loss: 8.07423210144043 | G Loss: 5.995192395857885e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9030/10000 | D Loss: 8.175646781921387 | G Loss: 1.1896847809111932e-06\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9031/10000 | D Loss: 7.923723220825195 | G Loss: 9.022354561238899e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9032/10000 | D Loss: 8.008293151855469 | G Loss: 3.919508344552014e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9033/10000 | D Loss: 8.037607192993164 | G Loss: 5.05606408296444e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9034/10000 | D Loss: 8.169855117797852 | G Loss: 4.356021463536308e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9035/10000 | D Loss: 8.301090240478516 | G Loss: 1.1278472129561123e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9036/10000 | D Loss: 8.162511825561523 | G Loss: 5.585178541878122e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9037/10000 | D Loss: 8.21854019165039 | G Loss: 6.900326070535812e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9038/10000 | D Loss: 8.102209091186523 | G Loss: 6.030969643688877e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9039/10000 | D Loss: 8.113326072692871 | G Loss: 6.007112460792996e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9040/10000 | D Loss: 8.081634521484375 | G Loss: 4.449403263606655e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9041/10000 | D Loss: 8.06723403930664 | G Loss: 5.428711347121862e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9042/10000 | D Loss: 8.199459075927734 | G Loss: 6.254157369767199e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9043/10000 | D Loss: 7.996761798858643 | G Loss: 4.845393277719268e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9044/10000 | D Loss: 7.930568695068359 | G Loss: 6.221888497748296e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9045/10000 | D Loss: 8.102730751037598 | G Loss: 4.6113402163427963e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9046/10000 | D Loss: 8.152751922607422 | G Loss: 4.998221356800059e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9047/10000 | D Loss: 8.071248054504395 | G Loss: 5.296814720168186e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9048/10000 | D Loss: 8.089269638061523 | G Loss: 8.623939038443496e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9049/10000 | D Loss: 7.955060958862305 | G Loss: 5.526827067114937e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9050/10000 | D Loss: 8.066970825195312 | G Loss: 1.5215136954793707e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9051/10000 | D Loss: 8.26705551147461 | G Loss: 8.495762244820071e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9052/10000 | D Loss: 8.208442687988281 | G Loss: 4.9139066504722e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9053/10000 | D Loss: 8.085517883300781 | G Loss: 5.566873255702376e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9054/10000 | D Loss: 8.107431411743164 | G Loss: 6.121125579738873e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9055/10000 | D Loss: 8.153009414672852 | G Loss: 6.08826439929544e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9056/10000 | D Loss: 8.097482681274414 | G Loss: 5.190984779801511e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9057/10000 | D Loss: 8.099562644958496 | G Loss: 6.419372766686138e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9058/10000 | D Loss: 8.178885459899902 | G Loss: 4.159757054367219e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9059/10000 | D Loss: 8.118897438049316 | G Loss: 4.4158133505334263e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9060/10000 | D Loss: 7.992280960083008 | G Loss: 7.963132020449848e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9061/10000 | D Loss: 8.033239364624023 | G Loss: 5.755355232395232e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9062/10000 | D Loss: 8.062122344970703 | G Loss: 6.823757416896115e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9063/10000 | D Loss: 8.223522186279297 | G Loss: 4.251946847944055e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9064/10000 | D Loss: 8.099227905273438 | G Loss: 6.529126039822586e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9065/10000 | D Loss: 8.207879066467285 | G Loss: 6.77089019518462e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9066/10000 | D Loss: 8.084546089172363 | G Loss: 3.338180647460831e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9067/10000 | D Loss: 8.111867904663086 | G Loss: 6.101844292061287e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9068/10000 | D Loss: 8.134149551391602 | G Loss: 4.5427691475197207e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9069/10000 | D Loss: 8.144192695617676 | G Loss: 5.944770578025782e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9070/10000 | D Loss: 8.140471458435059 | G Loss: 9.055165719473734e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9071/10000 | D Loss: 7.925063133239746 | G Loss: 5.115840053804277e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9072/10000 | D Loss: 8.160276412963867 | G Loss: 3.3642629659880185e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9073/10000 | D Loss: 8.049055099487305 | G Loss: 5.372121449909173e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9074/10000 | D Loss: 8.079490661621094 | G Loss: 4.830599209526554e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9075/10000 | D Loss: 8.009459495544434 | G Loss: 5.047824060966377e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9076/10000 | D Loss: 8.085897445678711 | G Loss: 4.563632387544203e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9077/10000 | D Loss: 7.952076435089111 | G Loss: 9.054543284037209e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9078/10000 | D Loss: 8.22709846496582 | G Loss: 3.2927505344559904e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9079/10000 | D Loss: 8.150166511535645 | G Loss: 6.956926199563895e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9080/10000 | D Loss: 8.117610931396484 | G Loss: 6.264838816605334e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9081/10000 | D Loss: 8.085918426513672 | G Loss: 5.445422743832751e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9082/10000 | D Loss: 7.972379207611084 | G Loss: 4.1048855337066925e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9083/10000 | D Loss: 8.210476875305176 | G Loss: 4.101864590211335e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9084/10000 | D Loss: 8.133367538452148 | G Loss: 6.176965143822599e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9085/10000 | D Loss: 8.198770523071289 | G Loss: 6.352158266054175e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9086/10000 | D Loss: 8.1146240234375 | G Loss: 5.093859272164991e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9087/10000 | D Loss: 8.057413101196289 | G Loss: 4.288404227281717e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9088/10000 | D Loss: 7.989567756652832 | G Loss: 4.421419248501479e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9089/10000 | D Loss: 8.145875930786133 | G Loss: 3.389158109712298e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9090/10000 | D Loss: 8.274356842041016 | G Loss: 5.891431555937743e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9091/10000 | D Loss: 8.128569602966309 | G Loss: 8.229159220718429e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9092/10000 | D Loss: 8.262869834899902 | G Loss: 7.001437438702851e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9093/10000 | D Loss: 8.139037132263184 | G Loss: 3.727406578946102e-07\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9094/10000 | D Loss: 8.019729614257812 | G Loss: 6.988981340327882e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9095/10000 | D Loss: 8.101186752319336 | G Loss: 1.2031738378937007e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9096/10000 | D Loss: 8.131830215454102 | G Loss: 6.442846824938897e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9097/10000 | D Loss: 8.062881469726562 | G Loss: 4.77874436910497e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9098/10000 | D Loss: 8.215234756469727 | G Loss: 6.037713546902523e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9099/10000 | D Loss: 8.1174898147583 | G Loss: 4.03120225200837e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9100/10000 | D Loss: 8.315399169921875 | G Loss: 9.292375580116641e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9101/10000 | D Loss: 8.247751235961914 | G Loss: 7.291719725799339e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9102/10000 | D Loss: 8.177766799926758 | G Loss: 5.075372655483079e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9103/10000 | D Loss: 8.127355575561523 | G Loss: 4.017040851067577e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9104/10000 | D Loss: 8.065004348754883 | G Loss: 7.981178669069777e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9105/10000 | D Loss: 8.139936447143555 | G Loss: 6.333524424917414e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9106/10000 | D Loss: 8.111557006835938 | G Loss: 5.137518996889412e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9107/10000 | D Loss: 8.043210983276367 | G Loss: 3.941039494748111e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9108/10000 | D Loss: 8.16618537902832 | G Loss: 6.703348844894208e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9109/10000 | D Loss: 7.9644341468811035 | G Loss: 6.870711786177708e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9110/10000 | D Loss: 8.175540924072266 | G Loss: 5.065381856184104e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9111/10000 | D Loss: 8.169408798217773 | G Loss: 3.9685548358647793e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9112/10000 | D Loss: 8.115763664245605 | G Loss: 9.038254802362644e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9113/10000 | D Loss: 8.101898193359375 | G Loss: 4.474601666970557e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9114/10000 | D Loss: 8.055961608886719 | G Loss: 7.167325293266913e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9115/10000 | D Loss: 8.006208419799805 | G Loss: 4.525873009697534e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9116/10000 | D Loss: 7.968503952026367 | G Loss: 5.397707241172611e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9117/10000 | D Loss: 8.07719898223877 | G Loss: 5.660483566316543e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9118/10000 | D Loss: 8.121906280517578 | G Loss: 5.682200594492315e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9119/10000 | D Loss: 8.128822326660156 | G Loss: 4.713322141469689e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9120/10000 | D Loss: 8.123172760009766 | G Loss: 6.000166195008205e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9121/10000 | D Loss: 8.06689167022705 | G Loss: 1.399610027874587e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9122/10000 | D Loss: 8.210119247436523 | G Loss: 4.911630071546824e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9123/10000 | D Loss: 8.319480895996094 | G Loss: 4.91728769702604e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9124/10000 | D Loss: 7.994870662689209 | G Loss: 1.166012225439772e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9125/10000 | D Loss: 8.00352668762207 | G Loss: 6.275892019402818e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9126/10000 | D Loss: 8.03520679473877 | G Loss: 3.3383454933755274e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9127/10000 | D Loss: 8.447477340698242 | G Loss: 5.947608201495314e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9128/10000 | D Loss: 8.023138046264648 | G Loss: 5.167701147001935e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9129/10000 | D Loss: 7.9188995361328125 | G Loss: 8.263681934295164e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9130/10000 | D Loss: 8.164532661437988 | G Loss: 6.058787676010979e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9131/10000 | D Loss: 8.071022033691406 | G Loss: 5.257247721601743e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9132/10000 | D Loss: 7.9963059425354 | G Loss: 5.630202508655202e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9133/10000 | D Loss: 8.128846168518066 | G Loss: 7.624178124387981e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9134/10000 | D Loss: 8.061347007751465 | G Loss: 5.406407126429258e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9135/10000 | D Loss: 7.973804473876953 | G Loss: 5.388462795963278e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9136/10000 | D Loss: 8.082399368286133 | G Loss: 6.939680474715715e-07\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch 9137/10000 | D Loss: 8.027813911437988 | G Loss: 3.9655176919950463e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9138/10000 | D Loss: 8.011967658996582 | G Loss: 9.105363005801337e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9139/10000 | D Loss: 8.088994979858398 | G Loss: 5.475205853144871e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9140/10000 | D Loss: 8.184882164001465 | G Loss: 6.106761816226935e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9141/10000 | D Loss: 8.121689796447754 | G Loss: 4.823700692213606e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9142/10000 | D Loss: 8.263839721679688 | G Loss: 2.780475938379823e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9143/10000 | D Loss: 8.121858596801758 | G Loss: 7.057863058435032e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9144/10000 | D Loss: 8.263187408447266 | G Loss: 5.454098754853476e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9145/10000 | D Loss: 8.110548973083496 | G Loss: 5.4637428092974e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9146/10000 | D Loss: 8.002918243408203 | G Loss: 5.395388598117279e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9147/10000 | D Loss: 8.120529174804688 | G Loss: 6.872159019621904e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9148/10000 | D Loss: 8.106315612792969 | G Loss: 5.940915457358642e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9149/10000 | D Loss: 8.095009803771973 | G Loss: 5.640280278385035e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9150/10000 | D Loss: 8.118173599243164 | G Loss: 1.0461832289365702e-06\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9151/10000 | D Loss: 8.28329086303711 | G Loss: 4.937231210533355e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9152/10000 | D Loss: 8.222053527832031 | G Loss: 3.6181631912768353e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9153/10000 | D Loss: 8.110132217407227 | G Loss: 6.070961831028399e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9154/10000 | D Loss: 8.099418640136719 | G Loss: 4.913461566502519e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9155/10000 | D Loss: 8.121938705444336 | G Loss: 5.845023451911402e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9156/10000 | D Loss: 8.094104766845703 | G Loss: 4.382417557735607e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9157/10000 | D Loss: 8.070762634277344 | G Loss: 5.654106303154549e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9158/10000 | D Loss: 8.216110229492188 | G Loss: 7.168296178861056e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9159/10000 | D Loss: 8.217578887939453 | G Loss: 4.1691737351357006e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9160/10000 | D Loss: 8.221175193786621 | G Loss: 7.960597372402844e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9161/10000 | D Loss: 8.019277572631836 | G Loss: 5.452796472127375e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9162/10000 | D Loss: 8.285211563110352 | G Loss: 4.24178836055944e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9163/10000 | D Loss: 7.974475860595703 | G Loss: 4.143989826843608e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9164/10000 | D Loss: 8.106486320495605 | G Loss: 5.487182761498843e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9165/10000 | D Loss: 8.103080749511719 | G Loss: 5.711821131626493e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9166/10000 | D Loss: 8.02062702178955 | G Loss: 5.254708526081231e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9167/10000 | D Loss: 8.313668251037598 | G Loss: 4.044572676775715e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9168/10000 | D Loss: 8.101397514343262 | G Loss: 5.264352012090967e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9169/10000 | D Loss: 8.084451675415039 | G Loss: 5.847555257787462e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9170/10000 | D Loss: 8.154886245727539 | G Loss: 3.896039970641141e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9171/10000 | D Loss: 8.153032302856445 | G Loss: 3.4632321899152885e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9172/10000 | D Loss: 8.278253555297852 | G Loss: 4.838003064833174e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9173/10000 | D Loss: 8.07498550415039 | G Loss: 4.084021156813833e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9174/10000 | D Loss: 8.14727783203125 | G Loss: 4.5165506890043616e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9175/10000 | D Loss: 8.176570892333984 | G Loss: 4.7554036086694396e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9176/10000 | D Loss: 8.122021675109863 | G Loss: 4.5810304527549306e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9177/10000 | D Loss: 8.116166114807129 | G Loss: 4.716636965440557e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9178/10000 | D Loss: 8.196158409118652 | G Loss: 4.5824185690435115e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9179/10000 | D Loss: 8.107048034667969 | G Loss: 6.451222134273848e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9180/10000 | D Loss: 8.151005744934082 | G Loss: 3.0872428169459454e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9181/10000 | D Loss: 7.853304386138916 | G Loss: 5.339551876204496e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9182/10000 | D Loss: 8.119996070861816 | G Loss: 3.845079277198238e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9183/10000 | D Loss: 8.152174949645996 | G Loss: 4.074309742918558e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9184/10000 | D Loss: 8.088223457336426 | G Loss: 7.04667854733998e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9185/10000 | D Loss: 8.131706237792969 | G Loss: 5.256396207187208e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9186/10000 | D Loss: 8.104959487915039 | G Loss: 3.922529572264466e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9187/10000 | D Loss: 8.240528106689453 | G Loss: 5.978004651296942e-07\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "Epoch 9188/10000 | D Loss: 8.068964004516602 | G Loss: 6.289994303187996e-07\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 9189/10000 | D Loss: 8.108566284179688 | G Loss: 5.784133918496082e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9190/10000 | D Loss: 8.249791145324707 | G Loss: 5.400667077992694e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9191/10000 | D Loss: 8.181883811950684 | G Loss: 5.307249466568464e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9192/10000 | D Loss: 8.22769832611084 | G Loss: 4.976272975909524e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9193/10000 | D Loss: 8.383893966674805 | G Loss: 4.4593454617825046e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9194/10000 | D Loss: 8.116268157958984 | G Loss: 5.46139062862494e-07\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 9195/10000 | D Loss: 8.290159225463867 | G Loss: 1.0334350690754945e-06\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9196/10000 | D Loss: 8.089248657226562 | G Loss: 3.9216195091285044e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9197/10000 | D Loss: 8.048849105834961 | G Loss: 7.718469419160101e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9198/10000 | D Loss: 8.14538860321045 | G Loss: 1.2364051826807554e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9199/10000 | D Loss: 8.190881729125977 | G Loss: 8.436493317276472e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9200/10000 | D Loss: 8.140246391296387 | G Loss: 8.227741545852041e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9201/10000 | D Loss: 8.14175033569336 | G Loss: 4.4648925268120365e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9202/10000 | D Loss: 8.066269874572754 | G Loss: 5.207543836149853e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9203/10000 | D Loss: 8.000947952270508 | G Loss: 4.589009279243328e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9204/10000 | D Loss: 8.020254135131836 | G Loss: 5.948916736997489e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9205/10000 | D Loss: 8.135807037353516 | G Loss: 4.292045332476846e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9206/10000 | D Loss: 8.107355117797852 | G Loss: 6.474482461271691e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9207/10000 | D Loss: 7.955613136291504 | G Loss: 4.03439173624065e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9208/10000 | D Loss: 7.885931491851807 | G Loss: 4.756464306865382e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9209/10000 | D Loss: 8.29251480102539 | G Loss: 3.975704885306186e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9210/10000 | D Loss: 8.136167526245117 | G Loss: 3.2459468002343783e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9211/10000 | D Loss: 8.298858642578125 | G Loss: 7.023488706181524e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9212/10000 | D Loss: 8.185722351074219 | G Loss: 6.159627332635864e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9213/10000 | D Loss: 8.0150146484375 | G Loss: 5.749726597059635e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9214/10000 | D Loss: 8.214672088623047 | G Loss: 4.773564796778373e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9215/10000 | D Loss: 8.055022239685059 | G Loss: 3.305285645183176e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9216/10000 | D Loss: 8.258001327514648 | G Loss: 6.030710437698872e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9217/10000 | D Loss: 8.171167373657227 | G Loss: 4.208365567137662e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9218/10000 | D Loss: 8.080564498901367 | G Loss: 5.667105824613827e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9219/10000 | D Loss: 8.316527366638184 | G Loss: 4.195352403257857e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9220/10000 | D Loss: 8.156282424926758 | G Loss: 5.457982297230046e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9221/10000 | D Loss: 8.158129692077637 | G Loss: 5.05389948557422e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9222/10000 | D Loss: 8.140776634216309 | G Loss: 2.577658051450271e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9223/10000 | D Loss: 8.048787117004395 | G Loss: 7.578429404020426e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9224/10000 | D Loss: 7.957886219024658 | G Loss: 4.937063522447716e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9225/10000 | D Loss: 8.211204528808594 | G Loss: 5.037452979195223e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9226/10000 | D Loss: 8.10605239868164 | G Loss: 5.614793963104603e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9227/10000 | D Loss: 8.164060592651367 | G Loss: 6.714440701216517e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9228/10000 | D Loss: 8.286925315856934 | G Loss: 7.67474034546467e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9229/10000 | D Loss: 8.25508975982666 | G Loss: 6.439371418309747e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9230/10000 | D Loss: 7.920408248901367 | G Loss: 5.90324702898215e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9231/10000 | D Loss: 8.256771087646484 | G Loss: 4.2454030335647985e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9232/10000 | D Loss: 8.43164348602295 | G Loss: 3.485140780412621e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9233/10000 | D Loss: 8.21096420288086 | G Loss: 4.1421168361921445e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9234/10000 | D Loss: 8.154297828674316 | G Loss: 6.659047357970849e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9235/10000 | D Loss: 8.258085250854492 | G Loss: 4.3733035681725596e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9236/10000 | D Loss: 8.124125480651855 | G Loss: 4.4913417696079705e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9237/10000 | D Loss: 8.166501998901367 | G Loss: 4.190842730622535e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9238/10000 | D Loss: 8.022930145263672 | G Loss: 7.095158025549608e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9239/10000 | D Loss: 8.041117668151855 | G Loss: 4.844637828682608e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9240/10000 | D Loss: 8.002205848693848 | G Loss: 5.061373258286039e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9241/10000 | D Loss: 8.138201713562012 | G Loss: 6.10749509633024e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9242/10000 | D Loss: 8.314554214477539 | G Loss: 5.601798420684645e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9243/10000 | D Loss: 8.197820663452148 | G Loss: 4.5139529447624227e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9244/10000 | D Loss: 8.20795726776123 | G Loss: 5.984588824503589e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9245/10000 | D Loss: 8.228641510009766 | G Loss: 6.201971700647846e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9246/10000 | D Loss: 7.950376510620117 | G Loss: 3.406892972179776e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9247/10000 | D Loss: 8.05667495727539 | G Loss: 3.892697293395031e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9248/10000 | D Loss: 8.187406539916992 | G Loss: 4.7666276259406004e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9249/10000 | D Loss: 8.254196166992188 | G Loss: 3.866328199819691e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9250/10000 | D Loss: 8.118265151977539 | G Loss: 1.0210436585111893e-06\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9251/10000 | D Loss: 7.984010696411133 | G Loss: 6.526555011987512e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9252/10000 | D Loss: 8.075544357299805 | G Loss: 1.2588106983457692e-06\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9253/10000 | D Loss: 8.149818420410156 | G Loss: 4.983282906323439e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9254/10000 | D Loss: 8.076845169067383 | G Loss: 5.820185720040172e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9255/10000 | D Loss: 8.217222213745117 | G Loss: 3.182092029874184e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9256/10000 | D Loss: 8.334577560424805 | G Loss: 4.153009740548441e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9257/10000 | D Loss: 8.10055160522461 | G Loss: 7.9504752648063e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9258/10000 | D Loss: 8.08338737487793 | G Loss: 4.620546860678587e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9259/10000 | D Loss: 8.107148170471191 | G Loss: 7.50395543036575e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9260/10000 | D Loss: 8.208395957946777 | G Loss: 3.7130701002752176e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9261/10000 | D Loss: 8.149372100830078 | G Loss: 6.935239866834308e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9262/10000 | D Loss: 8.03598403930664 | G Loss: 5.387619239627384e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9263/10000 | D Loss: 8.111709594726562 | G Loss: 9.846771718002856e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9264/10000 | D Loss: 8.206184387207031 | G Loss: 6.261322482714604e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9265/10000 | D Loss: 8.279902458190918 | G Loss: 3.7388974760688143e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9266/10000 | D Loss: 8.04835319519043 | G Loss: 4.396655128857674e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9267/10000 | D Loss: 8.187599182128906 | G Loss: 3.911285944013798e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9268/10000 | D Loss: 8.098917961120605 | G Loss: 5.202929287406732e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9269/10000 | D Loss: 8.057596206665039 | G Loss: 4.884489044343354e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9270/10000 | D Loss: 8.235870361328125 | G Loss: 5.620703973363561e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9271/10000 | D Loss: 8.258207321166992 | G Loss: 3.0945483331379364e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9272/10000 | D Loss: 7.973099708557129 | G Loss: 3.7115003692633763e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9273/10000 | D Loss: 8.28011703491211 | G Loss: 6.304585440375376e-07\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 9274/10000 | D Loss: 8.358406066894531 | G Loss: 3.5939183362643234e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9275/10000 | D Loss: 8.095605850219727 | G Loss: 6.910379397595534e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9276/10000 | D Loss: 8.362015724182129 | G Loss: 5.912642109251465e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9277/10000 | D Loss: 8.016307830810547 | G Loss: 6.596044386242284e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9278/10000 | D Loss: 8.091943740844727 | G Loss: 3.739269232028164e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9279/10000 | D Loss: 8.321575164794922 | G Loss: 4.183009423286421e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9280/10000 | D Loss: 8.096599578857422 | G Loss: 7.715653396189737e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9281/10000 | D Loss: 8.259349822998047 | G Loss: 3.6413848647498526e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9282/10000 | D Loss: 8.066533088684082 | G Loss: 6.501754228338541e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9283/10000 | D Loss: 8.202869415283203 | G Loss: 3.510647843540937e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9284/10000 | D Loss: 8.270841598510742 | G Loss: 5.440742256723752e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9285/10000 | D Loss: 8.182148933410645 | G Loss: 3.289081860202714e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9286/10000 | D Loss: 8.017608642578125 | G Loss: 5.527350595002645e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9287/10000 | D Loss: 8.148477554321289 | G Loss: 4.5611622567776067e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9288/10000 | D Loss: 8.34811782836914 | G Loss: 4.3966670659756346e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9289/10000 | D Loss: 8.13217544555664 | G Loss: 7.310657679227006e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9290/10000 | D Loss: 8.20411491394043 | G Loss: 4.334759182711423e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9291/10000 | D Loss: 8.055379867553711 | G Loss: 6.763697797396162e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9292/10000 | D Loss: 8.263446807861328 | G Loss: 6.132215730758617e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9293/10000 | D Loss: 8.009149551391602 | G Loss: 6.19157674464077e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9294/10000 | D Loss: 8.113608360290527 | G Loss: 3.355984574682225e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9295/10000 | D Loss: 8.171796798706055 | G Loss: 7.68864595102059e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9296/10000 | D Loss: 8.117136001586914 | G Loss: 3.388194329545513e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9297/10000 | D Loss: 8.117166519165039 | G Loss: 4.0888798480409605e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9298/10000 | D Loss: 8.307611465454102 | G Loss: 4.7414366122211504e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9299/10000 | D Loss: 8.1376314163208 | G Loss: 4.1716910459399514e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9300/10000 | D Loss: 8.366990089416504 | G Loss: 5.421404694061494e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9301/10000 | D Loss: 8.249452590942383 | G Loss: 7.212943273771089e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9302/10000 | D Loss: 8.075199127197266 | G Loss: 3.3461668635936803e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9303/10000 | D Loss: 8.335615158081055 | G Loss: 4.13772852425609e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9304/10000 | D Loss: 8.200602531433105 | G Loss: 3.678980249333108e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9305/10000 | D Loss: 8.107518196105957 | G Loss: 6.183218488331477e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9306/10000 | D Loss: 8.245281219482422 | G Loss: 6.811359867242572e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9307/10000 | D Loss: 8.21135139465332 | G Loss: 4.450516541965044e-07\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch 9308/10000 | D Loss: 8.16357135772705 | G Loss: 3.6354057897369785e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9309/10000 | D Loss: 8.224098205566406 | G Loss: 5.518514853974921e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9310/10000 | D Loss: 8.127908706665039 | G Loss: 5.374739657781902e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9311/10000 | D Loss: 8.39699935913086 | G Loss: 4.091676260031818e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9312/10000 | D Loss: 8.027315139770508 | G Loss: 6.270432777455426e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9313/10000 | D Loss: 8.295781135559082 | G Loss: 3.060778226426919e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9314/10000 | D Loss: 8.236729621887207 | G Loss: 4.3044863673458167e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9315/10000 | D Loss: 8.276845932006836 | G Loss: 4.4040311308890523e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9316/10000 | D Loss: 8.188486099243164 | G Loss: 5.639484470520983e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9317/10000 | D Loss: 8.215396881103516 | G Loss: 3.3792775866459124e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9318/10000 | D Loss: 8.164997100830078 | G Loss: 5.730013867832895e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9319/10000 | D Loss: 8.320642471313477 | G Loss: 3.8729453422092774e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9320/10000 | D Loss: 8.322433471679688 | G Loss: 5.377252705329738e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9321/10000 | D Loss: 8.1677827835083 | G Loss: 5.138645633451233e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9322/10000 | D Loss: 8.242873191833496 | G Loss: 5.493878916240647e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9323/10000 | D Loss: 8.080412864685059 | G Loss: 5.171037287254876e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9324/10000 | D Loss: 8.111825942993164 | G Loss: 4.895891834166832e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9325/10000 | D Loss: 8.243876457214355 | G Loss: 7.484645720978733e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9326/10000 | D Loss: 8.151058197021484 | G Loss: 4.1899897951225284e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9327/10000 | D Loss: 8.42310905456543 | G Loss: 6.022557954565855e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9328/10000 | D Loss: 8.17178726196289 | G Loss: 5.241037115411018e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9329/10000 | D Loss: 8.153374671936035 | G Loss: 3.5202384651711327e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9330/10000 | D Loss: 7.909207344055176 | G Loss: 6.063047521820408e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9331/10000 | D Loss: 8.146055221557617 | G Loss: 6.503523763967678e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9332/10000 | D Loss: 8.013504028320312 | G Loss: 3.891087771989987e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9333/10000 | D Loss: 8.163232803344727 | G Loss: 3.347848291923583e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9334/10000 | D Loss: 8.348889350891113 | G Loss: 3.441379590185534e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9335/10000 | D Loss: 8.107057571411133 | G Loss: 3.700198476508376e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9336/10000 | D Loss: 8.296394348144531 | G Loss: 3.1945887712936383e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9337/10000 | D Loss: 8.153251647949219 | G Loss: 7.559191317341174e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9338/10000 | D Loss: 8.313812255859375 | G Loss: 3.100173557868402e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9339/10000 | D Loss: 8.244674682617188 | G Loss: 4.495082350786106e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9340/10000 | D Loss: 8.196422576904297 | G Loss: 3.844164382371673e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9341/10000 | D Loss: 8.176457405090332 | G Loss: 4.7680225634394446e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9342/10000 | D Loss: 8.074697494506836 | G Loss: 4.163040046023525e-07\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "Epoch 9343/10000 | D Loss: 8.234392166137695 | G Loss: 4.33229985219441e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9344/10000 | D Loss: 8.171073913574219 | G Loss: 7.034840336928028e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9345/10000 | D Loss: 8.388588905334473 | G Loss: 3.844551486054115e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9346/10000 | D Loss: 8.108830451965332 | G Loss: 5.051129505773133e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9347/10000 | D Loss: 8.134319305419922 | G Loss: 3.6936430092282535e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9348/10000 | D Loss: 8.186386108398438 | G Loss: 4.178365884399682e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9349/10000 | D Loss: 8.106868743896484 | G Loss: 9.778842695595813e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9350/10000 | D Loss: 8.30698299407959 | G Loss: 5.807181651107385e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9351/10000 | D Loss: 8.193886756896973 | G Loss: 4.7248522605514154e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9352/10000 | D Loss: 8.099678039550781 | G Loss: 3.692139216582291e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9353/10000 | D Loss: 8.184185028076172 | G Loss: 3.554297052232869e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9354/10000 | D Loss: 8.113445281982422 | G Loss: 3.3102895713454927e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9355/10000 | D Loss: 8.11214828491211 | G Loss: 3.942018338420894e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9356/10000 | D Loss: 8.417681694030762 | G Loss: 2.766180955404707e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9357/10000 | D Loss: 8.254412651062012 | G Loss: 3.70493410173367e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9358/10000 | D Loss: 8.109342575073242 | G Loss: 4.602864009939367e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9359/10000 | D Loss: 8.168181419372559 | G Loss: 2.9045304472674616e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9360/10000 | D Loss: 8.120420455932617 | G Loss: 8.246669267464313e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9361/10000 | D Loss: 8.112553596496582 | G Loss: 3.671908643809729e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9362/10000 | D Loss: 8.304046630859375 | G Loss: 5.748957505602448e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9363/10000 | D Loss: 8.138727188110352 | G Loss: 4.4784388819607557e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9364/10000 | D Loss: 8.126556396484375 | G Loss: 5.312713255989365e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9365/10000 | D Loss: 8.063666343688965 | G Loss: 5.841253596372553e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9366/10000 | D Loss: 8.148285865783691 | G Loss: 4.913771363135311e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9367/10000 | D Loss: 8.242012977600098 | G Loss: 4.1078430967900204e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9368/10000 | D Loss: 8.095602035522461 | G Loss: 4.869319809586159e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9369/10000 | D Loss: 8.059735298156738 | G Loss: 3.825621774922183e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9370/10000 | D Loss: 8.158209800720215 | G Loss: 5.201979433877568e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9371/10000 | D Loss: 8.190031051635742 | G Loss: 3.8662122392452147e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9372/10000 | D Loss: 8.219284057617188 | G Loss: 3.376355266482278e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9373/10000 | D Loss: 8.12484359741211 | G Loss: 3.4732346421151306e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9374/10000 | D Loss: 8.25027084350586 | G Loss: 6.217712780198781e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9375/10000 | D Loss: 8.182695388793945 | G Loss: 2.599866775199189e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9376/10000 | D Loss: 8.219882011413574 | G Loss: 1.1849157317556092e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9377/10000 | D Loss: 8.13957691192627 | G Loss: 3.232117933293921e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9378/10000 | D Loss: 8.135478019714355 | G Loss: 4.932543333779904e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9379/10000 | D Loss: 8.264631271362305 | G Loss: 3.6188896501698764e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9380/10000 | D Loss: 8.172622680664062 | G Loss: 4.380929112812737e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9381/10000 | D Loss: 8.275611877441406 | G Loss: 3.8640561683678243e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9382/10000 | D Loss: 8.217718124389648 | G Loss: 5.576392823058995e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9383/10000 | D Loss: 8.239645004272461 | G Loss: 3.0001083928254957e-07\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9384/10000 | D Loss: 8.302752494812012 | G Loss: 3.1712153258922626e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9385/10000 | D Loss: 8.391024589538574 | G Loss: 3.3681789091133396e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9386/10000 | D Loss: 8.13474178314209 | G Loss: 8.368593853447237e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 9387/10000 | D Loss: 8.113885879516602 | G Loss: 5.228787358646514e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9388/10000 | D Loss: 8.18523120880127 | G Loss: 4.47890471377832e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9389/10000 | D Loss: 8.183980941772461 | G Loss: 6.465110118369921e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9390/10000 | D Loss: 8.273946762084961 | G Loss: 4.652141001315613e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9391/10000 | D Loss: 8.175575256347656 | G Loss: 6.13167117080593e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9392/10000 | D Loss: 8.244078636169434 | G Loss: 4.8565289034741e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9393/10000 | D Loss: 8.19321060180664 | G Loss: 5.172597639102605e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9394/10000 | D Loss: 8.137985229492188 | G Loss: 7.598194429192517e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9395/10000 | D Loss: 8.227777481079102 | G Loss: 5.539067728932423e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9396/10000 | D Loss: 8.281462669372559 | G Loss: 4.528975239281863e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9397/10000 | D Loss: 8.137242317199707 | G Loss: 4.299428439935582e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9398/10000 | D Loss: 8.096357345581055 | G Loss: 4.2990316728719336e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9399/10000 | D Loss: 8.14073371887207 | G Loss: 3.9831894582675886e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9400/10000 | D Loss: 8.155003547668457 | G Loss: 5.294320430948574e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9401/10000 | D Loss: 8.179859161376953 | G Loss: 4.0639281451149145e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9402/10000 | D Loss: 8.126188278198242 | G Loss: 3.826158945230418e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9403/10000 | D Loss: 8.311656951904297 | G Loss: 3.8336500551849895e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9404/10000 | D Loss: 8.20194149017334 | G Loss: 7.757277558084752e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9405/10000 | D Loss: 8.104476928710938 | G Loss: 4.097485373222298e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9406/10000 | D Loss: 8.191997528076172 | G Loss: 4.345199897670682e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9407/10000 | D Loss: 8.123842239379883 | G Loss: 3.3580886338313576e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9408/10000 | D Loss: 8.164411544799805 | G Loss: 4.0450299820804503e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9409/10000 | D Loss: 8.293062210083008 | G Loss: 3.7090140381224046e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9410/10000 | D Loss: 8.239570617675781 | G Loss: 4.4901975115863024e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9411/10000 | D Loss: 8.050891876220703 | G Loss: 5.420313868853555e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9412/10000 | D Loss: 8.075275421142578 | G Loss: 5.215837290961645e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9413/10000 | D Loss: 8.026387214660645 | G Loss: 3.718362222571159e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9414/10000 | D Loss: 8.268326759338379 | G Loss: 4.054076612192148e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9415/10000 | D Loss: 8.186319351196289 | G Loss: 3.6815617932006717e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9416/10000 | D Loss: 8.242166519165039 | G Loss: 3.842455384983623e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9417/10000 | D Loss: 8.28389835357666 | G Loss: 3.860487538531743e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9418/10000 | D Loss: 8.250478744506836 | G Loss: 4.120195171708474e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9419/10000 | D Loss: 8.20319938659668 | G Loss: 5.185945042285312e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9420/10000 | D Loss: 8.181131362915039 | G Loss: 4.5843870566386613e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9421/10000 | D Loss: 8.366655349731445 | G Loss: 4.566384177451255e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9422/10000 | D Loss: 8.160825729370117 | G Loss: 7.81413746153703e-07\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 9423/10000 | D Loss: 8.146394729614258 | G Loss: 2.633514100125467e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9424/10000 | D Loss: 8.147418975830078 | G Loss: 5.23136577612604e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9425/10000 | D Loss: 8.479400634765625 | G Loss: 4.1893616753441165e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9426/10000 | D Loss: 8.031477928161621 | G Loss: 4.4223915551810933e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9427/10000 | D Loss: 8.179670333862305 | G Loss: 3.240129160531069e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9428/10000 | D Loss: 8.13906478881836 | G Loss: 3.637053396232659e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9429/10000 | D Loss: 8.33724594116211 | G Loss: 3.200786977686221e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9430/10000 | D Loss: 8.301828384399414 | G Loss: 6.150755780254258e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9431/10000 | D Loss: 8.201970100402832 | G Loss: 3.9058971879057935e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9432/10000 | D Loss: 8.263862609863281 | G Loss: 3.949260189983761e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9433/10000 | D Loss: 8.221267700195312 | G Loss: 4.6708152012797655e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9434/10000 | D Loss: 8.308673858642578 | G Loss: 5.896293941987096e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9435/10000 | D Loss: 8.243999481201172 | G Loss: 2.3509630864282371e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9436/10000 | D Loss: 8.26207160949707 | G Loss: 6.449272405006923e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9437/10000 | D Loss: 8.196659088134766 | G Loss: 6.960300993341662e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9438/10000 | D Loss: 8.229379653930664 | G Loss: 6.599894959435915e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9439/10000 | D Loss: 8.245922088623047 | G Loss: 3.8383950595743954e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9440/10000 | D Loss: 8.203958511352539 | G Loss: 3.0340592616084905e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9441/10000 | D Loss: 8.268388748168945 | G Loss: 3.4136314752686303e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9442/10000 | D Loss: 8.234136581420898 | G Loss: 3.072893264288723e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9443/10000 | D Loss: 8.172890663146973 | G Loss: 4.4113545527579845e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9444/10000 | D Loss: 8.0255708694458 | G Loss: 5.132029059495835e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9445/10000 | D Loss: 8.259664535522461 | G Loss: 4.238286805957614e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9446/10000 | D Loss: 8.08029842376709 | G Loss: 5.795646416117961e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9447/10000 | D Loss: 8.198461532592773 | G Loss: 3.936829386930185e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9448/10000 | D Loss: 8.247930526733398 | G Loss: 5.169707719687722e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9449/10000 | D Loss: 8.137837409973145 | G Loss: 3.416514005039062e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9450/10000 | D Loss: 8.067110061645508 | G Loss: 3.394159477920766e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9451/10000 | D Loss: 8.155929565429688 | G Loss: 3.614221668613027e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9452/10000 | D Loss: 8.111990928649902 | G Loss: 3.1342906936515647e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9453/10000 | D Loss: 8.119091033935547 | G Loss: 4.7636942213102884e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9454/10000 | D Loss: 8.426652908325195 | G Loss: 5.297746952237503e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9455/10000 | D Loss: 8.278108596801758 | G Loss: 4.327718556851323e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9456/10000 | D Loss: 8.235990524291992 | G Loss: 4.4935973164683674e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 9457/10000 | D Loss: 8.179704666137695 | G Loss: 4.950916263624094e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9458/10000 | D Loss: 8.293173789978027 | G Loss: 2.960251777039957e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9459/10000 | D Loss: 8.145708084106445 | G Loss: 6.671484129583405e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9460/10000 | D Loss: 8.177946090698242 | G Loss: 3.070524314807699e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9461/10000 | D Loss: 8.323258399963379 | G Loss: 2.8034818910782633e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9462/10000 | D Loss: 8.18209457397461 | G Loss: 3.7148373621676e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9463/10000 | D Loss: 8.269365310668945 | G Loss: 5.869779897693661e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9464/10000 | D Loss: 8.054900169372559 | G Loss: 2.850042051250057e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9465/10000 | D Loss: 8.15359115600586 | G Loss: 1.2215676861160318e-06\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9466/10000 | D Loss: 8.273195266723633 | G Loss: 6.384017297023092e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9467/10000 | D Loss: 8.206605911254883 | G Loss: 3.8727034734620247e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9468/10000 | D Loss: 8.313154220581055 | G Loss: 3.878543566315784e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9469/10000 | D Loss: 8.27139663696289 | G Loss: 4.4540180965668696e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9470/10000 | D Loss: 8.103264808654785 | G Loss: 3.658470859591034e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9471/10000 | D Loss: 8.223855018615723 | G Loss: 4.313361614549649e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9472/10000 | D Loss: 8.171812057495117 | G Loss: 7.687629590691358e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9473/10000 | D Loss: 8.140689849853516 | G Loss: 6.514042070193682e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9474/10000 | D Loss: 8.181544303894043 | G Loss: 3.945988282794133e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9475/10000 | D Loss: 8.213485717773438 | G Loss: 4.54559341278582e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9476/10000 | D Loss: 8.190940856933594 | G Loss: 3.5418378274698625e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9477/10000 | D Loss: 8.157636642456055 | G Loss: 4.050248776366061e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9478/10000 | D Loss: 8.142902374267578 | G Loss: 4.3477936628733005e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9479/10000 | D Loss: 7.972508907318115 | G Loss: 5.077429250377463e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9480/10000 | D Loss: 8.246662139892578 | G Loss: 4.34479431987711e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9481/10000 | D Loss: 8.346656799316406 | G Loss: 3.724221073753142e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9482/10000 | D Loss: 8.310588836669922 | G Loss: 4.592765208144556e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9483/10000 | D Loss: 8.21480941772461 | G Loss: 3.2962151408355567e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9484/10000 | D Loss: 8.174574851989746 | G Loss: 5.588537987932796e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9485/10000 | D Loss: 8.133541107177734 | G Loss: 4.120491325920739e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9486/10000 | D Loss: 8.085837364196777 | G Loss: 3.17687238293729e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9487/10000 | D Loss: 8.141170501708984 | G Loss: 3.639365218077728e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9488/10000 | D Loss: 8.212050437927246 | G Loss: 3.120537144241098e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9489/10000 | D Loss: 8.131434440612793 | G Loss: 4.226007206398208e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9490/10000 | D Loss: 8.244714736938477 | G Loss: 3.690860523875017e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9491/10000 | D Loss: 8.310022354125977 | G Loss: 3.0373732329280756e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9492/10000 | D Loss: 8.162355422973633 | G Loss: 3.525946681293135e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9493/10000 | D Loss: 8.1683988571167 | G Loss: 5.214220664129243e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9494/10000 | D Loss: 8.104071617126465 | G Loss: 3.1390317190016503e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9495/10000 | D Loss: 8.268732070922852 | G Loss: 5.026163307775278e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9496/10000 | D Loss: 8.27285099029541 | G Loss: 6.211614618223393e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9497/10000 | D Loss: 8.103371620178223 | G Loss: 3.1115280307858484e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9498/10000 | D Loss: 8.115508079528809 | G Loss: 3.618923756221193e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9499/10000 | D Loss: 8.423758506774902 | G Loss: 3.096996010754083e-07\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "Epoch 9500/10000 | D Loss: 8.337326049804688 | G Loss: 2.90156009441489e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9501/10000 | D Loss: 8.236818313598633 | G Loss: 3.7098814686942205e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9502/10000 | D Loss: 8.190399169921875 | G Loss: 4.298126441426575e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9503/10000 | D Loss: 8.2975492477417 | G Loss: 4.5304724949346564e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9504/10000 | D Loss: 8.234193801879883 | G Loss: 5.377722800403717e-07\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "Epoch 9505/10000 | D Loss: 8.20211410522461 | G Loss: 3.631149070315587e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9506/10000 | D Loss: 8.43764591217041 | G Loss: 3.294773023299058e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9507/10000 | D Loss: 8.289002418518066 | G Loss: 3.862909920826496e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9508/10000 | D Loss: 8.0940580368042 | G Loss: 4.7441653805435635e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9509/10000 | D Loss: 8.322757720947266 | G Loss: 6.119994395703543e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9510/10000 | D Loss: 8.286016464233398 | G Loss: 4.579912911140127e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9511/10000 | D Loss: 8.195991516113281 | G Loss: 2.969485706216801e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9512/10000 | D Loss: 8.148577690124512 | G Loss: 5.824744562232809e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9513/10000 | D Loss: 8.18501091003418 | G Loss: 5.573836006078636e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9514/10000 | D Loss: 8.32357406616211 | G Loss: 4.133810591611109e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9515/10000 | D Loss: 8.151443481445312 | G Loss: 4.7068471076272544e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9516/10000 | D Loss: 8.201057434082031 | G Loss: 3.872868035159627e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9517/10000 | D Loss: 8.235906600952148 | G Loss: 6.870189963592566e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9518/10000 | D Loss: 8.15185546875 | G Loss: 5.120716650708346e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9519/10000 | D Loss: 8.194936752319336 | G Loss: 3.842464764147735e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9520/10000 | D Loss: 8.278326034545898 | G Loss: 5.228947657087701e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9521/10000 | D Loss: 8.251864433288574 | G Loss: 4.5432634010467154e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9522/10000 | D Loss: 8.278423309326172 | G Loss: 5.387007604440441e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9523/10000 | D Loss: 8.246406555175781 | G Loss: 3.31589376401098e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9524/10000 | D Loss: 8.302391052246094 | G Loss: 3.1498177577304887e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9525/10000 | D Loss: 8.268199920654297 | G Loss: 6.289529892455903e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9526/10000 | D Loss: 8.294892311096191 | G Loss: 4.769547103933292e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9527/10000 | D Loss: 8.135952949523926 | G Loss: 1.1537204045453109e-06\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9528/10000 | D Loss: 8.105506896972656 | G Loss: 2.428872107884672e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9529/10000 | D Loss: 8.190727233886719 | G Loss: 3.4198097864646115e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9530/10000 | D Loss: 8.34115982055664 | G Loss: 4.276602396657836e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9531/10000 | D Loss: 8.114686965942383 | G Loss: 4.506741220211552e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9532/10000 | D Loss: 8.369300842285156 | G Loss: 2.561039025295031e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9533/10000 | D Loss: 8.108301162719727 | G Loss: 6.505206329165958e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9534/10000 | D Loss: 8.238654136657715 | G Loss: 5.954699986432388e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9535/10000 | D Loss: 8.228946685791016 | G Loss: 4.057358751197171e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9536/10000 | D Loss: 8.194952011108398 | G Loss: 3.2172056307899766e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9537/10000 | D Loss: 8.171492576599121 | G Loss: 4.625571250471694e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9538/10000 | D Loss: 8.396854400634766 | G Loss: 5.976226020720787e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9539/10000 | D Loss: 8.241933822631836 | G Loss: 3.859104253933765e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9540/10000 | D Loss: 8.176604270935059 | G Loss: 2.6518023332755547e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9541/10000 | D Loss: 8.171908378601074 | G Loss: 4.4534880316859926e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9542/10000 | D Loss: 8.298494338989258 | G Loss: 3.5066761938651325e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9543/10000 | D Loss: 8.276318550109863 | G Loss: 6.773933591830428e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9544/10000 | D Loss: 8.220134735107422 | G Loss: 5.038192512074602e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9545/10000 | D Loss: 8.190260887145996 | G Loss: 3.398417334210535e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9546/10000 | D Loss: 8.210226058959961 | G Loss: 6.133903980298783e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9547/10000 | D Loss: 8.342876434326172 | G Loss: 3.551692202563572e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9548/10000 | D Loss: 8.42991828918457 | G Loss: 4.840308633902168e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9549/10000 | D Loss: 8.127614974975586 | G Loss: 5.048342472946388e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9550/10000 | D Loss: 8.207653999328613 | G Loss: 3.617769550601224e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9551/10000 | D Loss: 8.276721954345703 | G Loss: 3.64754640713727e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9552/10000 | D Loss: 8.287353515625 | G Loss: 4.3145388417542563e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9553/10000 | D Loss: 8.254997253417969 | G Loss: 4.937131734550348e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9554/10000 | D Loss: 8.344229698181152 | G Loss: 4.7938669922587e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9555/10000 | D Loss: 8.188521385192871 | G Loss: 3.7250288187351543e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9556/10000 | D Loss: 8.205268859863281 | G Loss: 3.160068899887847e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9557/10000 | D Loss: 8.128158569335938 | G Loss: 5.563441618505749e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9558/10000 | D Loss: 8.275069236755371 | G Loss: 3.8636767385469284e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9559/10000 | D Loss: 8.225693702697754 | G Loss: 3.670214709927677e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9560/10000 | D Loss: 8.176068305969238 | G Loss: 3.976276730099926e-07\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "Epoch 9561/10000 | D Loss: 8.347299575805664 | G Loss: 3.50112117075696e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9562/10000 | D Loss: 8.192020416259766 | G Loss: 2.8604040380741935e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9563/10000 | D Loss: 8.399862289428711 | G Loss: 3.609315228914056e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9564/10000 | D Loss: 8.120610237121582 | G Loss: 4.4835780954599613e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9565/10000 | D Loss: 8.15575885772705 | G Loss: 4.070949728429696e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9566/10000 | D Loss: 8.264540672302246 | G Loss: 2.1965848873151117e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9567/10000 | D Loss: 8.394247055053711 | G Loss: 5.380837819757289e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9568/10000 | D Loss: 8.218902587890625 | G Loss: 3.069719696213724e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9569/10000 | D Loss: 8.336669921875 | G Loss: 5.799616928925388e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9570/10000 | D Loss: 8.275794982910156 | G Loss: 3.9262386053451337e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9571/10000 | D Loss: 8.301387786865234 | G Loss: 4.5745082388748415e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9572/10000 | D Loss: 8.295775413513184 | G Loss: 3.7993055457263836e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9573/10000 | D Loss: 8.164024353027344 | G Loss: 6.376237138283614e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9574/10000 | D Loss: 8.384885787963867 | G Loss: 3.8097874721643166e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9575/10000 | D Loss: 8.283866882324219 | G Loss: 2.976700557155709e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9576/10000 | D Loss: 8.201789855957031 | G Loss: 6.913658125995426e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9577/10000 | D Loss: 8.131677627563477 | G Loss: 5.034940500081575e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9578/10000 | D Loss: 8.254291534423828 | G Loss: 3.3035587421181845e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9579/10000 | D Loss: 8.229798316955566 | G Loss: 4.6152683808031725e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9580/10000 | D Loss: 8.213997840881348 | G Loss: 3.229166622986668e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9581/10000 | D Loss: 8.298356056213379 | G Loss: 4.759146179367235e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9582/10000 | D Loss: 8.243837356567383 | G Loss: 8.206694701584638e-07\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 9583/10000 | D Loss: 8.209734916687012 | G Loss: 4.4005594190821284e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9584/10000 | D Loss: 8.273536682128906 | G Loss: 3.3710466595948674e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9585/10000 | D Loss: 8.059497833251953 | G Loss: 4.273934450793604e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9586/10000 | D Loss: 8.214609146118164 | G Loss: 3.248956659263058e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9587/10000 | D Loss: 8.275516510009766 | G Loss: 4.6070832127043104e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9588/10000 | D Loss: 8.179950714111328 | G Loss: 3.729058448698197e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9589/10000 | D Loss: 8.35704231262207 | G Loss: 2.510143986000912e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9590/10000 | D Loss: 8.342184066772461 | G Loss: 4.1703825104377756e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9591/10000 | D Loss: 8.217936515808105 | G Loss: 3.3308268143628084e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9592/10000 | D Loss: 8.324132919311523 | G Loss: 4.1253343852076796e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9593/10000 | D Loss: 8.235150337219238 | G Loss: 3.587469734611659e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9594/10000 | D Loss: 8.205249786376953 | G Loss: 4.6984050072751415e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9595/10000 | D Loss: 8.143616676330566 | G Loss: 4.9704510729498e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9596/10000 | D Loss: 8.128583908081055 | G Loss: 3.37731421495846e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9597/10000 | D Loss: 8.319666862487793 | G Loss: 4.189678293187171e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9598/10000 | D Loss: 8.225457191467285 | G Loss: 4.496748999827105e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9599/10000 | D Loss: 8.267282485961914 | G Loss: 5.410777248471277e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9600/10000 | D Loss: 8.475887298583984 | G Loss: 2.4869314074749127e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9601/10000 | D Loss: 8.197944641113281 | G Loss: 4.980918220098829e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9602/10000 | D Loss: 8.225297927856445 | G Loss: 4.230044510222797e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9603/10000 | D Loss: 8.486705780029297 | G Loss: 3.0902288017387036e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9604/10000 | D Loss: 8.143095016479492 | G Loss: 7.143347602323047e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9605/10000 | D Loss: 8.15438461303711 | G Loss: 1.9938471496061538e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9606/10000 | D Loss: 8.230554580688477 | G Loss: 5.248139132163487e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9607/10000 | D Loss: 8.28502082824707 | G Loss: 3.602158926696575e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9608/10000 | D Loss: 8.340169906616211 | G Loss: 4.558853561320575e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9609/10000 | D Loss: 8.336830139160156 | G Loss: 3.499172009924223e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9610/10000 | D Loss: 8.320551872253418 | G Loss: 2.842707829131541e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9611/10000 | D Loss: 8.28969955444336 | G Loss: 4.025166333576635e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9612/10000 | D Loss: 8.335284233093262 | G Loss: 4.723544861917617e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9613/10000 | D Loss: 8.189035415649414 | G Loss: 3.9075328572835133e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9614/10000 | D Loss: 8.275079727172852 | G Loss: 3.921456652733468e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9615/10000 | D Loss: 8.387304306030273 | G Loss: 4.0010235125009785e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9616/10000 | D Loss: 8.352311134338379 | G Loss: 2.810635635341896e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9617/10000 | D Loss: 8.142637252807617 | G Loss: 3.7305537148313306e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9618/10000 | D Loss: 8.162520408630371 | G Loss: 4.182192299140297e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9619/10000 | D Loss: 8.189355850219727 | G Loss: 3.763831273317919e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9620/10000 | D Loss: 8.284394264221191 | G Loss: 3.462892550487595e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9621/10000 | D Loss: 8.27294921875 | G Loss: 3.6641171163864783e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9622/10000 | D Loss: 8.145652770996094 | G Loss: 6.424459684239991e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9623/10000 | D Loss: 8.161689758300781 | G Loss: 4.2083510720658523e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9624/10000 | D Loss: 8.360330581665039 | G Loss: 8.477965138808941e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9625/10000 | D Loss: 8.412088394165039 | G Loss: 3.899941134477558e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9626/10000 | D Loss: 8.327333450317383 | G Loss: 3.584931675959524e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9627/10000 | D Loss: 8.340055465698242 | G Loss: 5.77978539695323e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9628/10000 | D Loss: 8.303245544433594 | G Loss: 5.370600320020458e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9629/10000 | D Loss: 8.429237365722656 | G Loss: 3.5257826880297216e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9630/10000 | D Loss: 8.43870735168457 | G Loss: 2.6816888976100017e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9631/10000 | D Loss: 8.325115203857422 | G Loss: 3.1396319855048205e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9632/10000 | D Loss: 8.249032974243164 | G Loss: 4.0821652191880275e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9633/10000 | D Loss: 8.326711654663086 | G Loss: 4.714492263246939e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9634/10000 | D Loss: 8.249290466308594 | G Loss: 5.109662879476673e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9635/10000 | D Loss: 8.464603424072266 | G Loss: 3.455656951700803e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9636/10000 | D Loss: 8.287574768066406 | G Loss: 3.143654225823411e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9637/10000 | D Loss: 8.448028564453125 | G Loss: 5.336870003702643e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9638/10000 | D Loss: 8.217789649963379 | G Loss: 4.0035325810094946e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9639/10000 | D Loss: 8.23849868774414 | G Loss: 4.524755752299825e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9640/10000 | D Loss: 8.417155265808105 | G Loss: 3.278281042184972e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9641/10000 | D Loss: 8.222784042358398 | G Loss: 2.5321429575342336e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9642/10000 | D Loss: 8.301395416259766 | G Loss: 7.013532581368054e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9643/10000 | D Loss: 8.12690544128418 | G Loss: 3.8732247276129783e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9644/10000 | D Loss: 8.31474494934082 | G Loss: 3.5349091831449186e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9645/10000 | D Loss: 8.241622924804688 | G Loss: 8.804018989394535e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9646/10000 | D Loss: 8.33476734161377 | G Loss: 5.69811732020753e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9647/10000 | D Loss: 8.307958602905273 | G Loss: 3.7179785294938483e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9648/10000 | D Loss: 8.207086563110352 | G Loss: 3.060086442019383e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9649/10000 | D Loss: 8.222602844238281 | G Loss: 4.5832587147742743e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9650/10000 | D Loss: 8.1583251953125 | G Loss: 3.137632802463486e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9651/10000 | D Loss: 8.378745079040527 | G Loss: 4.448162655990018e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9652/10000 | D Loss: 8.26906967163086 | G Loss: 3.4397686476950184e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9653/10000 | D Loss: 8.182621002197266 | G Loss: 3.4123490877391305e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9654/10000 | D Loss: 8.268268585205078 | G Loss: 3.5572440992837073e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9655/10000 | D Loss: 8.372649192810059 | G Loss: 5.287433282319398e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9656/10000 | D Loss: 8.286158561706543 | G Loss: 4.012030103694997e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9657/10000 | D Loss: 8.386584281921387 | G Loss: 5.845725468134333e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9658/10000 | D Loss: 8.31893539428711 | G Loss: 3.603188361012144e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9659/10000 | D Loss: 8.252134323120117 | G Loss: 2.931540166173363e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9660/10000 | D Loss: 8.330278396606445 | G Loss: 3.054227875054494e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9661/10000 | D Loss: 8.227571487426758 | G Loss: 4.98255928960134e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9662/10000 | D Loss: 8.240097045898438 | G Loss: 3.563730501809914e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9663/10000 | D Loss: 8.333039283752441 | G Loss: 4.877530841440603e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9664/10000 | D Loss: 8.390350341796875 | G Loss: 3.232842686884396e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9665/10000 | D Loss: 8.278099060058594 | G Loss: 4.309429755267047e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9666/10000 | D Loss: 8.420223236083984 | G Loss: 3.339279146530316e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9667/10000 | D Loss: 8.51087760925293 | G Loss: 2.7824202675219567e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9668/10000 | D Loss: 8.284374237060547 | G Loss: 3.2189274179472704e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9669/10000 | D Loss: 8.183187484741211 | G Loss: 3.745223011719645e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9670/10000 | D Loss: 8.375592231750488 | G Loss: 4.1967922470576013e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9671/10000 | D Loss: 8.369731903076172 | G Loss: 3.5486002047946386e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9672/10000 | D Loss: 8.268531799316406 | G Loss: 3.1938148481458484e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9673/10000 | D Loss: 8.24215316772461 | G Loss: 3.449573569014319e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9674/10000 | D Loss: 8.444307327270508 | G Loss: 2.5186909624608234e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9675/10000 | D Loss: 8.257036209106445 | G Loss: 3.905974494955444e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9676/10000 | D Loss: 8.28727912902832 | G Loss: 2.438796968817769e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9677/10000 | D Loss: 8.128643035888672 | G Loss: 2.470009974331333e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9678/10000 | D Loss: 8.329950332641602 | G Loss: 3.935403753985156e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9679/10000 | D Loss: 8.31974983215332 | G Loss: 3.577296183721046e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9680/10000 | D Loss: 8.321304321289062 | G Loss: 4.218098865749198e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9681/10000 | D Loss: 8.10189151763916 | G Loss: 4.714586907539342e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9682/10000 | D Loss: 8.389913558959961 | G Loss: 3.940963040349743e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9683/10000 | D Loss: 8.209941864013672 | G Loss: 2.3716596331269102e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9684/10000 | D Loss: 8.303695678710938 | G Loss: 4.173337799784349e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9685/10000 | D Loss: 8.250337600708008 | G Loss: 3.893704842994339e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9686/10000 | D Loss: 8.31530475616455 | G Loss: 4.0327523720407044e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9687/10000 | D Loss: 8.173016548156738 | G Loss: 4.229886485518364e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9688/10000 | D Loss: 8.291610717773438 | G Loss: 2.75464685728366e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9689/10000 | D Loss: 8.35704517364502 | G Loss: 5.884219831386872e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9690/10000 | D Loss: 8.319181442260742 | G Loss: 3.3996533943536633e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9691/10000 | D Loss: 8.40579605102539 | G Loss: 3.29540114307747e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9692/10000 | D Loss: 8.231870651245117 | G Loss: 3.2526094173590536e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9693/10000 | D Loss: 8.251031875610352 | G Loss: 7.045726420074061e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9694/10000 | D Loss: 8.301002502441406 | G Loss: 3.9597119894096977e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9695/10000 | D Loss: 8.21541976928711 | G Loss: 3.893206041993835e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9696/10000 | D Loss: 8.288503646850586 | G Loss: 3.033636062355072e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9697/10000 | D Loss: 8.306435585021973 | G Loss: 4.384905594179145e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9698/10000 | D Loss: 8.204019546508789 | G Loss: 5.139436325407587e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9699/10000 | D Loss: 8.457530975341797 | G Loss: 3.6630581234931014e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9700/10000 | D Loss: 8.436397552490234 | G Loss: 4.4437939550334704e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9701/10000 | D Loss: 8.357756614685059 | G Loss: 2.7645000955089927e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9702/10000 | D Loss: 8.161548614501953 | G Loss: 3.738659017926693e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9703/10000 | D Loss: 8.23563003540039 | G Loss: 3.758999298497656e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9704/10000 | D Loss: 8.34328556060791 | G Loss: 3.104913162133016e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9705/10000 | D Loss: 8.450418472290039 | G Loss: 4.093026859663951e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9706/10000 | D Loss: 8.224306106567383 | G Loss: 2.987921448038833e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9707/10000 | D Loss: 8.260381698608398 | G Loss: 3.7540621633525006e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9708/10000 | D Loss: 8.24319839477539 | G Loss: 4.150078893871978e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9709/10000 | D Loss: 8.282363891601562 | G Loss: 2.957278866233537e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9710/10000 | D Loss: 8.282167434692383 | G Loss: 3.9231639448189526e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9711/10000 | D Loss: 8.25581169128418 | G Loss: 3.8429672599704645e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9712/10000 | D Loss: 8.400245666503906 | G Loss: 3.0939855832912144e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9713/10000 | D Loss: 8.161307334899902 | G Loss: 3.268868908889999e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9714/10000 | D Loss: 8.325811386108398 | G Loss: 5.187440592635539e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9715/10000 | D Loss: 8.16823959350586 | G Loss: 3.431361506045505e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9716/10000 | D Loss: 8.232072830200195 | G Loss: 3.544643618624832e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9717/10000 | D Loss: 8.241643905639648 | G Loss: 3.36304339043636e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9718/10000 | D Loss: 8.214449882507324 | G Loss: 4.291151753932354e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9719/10000 | D Loss: 8.223246574401855 | G Loss: 2.6822203835763503e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9720/10000 | D Loss: 8.335494995117188 | G Loss: 3.549134248714836e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9721/10000 | D Loss: 8.222661018371582 | G Loss: 3.9763747849974607e-07\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 9722/10000 | D Loss: 8.357298851013184 | G Loss: 4.918568947687163e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9723/10000 | D Loss: 8.358179092407227 | G Loss: 2.4623784611321753e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9724/10000 | D Loss: 8.352073669433594 | G Loss: 2.626559307827847e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9725/10000 | D Loss: 8.212589263916016 | G Loss: 3.958897991651611e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9726/10000 | D Loss: 8.361302375793457 | G Loss: 3.071990022363025e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9727/10000 | D Loss: 8.192508697509766 | G Loss: 5.567802077166562e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9728/10000 | D Loss: 8.460955619812012 | G Loss: 4.068258476763731e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9729/10000 | D Loss: 8.286922454833984 | G Loss: 3.5289195920995553e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9730/10000 | D Loss: 8.400278091430664 | G Loss: 3.5750821325564175e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9731/10000 | D Loss: 8.308955192565918 | G Loss: 4.063835206125077e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9732/10000 | D Loss: 8.33715534210205 | G Loss: 5.033759293837647e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9733/10000 | D Loss: 8.155084609985352 | G Loss: 5.41691406397149e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9734/10000 | D Loss: 8.53869915008545 | G Loss: 2.471156221872661e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9735/10000 | D Loss: 8.355524063110352 | G Loss: 5.032416652284155e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9736/10000 | D Loss: 8.226472854614258 | G Loss: 3.587779815461545e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9737/10000 | D Loss: 8.222333908081055 | G Loss: 4.2362006524854223e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9738/10000 | D Loss: 8.273752212524414 | G Loss: 3.603833533816214e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9739/10000 | D Loss: 8.266060829162598 | G Loss: 2.3197907239591586e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9740/10000 | D Loss: 8.19572925567627 | G Loss: 3.081584338815446e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9741/10000 | D Loss: 8.351951599121094 | G Loss: 3.988768639828777e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9742/10000 | D Loss: 8.353446960449219 | G Loss: 3.1017930268717464e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9743/10000 | D Loss: 8.369056701660156 | G Loss: 4.027579620924371e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9744/10000 | D Loss: 8.289624214172363 | G Loss: 3.7358194049375015e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9745/10000 | D Loss: 8.271269798278809 | G Loss: 4.029100466595992e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9746/10000 | D Loss: 8.275218963623047 | G Loss: 2.384336141858512e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9747/10000 | D Loss: 8.304560661315918 | G Loss: 4.2044149495268357e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9748/10000 | D Loss: 8.043298721313477 | G Loss: 3.238943975247821e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9749/10000 | D Loss: 8.384727478027344 | G Loss: 3.62224710670489e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9750/10000 | D Loss: 8.369720458984375 | G Loss: 2.9522584554797504e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9751/10000 | D Loss: 8.283255577087402 | G Loss: 7.989949040165811e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9752/10000 | D Loss: 8.094636917114258 | G Loss: 3.9901789250507136e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9753/10000 | D Loss: 8.285097122192383 | G Loss: 3.5066472037215135e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9754/10000 | D Loss: 8.333999633789062 | G Loss: 4.857648718825658e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9755/10000 | D Loss: 8.356758117675781 | G Loss: 3.7790081819366605e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9756/10000 | D Loss: 8.37920093536377 | G Loss: 3.264818246861978e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9757/10000 | D Loss: 8.205507278442383 | G Loss: 3.96867505969567e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9758/10000 | D Loss: 8.456324577331543 | G Loss: 2.7322707296661974e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9759/10000 | D Loss: 8.423892974853516 | G Loss: 3.764173470699461e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9760/10000 | D Loss: 8.168998718261719 | G Loss: 2.477172529324889e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9761/10000 | D Loss: 8.190484046936035 | G Loss: 4.0801560885483923e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9762/10000 | D Loss: 8.334060668945312 | G Loss: 3.7564916510746116e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9763/10000 | D Loss: 8.326635360717773 | G Loss: 4.1531697547725344e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9764/10000 | D Loss: 8.312828063964844 | G Loss: 4.925714165437967e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9765/10000 | D Loss: 8.29313850402832 | G Loss: 3.519404856433539e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9766/10000 | D Loss: 8.347554206848145 | G Loss: 3.084168724853953e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9767/10000 | D Loss: 8.434402465820312 | G Loss: 5.478145794768352e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9768/10000 | D Loss: 8.171721458435059 | G Loss: 5.553124537982512e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9769/10000 | D Loss: 8.296817779541016 | G Loss: 2.2676097444218613e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9770/10000 | D Loss: 8.19412612915039 | G Loss: 4.788848286807479e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9771/10000 | D Loss: 8.304021835327148 | G Loss: 3.55285692421603e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9772/10000 | D Loss: 8.339258193969727 | G Loss: 3.564009034562332e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9773/10000 | D Loss: 8.361967086791992 | G Loss: 3.4400679282953206e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9774/10000 | D Loss: 8.438070297241211 | G Loss: 5.026929557061521e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9775/10000 | D Loss: 8.381017684936523 | G Loss: 2.3756123823659436e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9776/10000 | D Loss: 8.26436996459961 | G Loss: 2.6652736551113776e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9777/10000 | D Loss: 8.36264419555664 | G Loss: 2.991794758600008e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9778/10000 | D Loss: 8.307979583740234 | G Loss: 3.5880302107216266e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9779/10000 | D Loss: 8.486091613769531 | G Loss: 3.028150956652098e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9780/10000 | D Loss: 8.34786319732666 | G Loss: 2.3778567026511155e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9781/10000 | D Loss: 8.250439643859863 | G Loss: 4.85262489746674e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9782/10000 | D Loss: 8.441276550292969 | G Loss: 4.1635126990513527e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9783/10000 | D Loss: 8.114909172058105 | G Loss: 3.0742165790798026e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9784/10000 | D Loss: 8.247020721435547 | G Loss: 4.0224267650046386e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9785/10000 | D Loss: 8.383255004882812 | G Loss: 3.971134674429777e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9786/10000 | D Loss: 8.122638702392578 | G Loss: 3.5314513979756157e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9787/10000 | D Loss: 8.108827590942383 | G Loss: 4.193366009985766e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9788/10000 | D Loss: 8.301802635192871 | G Loss: 4.40477322172228e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9789/10000 | D Loss: 8.303829193115234 | G Loss: 4.0354700558964396e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9790/10000 | D Loss: 8.450578689575195 | G Loss: 3.228085461159935e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9791/10000 | D Loss: 8.270116806030273 | G Loss: 3.617642221342976e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9792/10000 | D Loss: 8.29675579071045 | G Loss: 4.3998068122164113e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9793/10000 | D Loss: 8.253084182739258 | G Loss: 3.6577711171048577e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9794/10000 | D Loss: 8.218408584594727 | G Loss: 3.1542253964289557e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9795/10000 | D Loss: 8.455545425415039 | G Loss: 4.979128789273091e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9796/10000 | D Loss: 8.29848575592041 | G Loss: 3.3817880762399e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9797/10000 | D Loss: 8.425338745117188 | G Loss: 3.8461979556814185e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9798/10000 | D Loss: 8.271900177001953 | G Loss: 2.9849485372324125e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9799/10000 | D Loss: 8.27737808227539 | G Loss: 3.1107623499337933e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9800/10000 | D Loss: 8.140644073486328 | G Loss: 5.26110000009794e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9801/10000 | D Loss: 8.330000877380371 | G Loss: 3.042707419353974e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9802/10000 | D Loss: 8.121783256530762 | G Loss: 3.633170138073183e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9803/10000 | D Loss: 8.242814064025879 | G Loss: 2.873567552796885e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9804/10000 | D Loss: 8.50536060333252 | G Loss: 3.2848180353539647e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9805/10000 | D Loss: 8.310445785522461 | G Loss: 3.945371247482399e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9806/10000 | D Loss: 8.27835464477539 | G Loss: 3.4257550396432634e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9807/10000 | D Loss: 8.314406394958496 | G Loss: 4.0962038383440813e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9808/10000 | D Loss: 8.34416389465332 | G Loss: 5.642675660055829e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9809/10000 | D Loss: 8.423665046691895 | G Loss: 2.681493072032026e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9810/10000 | D Loss: 8.209932327270508 | G Loss: 3.4650082625375944e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9811/10000 | D Loss: 8.364212989807129 | G Loss: 3.1966419555828907e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9812/10000 | D Loss: 8.314727783203125 | G Loss: 3.7117979445611127e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9813/10000 | D Loss: 8.39941120147705 | G Loss: 3.622332087616087e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9814/10000 | D Loss: 8.3380126953125 | G Loss: 3.627964133556816e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9815/10000 | D Loss: 8.256454467773438 | G Loss: 3.915492357009498e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9816/10000 | D Loss: 8.419904708862305 | G Loss: 4.400070281462831e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9817/10000 | D Loss: 8.452363967895508 | G Loss: 5.105758305035124e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9818/10000 | D Loss: 8.412620544433594 | G Loss: 5.987456006550929e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9819/10000 | D Loss: 8.243793487548828 | G Loss: 2.9863463169022e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9820/10000 | D Loss: 8.461249351501465 | G Loss: 4.6724969138267625e-07\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "Epoch 9821/10000 | D Loss: 8.388152122497559 | G Loss: 5.522115316125564e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9822/10000 | D Loss: 8.309130668640137 | G Loss: 1.7981739119932172e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9823/10000 | D Loss: 8.321809768676758 | G Loss: 3.1480124107474694e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9824/10000 | D Loss: 8.204421997070312 | G Loss: 3.679993483274302e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9825/10000 | D Loss: 8.401322364807129 | G Loss: 2.9246621124912053e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9826/10000 | D Loss: 8.266624450683594 | G Loss: 3.53220315219005e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9827/10000 | D Loss: 8.10493278503418 | G Loss: 3.1656688292969193e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9828/10000 | D Loss: 8.272470474243164 | G Loss: 3.558658363544964e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9829/10000 | D Loss: 8.351716995239258 | G Loss: 3.2467556820847676e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9830/10000 | D Loss: 8.23281478881836 | G Loss: 3.2451561082780245e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9831/10000 | D Loss: 8.241657257080078 | G Loss: 2.8271495011722436e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9832/10000 | D Loss: 8.314094543457031 | G Loss: 5.606717081718671e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9833/10000 | D Loss: 8.332822799682617 | G Loss: 4.2417403278705024e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9834/10000 | D Loss: 8.305510520935059 | G Loss: 4.1113560200756183e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9835/10000 | D Loss: 8.293964385986328 | G Loss: 2.690329381493939e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9836/10000 | D Loss: 8.353739738464355 | G Loss: 4.64525271581806e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9837/10000 | D Loss: 8.269159317016602 | G Loss: 3.0448956067630206e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9838/10000 | D Loss: 8.290426254272461 | G Loss: 3.646960635705909e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9839/10000 | D Loss: 8.1837797164917 | G Loss: 3.2356575729863835e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9840/10000 | D Loss: 8.21339225769043 | G Loss: 5.628625103781815e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9841/10000 | D Loss: 8.478569030761719 | G Loss: 3.090646032433142e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9842/10000 | D Loss: 8.186763763427734 | G Loss: 3.1955724466570246e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9843/10000 | D Loss: 8.401512145996094 | G Loss: 2.3456323106074706e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9844/10000 | D Loss: 8.209312438964844 | G Loss: 5.368498250390985e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9845/10000 | D Loss: 8.35791015625 | G Loss: 3.059357140955399e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9846/10000 | D Loss: 8.256875038146973 | G Loss: 3.721262373801437e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9847/10000 | D Loss: 8.300002098083496 | G Loss: 2.51236656367837e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9848/10000 | D Loss: 8.329540252685547 | G Loss: 2.5960852667594736e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9849/10000 | D Loss: 8.257234573364258 | G Loss: 2.612807179502852e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9850/10000 | D Loss: 8.393683433532715 | G Loss: 2.8067643143003806e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9851/10000 | D Loss: 8.52585220336914 | G Loss: 2.118214297297527e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9852/10000 | D Loss: 8.358064651489258 | G Loss: 3.7576825206997455e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9853/10000 | D Loss: 8.429491996765137 | G Loss: 2.77930297443163e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9854/10000 | D Loss: 8.204507827758789 | G Loss: 3.47938510003587e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9855/10000 | D Loss: 8.307374000549316 | G Loss: 4.383825000786601e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9856/10000 | D Loss: 8.364105224609375 | G Loss: 2.872664595088281e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9857/10000 | D Loss: 8.279492378234863 | G Loss: 3.466111024863494e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9858/10000 | D Loss: 8.304890632629395 | G Loss: 5.301654368849995e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9859/10000 | D Loss: 8.223800659179688 | G Loss: 4.3350542000553105e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9860/10000 | D Loss: 8.186237335205078 | G Loss: 4.3095798218928394e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9861/10000 | D Loss: 8.324206352233887 | G Loss: 2.5276435167143063e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9862/10000 | D Loss: 8.223152160644531 | G Loss: 5.649559398079873e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9863/10000 | D Loss: 8.453369140625 | G Loss: 4.2596008142936626e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9864/10000 | D Loss: 8.259794235229492 | G Loss: 3.229360459044983e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9865/10000 | D Loss: 8.39651870727539 | G Loss: 2.5143498305624234e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9866/10000 | D Loss: 8.329483032226562 | G Loss: 3.3220220529983635e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9867/10000 | D Loss: 8.435785293579102 | G Loss: 3.725503461282642e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9868/10000 | D Loss: 8.39000415802002 | G Loss: 3.928074079340149e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9869/10000 | D Loss: 8.397867202758789 | G Loss: 4.391332595332642e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9870/10000 | D Loss: 8.26902961730957 | G Loss: 3.3078214300985564e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9871/10000 | D Loss: 8.299237251281738 | G Loss: 5.46073749774223e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9872/10000 | D Loss: 8.38757610321045 | G Loss: 3.5410738519203733e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9873/10000 | D Loss: 8.432586669921875 | G Loss: 2.6106866357622494e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9874/10000 | D Loss: 8.331336975097656 | G Loss: 4.10123362826198e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9875/10000 | D Loss: 8.251948356628418 | G Loss: 5.344510327631724e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9876/10000 | D Loss: 8.309087753295898 | G Loss: 4.576865535454999e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9877/10000 | D Loss: 8.336362838745117 | G Loss: 4.395269854740036e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9878/10000 | D Loss: 8.18454360961914 | G Loss: 3.935876691230078e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9879/10000 | D Loss: 8.296137809753418 | G Loss: 2.2328195825593866e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9880/10000 | D Loss: 8.252767562866211 | G Loss: 2.5915664991771337e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9881/10000 | D Loss: 8.387775421142578 | G Loss: 3.703898414642026e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9882/10000 | D Loss: 8.315576553344727 | G Loss: 4.0646284560352797e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9883/10000 | D Loss: 8.28700065612793 | G Loss: 6.416835276468191e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9884/10000 | D Loss: 8.231958389282227 | G Loss: 2.0822123758534872e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9885/10000 | D Loss: 8.283695220947266 | G Loss: 2.9792323630317696e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9886/10000 | D Loss: 8.194280624389648 | G Loss: 3.9777907545612834e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9887/10000 | D Loss: 8.294301986694336 | G Loss: 4.6745543613724294e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9888/10000 | D Loss: 8.353240966796875 | G Loss: 2.361954329899163e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9889/10000 | D Loss: 8.417015075683594 | G Loss: 3.068354885726876e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9890/10000 | D Loss: 8.262958526611328 | G Loss: 3.5976023582406924e-07\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch 9891/10000 | D Loss: 8.416241645812988 | G Loss: 3.2521035109311924e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9892/10000 | D Loss: 8.129318237304688 | G Loss: 2.920191377597803e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9893/10000 | D Loss: 8.293316841125488 | G Loss: 5.366916298044089e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9894/10000 | D Loss: 8.34324836730957 | G Loss: 3.279809561718139e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9895/10000 | D Loss: 8.363805770874023 | G Loss: 5.329284249455668e-07\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "Epoch 9896/10000 | D Loss: 8.218511581420898 | G Loss: 3.917563162758597e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9897/10000 | D Loss: 8.349447250366211 | G Loss: 5.322717129274679e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9898/10000 | D Loss: 8.329793930053711 | G Loss: 3.0181237775650516e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9899/10000 | D Loss: 8.198065757751465 | G Loss: 3.5254674912721384e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9900/10000 | D Loss: 8.375469207763672 | G Loss: 3.2490217449776537e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9901/10000 | D Loss: 8.413442611694336 | G Loss: 3.1564641744807886e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9902/10000 | D Loss: 8.187398910522461 | G Loss: 4.2516467146924697e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9903/10000 | D Loss: 8.297690391540527 | G Loss: 3.734532754151587e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9904/10000 | D Loss: 8.368206977844238 | G Loss: 3.9958027286957076e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9905/10000 | D Loss: 8.367576599121094 | G Loss: 3.075625443216268e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9906/10000 | D Loss: 8.512067794799805 | G Loss: 4.48023399712838e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9907/10000 | D Loss: 8.382848739624023 | G Loss: 3.470149181339366e-07\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "Epoch 9908/10000 | D Loss: 8.295976638793945 | G Loss: 2.984964169172599e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9909/10000 | D Loss: 8.321149826049805 | G Loss: 4.829375939152669e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9910/10000 | D Loss: 8.33722972869873 | G Loss: 2.742092419794062e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9911/10000 | D Loss: 8.17109203338623 | G Loss: 4.090791776434344e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9912/10000 | D Loss: 8.270244598388672 | G Loss: 2.8194671131132054e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9913/10000 | D Loss: 8.224217414855957 | G Loss: 2.526381308598502e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9914/10000 | D Loss: 8.434259414672852 | G Loss: 5.49222363588342e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9915/10000 | D Loss: 8.318460464477539 | G Loss: 2.874386382245575e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9916/10000 | D Loss: 8.425841331481934 | G Loss: 4.2580600734254404e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9917/10000 | D Loss: 8.108022689819336 | G Loss: 3.0132673600746784e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9918/10000 | D Loss: 8.475747108459473 | G Loss: 2.400483936071396e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9919/10000 | D Loss: 8.54283618927002 | G Loss: 5.933023885518196e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9920/10000 | D Loss: 8.465675354003906 | G Loss: 4.2690626855801383e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 9921/10000 | D Loss: 8.460244178771973 | G Loss: 3.040830733880284e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9922/10000 | D Loss: 8.474563598632812 | G Loss: 3.3228334928026015e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9923/10000 | D Loss: 8.394861221313477 | G Loss: 2.621535770686023e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9924/10000 | D Loss: 8.354854583740234 | G Loss: 4.900337557955936e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9925/10000 | D Loss: 8.455361366271973 | G Loss: 3.986393437571678e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9926/10000 | D Loss: 8.405158996582031 | G Loss: 3.7223674098640913e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9927/10000 | D Loss: 8.287433624267578 | G Loss: 3.776013386413979e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9928/10000 | D Loss: 8.484769821166992 | G Loss: 5.111572818350396e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9929/10000 | D Loss: 8.475452423095703 | G Loss: 2.477622160768078e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9930/10000 | D Loss: 8.344615936279297 | G Loss: 2.207129625730886e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9931/10000 | D Loss: 8.32087516784668 | G Loss: 3.8693715964654984e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9932/10000 | D Loss: 8.422405242919922 | G Loss: 2.755546972821321e-07\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 9933/10000 | D Loss: 8.51247787475586 | G Loss: 2.567421120147628e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9934/10000 | D Loss: 8.35779094696045 | G Loss: 3.47366778896685e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9935/10000 | D Loss: 8.372693061828613 | G Loss: 2.9173259008530295e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9936/10000 | D Loss: 8.153189659118652 | G Loss: 2.4498677930751e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9937/10000 | D Loss: 8.381170272827148 | G Loss: 4.1253372273786226e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9938/10000 | D Loss: 8.41161823272705 | G Loss: 3.946831554912933e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9939/10000 | D Loss: 8.429304122924805 | G Loss: 7.677425060137466e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9940/10000 | D Loss: 8.437030792236328 | G Loss: 3.8680047964589903e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9941/10000 | D Loss: 8.311365127563477 | G Loss: 3.8515881328748947e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9942/10000 | D Loss: 8.453310012817383 | G Loss: 4.5231382728161407e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9943/10000 | D Loss: 8.403132438659668 | G Loss: 3.8335377894327394e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9944/10000 | D Loss: 8.178359985351562 | G Loss: 2.932899292318325e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9945/10000 | D Loss: 8.14246940612793 | G Loss: 3.0219601399039675e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9946/10000 | D Loss: 8.494989395141602 | G Loss: 2.1213263323716092e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9947/10000 | D Loss: 8.312394142150879 | G Loss: 3.453987460488861e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9948/10000 | D Loss: 8.402067184448242 | G Loss: 2.993013481500384e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9949/10000 | D Loss: 8.426630020141602 | G Loss: 2.7124463031213963e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9950/10000 | D Loss: 8.238831520080566 | G Loss: 2.597702746243158e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9951/10000 | D Loss: 8.42065715789795 | G Loss: 3.156843035867496e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9952/10000 | D Loss: 8.437919616699219 | G Loss: 3.042815137632715e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9953/10000 | D Loss: 8.418669700622559 | G Loss: 2.60467288626387e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9954/10000 | D Loss: 8.57589340209961 | G Loss: 3.142124569421867e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9955/10000 | D Loss: 8.162004470825195 | G Loss: 4.604947889674804e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9956/10000 | D Loss: 8.516400337219238 | G Loss: 4.482628241930797e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9957/10000 | D Loss: 8.332141876220703 | G Loss: 2.437192847537517e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9958/10000 | D Loss: 8.483098983764648 | G Loss: 3.079748012169148e-07\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9959/10000 | D Loss: 8.4532470703125 | G Loss: 3.2733103694226884e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9960/10000 | D Loss: 8.228450775146484 | G Loss: 3.1137716405282845e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9961/10000 | D Loss: 8.327526092529297 | G Loss: 3.177396479259187e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9962/10000 | D Loss: 8.48062801361084 | G Loss: 4.2637131514311477e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9963/10000 | D Loss: 8.56804370880127 | G Loss: 4.271157081348065e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9964/10000 | D Loss: 8.296972274780273 | G Loss: 3.330346771690529e-07\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9965/10000 | D Loss: 8.421564102172852 | G Loss: 4.718302761830273e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9966/10000 | D Loss: 8.4522705078125 | G Loss: 2.775963139356463e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9967/10000 | D Loss: 8.410653114318848 | G Loss: 5.37177129444899e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9968/10000 | D Loss: 8.422215461730957 | G Loss: 3.480339501038543e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9969/10000 | D Loss: 8.379475593566895 | G Loss: 3.460941684352292e-07\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 9970/10000 | D Loss: 8.613744735717773 | G Loss: 2.9548181146310526e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9971/10000 | D Loss: 8.300888061523438 | G Loss: 2.9886476227147796e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9972/10000 | D Loss: 8.344104766845703 | G Loss: 3.361239464538812e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9973/10000 | D Loss: 8.28382682800293 | G Loss: 2.122193620834878e-07\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 9974/10000 | D Loss: 8.274332046508789 | G Loss: 7.360430345215718e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9975/10000 | D Loss: 8.510946273803711 | G Loss: 3.088721314270515e-07\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 9976/10000 | D Loss: 8.343952178955078 | G Loss: 2.7978609296042123e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9977/10000 | D Loss: 8.507330894470215 | G Loss: 2.639124829784123e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9978/10000 | D Loss: 8.434285163879395 | G Loss: 2.767832256722613e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9979/10000 | D Loss: 8.13051986694336 | G Loss: 5.828514986205846e-07\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 9980/10000 | D Loss: 8.431659698486328 | G Loss: 7.128318770810438e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9981/10000 | D Loss: 8.336776733398438 | G Loss: 3.31587727941951e-07\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 9982/10000 | D Loss: 8.42949104309082 | G Loss: 4.212438398099039e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9983/10000 | D Loss: 8.34145736694336 | G Loss: 3.156152388328337e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9984/10000 | D Loss: 8.47111701965332 | G Loss: 2.8105313276682864e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9985/10000 | D Loss: 8.401079177856445 | G Loss: 2.9569736170742544e-07\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9986/10000 | D Loss: 8.279537200927734 | G Loss: 2.707602675400267e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9987/10000 | D Loss: 8.334890365600586 | G Loss: 3.576657832127239e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9988/10000 | D Loss: 8.46646499633789 | G Loss: 3.7563336263701785e-07\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 9989/10000 | D Loss: 8.505054473876953 | G Loss: 3.867854161399009e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9990/10000 | D Loss: 8.447793960571289 | G Loss: 4.962616912962403e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9991/10000 | D Loss: 8.316676139831543 | G Loss: 4.5006430582361645e-07\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9992/10000 | D Loss: 8.429529190063477 | G Loss: 3.310740339657059e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9993/10000 | D Loss: 8.276644706726074 | G Loss: 4.2693807245086646e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9994/10000 | D Loss: 8.563776016235352 | G Loss: 1.907441742332594e-07\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9995/10000 | D Loss: 8.482667922973633 | G Loss: 2.8633644433284644e-07\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9996/10000 | D Loss: 8.419683456420898 | G Loss: 2.2756324824513285e-07\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9997/10000 | D Loss: 8.372051239013672 | G Loss: 2.701517018977029e-07\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9998/10000 | D Loss: 8.348562240600586 | G Loss: 3.179953296239546e-07\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9999/10000 | D Loss: 8.271543502807617 | G Loss: 3.350013173530897e-07\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train discriminator\n",
        "    real_data = model.wv.vectors[np.random.randint(0, model.wv.vectors.shape[0], size=BATCH_SIZE)]\n",
        "    noise = np.random.normal(0, 1, size=(BATCH_SIZE, NOISE_DIM))\n",
        "    generated_data = generator.predict(noise)\n",
        "\n",
        "\n",
        "    x_real = real_data\n",
        "    x_generated = generated_data\n",
        "    y_real = np.ones(BATCH_SIZE)  # Label for real data is 1\n",
        "    y_generated = np.zeros(BATCH_SIZE)  # Label for generated data is 0\n",
        "\n",
        "    # Concatenate real and generated data with their corresponding labels\n",
        "    x = np.concatenate((x_real, x_generated))\n",
        "    y = np.concatenate((y_real, y_generated))\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(x, y)\n",
        "\n",
        "    # Train generator\n",
        "    noise = np.random.normal(0, 1, size=(BATCH_SIZE, NOISE_DIM))\n",
        "    valid_y = np.ones(BATCH_SIZE)\n",
        "\n",
        "    g_loss = gan.train_on_batch(noise, valid_y)\n",
        "\n",
        "    # Display progress\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} | D Loss: {d_loss} | G Loss: {g_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP1NifbHgTd5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mfkOo69gTaQ",
        "outputId": "54571d29-701e-4456-9439-412006429dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 4ms/step\n",
            "125/125 [==============================] - 1s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# After training, you can use the generator to generate new word vectors\n",
        "def generate_word_vectors(generator, num_samples):\n",
        "    noise = np.random.normal(0, 1, size=(num_samples, NOISE_DIM))\n",
        "    generated_data = generator.predict(noise)\n",
        "    return generated_data\n",
        "\n",
        "# Generate word vectors for male and female categories\n",
        "num_male_samples = len(male_word_vectors)  # Assuming an equal number of male and female samples\n",
        "num_female_samples = len(female_word_vectors)\n",
        "generated_male_word_vectors = generate_word_vectors(generator, num_male_samples)\n",
        "generated_female_word_vectors = generate_word_vectors(generator, num_female_samples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #   #  need to improvise the code\n",
        "\n",
        "\n",
        "  #  # Combine generated word vectors and real word vectors for classification\n",
        "  #          combined_vectors = np.concatenate((generated_male_word_vectors, generated_female_word_vectors), axis=0)\n",
        "  #          combined_labels = np.concatenate((np.zeros(num_samples), np.ones(num_samples)))\n",
        "\n",
        "  # # Shuffle the combined data\n",
        "  #          shuffled_indices = np.arange(len(combined_vectors))\n",
        "  #          np.random.shuffle(shuffled_indices)\n",
        "  #          shuffled_vectors = combined_vectors[shuffled_indices]\n",
        "  #          shuffled_labels = combined_labels[shuffled_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnK5QqjRpVBM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7KjPMM2gTWW"
      },
      "outputs": [],
      "source": [
        "# # After training, you can use the generator to generate new word vectors\n",
        "# def generate_word_vectors(generator, num_samples):\n",
        "#     noise = np.random.normal(0, 1, size=(num_samples, NOISE_DIM))\n",
        "#     generated_data = generator.predict(noise)\n",
        "#     return generated_data\n",
        "\n",
        "# # Generate word vectors for male and female categories\n",
        "# num_male_samples = len(male_word_vectors)  # Assuming an equal number of male and female samples\n",
        "# num_female_samples = len(male_word_vectors)\n",
        "# generated_male_word_vectors = generate_word_vectors(generator, num_male_samples)\n",
        "# generated_female_word_vectors = generate_word_vectors(generator, num_female_samples)\n",
        "\n",
        "# # Combine generated word vectors and real word vectors for classification\n",
        "# combined_vectors = np.concatenate((generated_male_word_vectors, generated_female_word_vectors), axis=0)\n",
        "# combined_labels = np.concatenate((np.zeros(num_samples), np.ones(num_samples)))\n",
        "\n",
        "# # Shuffle the combined data\n",
        "# shuffled_indices = np.arange(len(combined_vectors))\n",
        "# np.random.shuffle(shuffled_indices)\n",
        "# shuffled_vectors = combined_vectors[shuffled_indices]\n",
        "# shuffled_labels = combined_labels[shuffled_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2OBMDxMgTS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMx-56aCgTQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceefd737-6b37-4e5a-d0f3-24ac9ec4db1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "len(generated_male_word_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK0Xv5nKgTO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788b3cd8-6f9c-4f75-effa-f344a3ff2d1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "len(generated_female_word_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0UMu5VkgTMo"
      },
      "outputs": [],
      "source": [
        "# Combine the generated word vectors for both male and female categories\n",
        "all_generated_vectors = np.concatenate((generated_male_word_vectors, generated_female_word_vectors), axis=0)\n",
        "\n",
        "# Create corresponding labels (0 for male, 1 for female)\n",
        "male_labels = np.ones(len(generated_male_word_vectors))  # 1 for male data\n",
        "female_labels = np.zeros(len(generated_female_word_vectors))  # 0 for female data\n",
        "all_labels = np.concatenate((male_labels, female_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeYedzKjgTG1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GAN's end\n"
      ],
      "metadata": {
        "id": "dXlsATzYA2tC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjcbVGOegTEq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Auto encoders starting"
      ],
      "metadata": {
        "id": "JMQXPMvmRzRT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IkyRwi5gTB8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense"
      ],
      "metadata": {
        "id": "i3vhCCGHXSUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_autoencoder():\n",
        "    input_dim = 100  # Dimensionality of the input vectors\n",
        "\n",
        "    # Encoder\n",
        "    inputs = Input(shape=(input_dim,))\n",
        "    encoded = Dense(32, activation='relu')(inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "    # Autoencoder\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "yay-wNiyXSR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGTtEj1xXSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = build_autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "sJWTzQ0pXSMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder\n",
        "autoencoder.fit(all_generated_vectors, all_generated_vectors, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8GfyN_6XSKI",
        "outputId": "4ceb6219-c31a-4f31-b6d0-8765e98e4a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 4.1876 - val_loss: 3.8720\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.8181 - val_loss: 3.7923\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7664 - val_loss: 3.7617\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7442 - val_loss: 3.7477\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7327 - val_loss: 3.7381\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7245 - val_loss: 3.7317\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7189 - val_loss: 3.7269\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7143 - val_loss: 3.7223\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7096 - val_loss: 3.7189\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7059 - val_loss: 3.7143\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.7013 - val_loss: 3.7113\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6986 - val_loss: 3.7085\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6957 - val_loss: 3.7062\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6936 - val_loss: 3.7042\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6917 - val_loss: 3.7025\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6900 - val_loss: 3.7011\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6885 - val_loss: 3.6995\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6871 - val_loss: 3.6981\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6859 - val_loss: 3.6969\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6843 - val_loss: 3.6944\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6824 - val_loss: 3.6934\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6813 - val_loss: 3.6923\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6804 - val_loss: 3.6915\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6797 - val_loss: 3.6909\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6792 - val_loss: 3.6904\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6785 - val_loss: 3.6899\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6781 - val_loss: 3.6896\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6775 - val_loss: 3.6890\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6771 - val_loss: 3.6883\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6767 - val_loss: 3.6882\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6763 - val_loss: 3.6877\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6760 - val_loss: 3.6874\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6755 - val_loss: 3.6865\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6744 - val_loss: 3.6855\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6739 - val_loss: 3.6853\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6734 - val_loss: 3.6848\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6731 - val_loss: 3.6846\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6728 - val_loss: 3.6845\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6725 - val_loss: 3.6842\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6723 - val_loss: 3.6837\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6721 - val_loss: 3.6836\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6719 - val_loss: 3.6836\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6717 - val_loss: 3.6835\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6716 - val_loss: 3.6831\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6715 - val_loss: 3.6833\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6713 - val_loss: 3.6830\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6712 - val_loss: 3.6830\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6711 - val_loss: 3.6828\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.6710 - val_loss: 3.6829\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6709 - val_loss: 3.6826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b6a0e83c8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evOWeZ8YXSHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(autoencoder.input, autoencoder.layers[-2].output)\n",
        "encoded_data = encoder.predict(all_generated_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URMjckQfXSCu",
        "outputId": "d8e41bf7-9517-46d3-ae1b-59d7c9d04e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIggwXOQXr0D",
        "outputId": "295bac79-bc9e-43f7-8f79-b1bc1a2ba7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=all_labels"
      ],
      "metadata": {
        "id": "UPYAZ2EEgNk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGhIzNsoXrxR",
        "outputId": "110b9550-9c88-4e89-a516-f9d798802d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.031458 , 19.662722 , 16.218287 , ..., 31.953243 , 21.18817  ,\n",
              "        14.536747 ],\n",
              "       [17.131617 , 25.853481 , 19.886877 , ..., 18.935246 , 16.231953 ,\n",
              "        10.211346 ],\n",
              "       [ 7.3652954, 17.238878 , 16.837276 , ..., 18.9005   , 20.982256 ,\n",
              "         6.5765934],\n",
              "       ...,\n",
              "       [12.415493 , 20.064194 , 24.775358 , ..., 24.149078 , 19.678638 ,\n",
              "         6.1184444],\n",
              "       [13.280991 , 13.186792 , 18.965973 , ..., 27.739878 , 11.984819 ,\n",
              "        14.413086 ],\n",
              "       [17.167707 , 10.360217 , 23.00048  , ..., 23.441828 , 26.723297 ,\n",
              "        21.48173  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=encoded_data"
      ],
      "metadata": {
        "id": "jhEVuYXbXrt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOLv4FxbXrrJ",
        "outputId": "d8376fe1-b477-4ae0-852e-62ad143f50ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oGk6ep7XSAE",
        "outputId": "c2e117a0-a131-4a8e-bd84-f0c6213755cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000,)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjIa5-JuXR9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y,test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "Imv2tAS-RyN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1sP8vp1RyIS",
        "outputId": "92eaf858-feb2-4188-e6a1-f8aeae698b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FxA7baVgS_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a768ddc-565a-436d-a70c-d1626992d1b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400,)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9KopfUmhFKS",
        "outputId": "6d5051fa-d1de-4a26-b068-a27bfb879ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVE8utM8hFG2",
        "outputId": "462cbc15-e93f-41d9-d556-d0167e4b8cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600,)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autoencoders ending"
      ],
      "metadata": {
        "id": "GOTeh0q3R5-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN3GCQOpgS8g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfzzvtF71wo6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpdIc6wSdqP"
      },
      "source": [
        "#code fom tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3zqFTS_Sc-c"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#before autoencoder\n",
        "model1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "d8nzy6ZjhiZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBp8nEyQSc7I"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#before autoencoder\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tkg49BNei79R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuw92bLiSc4r",
        "outputId": "26cc064f-2660-4a81-ccf6-3cd89d61179d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 1.2458 - accuracy: 0.5011\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.5029\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5048\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5156\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5066\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5094\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5155\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5154\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5129\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5192\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5228\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5174\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5164\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5211\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5251\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5253\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5256\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5189\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5117\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5217\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5179\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5229\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5310\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5295\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5336\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5354\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.5318\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6787 - accuracy: 0.5370\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6817 - accuracy: 0.5369\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5314\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5362\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5424\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5506\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.5419\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.5537\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5447\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.5497\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.5518\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5526\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5537\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.5571\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.5550\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.5567\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5625\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5660\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.5596\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.5698\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.5636\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.5677\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.5670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b6a0db066b0>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "model.fit(x, y, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(all_generated_vectors, all_labels, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7mLkGHOjJqk",
        "outputId": "19251122-7eb6-4da5-fe74-4405778329b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 0.7468 - accuracy: 0.5021\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6974 - accuracy: 0.5145\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.5304\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6876 - accuracy: 0.5364\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5431\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6827 - accuracy: 0.5506\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5518\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6779 - accuracy: 0.5612\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.5714\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6737 - accuracy: 0.5727\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6692 - accuracy: 0.5742\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6670 - accuracy: 0.5855\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.5884\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.5994\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.6016\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6500 - accuracy: 0.6015\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6141\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6164\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6328 - accuracy: 0.6280\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6272 - accuracy: 0.6361\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6209 - accuracy: 0.6401\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6482\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6060 - accuracy: 0.6524\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6039 - accuracy: 0.6571\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5933 - accuracy: 0.6593\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6680\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5834 - accuracy: 0.6798\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6793\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.6820\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6902\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.6914\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5567 - accuracy: 0.6940\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7070\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7082\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7053\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7157\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7195\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7294\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7291\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7325\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7341\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.7366\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7375\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.7401\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7433\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4829 - accuracy: 0.7529\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4785 - accuracy: 0.7534\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.7555\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7664\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b6a1129ffa0>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before autoencoder\n",
        "model1.evaluate()"
      ],
      "metadata": {
        "id": "1HVyYlW_jXnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSwcwjOOSc2F",
        "outputId": "9f00834d-099a-43a3-cf5e-fb1b2d48d414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.4956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7188241481781006, 0.49562498927116394]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tol0KGn92yiZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXdk98gKkFkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwjpSpuukFg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqZq7gn9kFdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwGqq-lFkFYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IV4Ye70dkFUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1klB6JrykFRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1PHOF6lIkFPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCNOD8Yj2yf_",
        "outputId": "7183ad4d-0233-4bc9-bb24-7a55ce4b37a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLKmNVZi2ynB",
        "outputId": "99bde1e3-0bf3-4e73-86b8-8191c3a96080"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['male_female_model.pkl']"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "model_filename = 'male_female_model.pkl'\n",
        "joblib.dump(model, model_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we_vjpDCxxFK",
        "outputId": "27c8aa0a-f1e2-4b87-c43d-812706b3f9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZmbOsHp20f6",
        "outputId": "25050a75-6d95-407c-bc29-c8be37d6e843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/male_female_model_filename.pkl']"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_filename = '/content/drive/MyDrive/male_female_model_filename.pkl'\n",
        "joblib.dump(model, model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsULbYip20bR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d1UXD1I20ZB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNXgjofl20Wl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rB2KjoJxxCx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8izVYmhxw_s",
        "outputId": "9548364b-f455-40f1-e228-b534181ce1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n",
            "Text: bikes heroines weapons \n",
            "Prediction: Male\n",
            "\n",
            "Text:  Good Hotel and a very pleasant stay at the Elysees Regencia We stayed at the Elysees Regencia in a (green) deluxe room (47) from Jan 2 til Jan 5, based on TripAdvisor's reviews. To summarize our experience with the Elysees Regencia: it is a very fine hotel.Some pro's:* nice staff, that will help you with booking restaurants* good location (close to the Champs Elysees, subway station nearby (George V))* nice, clean and quite spacious (for Paris!) room. Nice touch: during the day the room is organized (with the green pillows)differently than in the evening (set up for bedtime, with a chocolate and refreshing towel on your pillow). Bathroom (marbled) is ok, with bathrobes slippers and l'Occitane tolietry. The bath itself is a bit on the small side though (no problem for us, though)* a very good feature is the separate toilet from the bath* on arrival, we received a Paris tourist guide and a map (we didn't need it though, since we brought our own and we do know Paris a bitA con* you do hear a bit of street noise (traffic noise from the Avenue Marceau), though it didn't bother us reallySince we woke up quite late, we cannot say how breakfast was (breakfast being served til 1030 am).We would definitely return here.\n",
            "Prediction: Male\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have your own text data\n",
        "text_data = [\"bikes heroines weapons \",\n",
        "             \" Good Hotel and a very pleasant stay at the Elysees Regencia We stayed at the Elysees Regencia in a (green) deluxe room (47) from Jan 2 til Jan 5, based on TripAdvisor's reviews. To summarize our experience with the Elysees Regencia: it is a very fine hotel.Some pro's:* nice staff, that will help you with booking restaurants* good location (close to the Champs Elysees, subway station nearby (George V))* nice, clean and quite spacious (for Paris!) room. Nice touch: during the day the room is organized (with the green pillows)differently than in the evening (set up for bedtime, with a chocolate and refreshing towel on your pillow). Bathroom (marbled) is ok, with bathrobes slippers and l'Occitane tolietry. The bath itself is a bit on the small side though (no problem for us, though)* a very good feature is the separate toilet from the bath* on arrival, we received a Paris tourist guide and a map (we didn't need it though, since we brought our own and we do know Paris a bitA con* you do hear a bit of street noise (traffic noise from the Avenue Marceau), though it didn't bother us reallySince we woke up quite late, we cannot say how breakfast was (breakfast being served til 1030 am).We would definitely return here.\"]\n",
        "\n",
        "# Assuming you have the word-to-index mapping from training\n",
        "# Replace word_to_index with your own mapping\n",
        "word_to_index = {}\n",
        "sequences = []\n",
        "for text in text_data:\n",
        "    tokens = [word_to_index[word] for word in text.split() if word in word_to_index]\n",
        "    sequences.append(tokens)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 100  # Use the same value as used during training\n",
        "sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(sequences)\n",
        "\n",
        "# Print the predictions\n",
        "for i, text in enumerate(text_data):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Prediction: {'Male' if predictions[i][0] > predictions[i][1] else 'Female'}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv1mNoGMxw8U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XieHlTwXxw5u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tdo8HbQSczf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ium0lexNSg3B"
      },
      "source": [
        "#end of tf code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfUXr8jS5Uco"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7RqbaZz5UaG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7blxWHUt5UXI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_LfKof-5UUh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-az1g--x2QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDHMMiGA5Nzy"
      },
      "outputs": [],
      "source": [
        "max_features = 1000\n",
        "max_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGcOb2015NwY"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32, input_length=max_len))  # Embedding layer\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNRB_ql37JuM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVOxqywh5NuP"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITdEn8735No8",
        "outputId": "3e88b291-7611-4f01-a5c5-ef3570617463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ByZLGbO6X2m",
        "outputId": "01739530-7d28-49f3-ec53-a2a345cbe78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4344, 100)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoIjtWXy6X0L",
        "outputId": "b9292df4-2822-4a19-9b66-27af433df096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-6\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "print(np.min(X_train))\n",
        "print(np.max(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDKcgKD_6Xxb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE6MWw7P5NmV"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 10\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG2CGzZA5nWT"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYp0YOes6W5b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCV6-X6F6W-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmll1s6i6W8h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMugapdpg5UlCSj33CIhOOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}